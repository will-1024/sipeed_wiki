{"/soft/maixpy3/zh/usage/08_V831_resnet_copy.html": {"title": "resnet18分类", "content": "# resnet18分类\n\n在V831上（awnn）跑 pytorch resnet18 模型， 模型转换方法\n\n## 直接使用 pytorch hub 的与训练模型\n这里省略了模型定义和训练过程， 直接使用 pytorch hub 的 resnet18 预训练模型进行简单介绍：\nhttps://pytorch.org/hub/pytorch_vision_resnet/\n\n## 在 PC 端测试模型推理\n根据上面链接的使用说明， 使用如下代码可以运行模型\n\n其中， label 下载： https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n```python\nimport os\nimport torch\nfrom torchsummary import summary\ntorch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n## model\nmodel = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\nmodel.eval()\ninput_shape = (3, 224, 224)\nsummary(model, input_shape, device=\"cpu\")\n## test image\nfilename = \"out/dog.jpg\"\nif not os.path.exists(filename):\n    if not os.path.exists(\"out\"):\n        os.makedirs(\"out\")\n    import urllib\n    url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", filename)\n    try: urllib.URLopener().retrieve(url, filename)\n    except: urllib.request.urlretrieve(url, filename)\nprint(\"test image:\", filename)\n## preparing input data\nfrom PIL import Image\nimport numpy as np\nfrom torchvision import transforms\ninput_image = Image.open(filename)\n# input_image.show()\npreprocess = transforms.Compose([\n    transforms.Resize(max(input_shape[1:3])),\n    transforms.CenterCrop(input_shape[1:3]),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\ninput_tensor = preprocess(input_image)\nprint(\"input data max value: {}, min value: {}\".format(torch.max(input_tensor), torch.min(input_tensor)))\ninput_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n## forward model\n# move the input and model to GPU for speed if available\nif torch.cuda.is_available():\n    input_batch = input_batch.to('cuda')\n    model.to('cuda')\nwith torch.no_grad():\n    output = model(input_batch)\n## result    \n# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n# print(output[0])\n# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\nmax_1000 = torch.nn.functional.softmax(output[0], dim=0)\nmax_idx = int(torch.argmax(max_1000))\nwith open(\"imagenet_classes.txt\") as f:\n    labels = f.read().split(\"\\n\")\nprint(\"result: idx:{}, name:{}\".format(max_idx, labels[max_idx]))\n```\n运行后 结果：\n\n```bash\nUsing cache found in /home/neucrack/.cache/torch/hub/pytorch_vision_v0.6.0\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 112, 112]           9,408\n       BatchNorm2d-2         [-1, 64, 112, 112]             128\n              ReLU-3         [-1, 64, 112, 112]               0\n         MaxPool2d-4           [-1, 64, 56, 56]               0\n            Conv2d-5           [-1, 64, 56, 56]          36,864\n       BatchNorm2d-6           [-1, 64, 56, 56]             128\n              ReLU-7           [-1, 64, 56, 56]               0\n            Conv2d-8           [-1, 64, 56, 56]          36,864\n       BatchNorm2d-9           [-1, 64, 56, 56]             128\n             ReLU-10           [-1, 64, 56, 56]               0\n       BasicBlock-11           [-1, 64, 56, 56]               0\n           Conv2d-12           [-1, 64, 56, 56]          36,864\n      BatchNorm2d-13           [-1, 64, 56, 56]             128\n             ReLU-14           [-1, 64, 56, 56]               0\n           Conv2d-15           [-1, 64, 56, 56]          36,864\n      BatchNorm2d-16           [-1, 64, 56, 56]             128\n             ReLU-17           [-1, 64, 56, 56]               0\n       BasicBlock-18           [-1, 64, 56, 56]               0\n           Conv2d-19          [-1, 128, 28, 28]          73,728\n      BatchNorm2d-20          [-1, 128, 28, 28]             256\n             ReLU-21          [-1, 128, 28, 28]               0\n           Conv2d-22          [-1, 128, 28, 28]         147,456\n      BatchNorm2d-23          [-1, 128, 28, 28]             256\n           Conv2d-24          [-1, 128, 28, 28]           8,192\n      BatchNorm2d-25          [-1, 128, 28, 28]             256\n             ReLU-26          [-1, 128, 28, 28]               0\n       BasicBlock-27          [-1, 128, 28, 28]               0\n           Conv2d-28          [-1, 128, 28, 28]         147,456\n      BatchNorm2d-29          [-1, 128, 28, 28]             256\n             ReLU-30          [-1, 128, 28, 28]               0\n           Conv2d-31          [-1, 128, 28, 28]         147,456\n      BatchNorm2d-32          [-1, 128, 28, 28]             256\n             ReLU-33          [-1, 128, 28, 28]               0\n       BasicBlock-34          [-1, 128, 28, 28]               0\n           Conv2d-35          [-1, 256, 14, 14]         294,912\n      BatchNorm2d-36          [-1, 256, 14, 14]             512\n             ReLU-37          [-1, 256, 14, 14]               0\n           Conv2d-38          [-1, 256, 14, 14]         589,824\n      BatchNorm2d-39          [-1, 256, 14, 14]             512\n           Conv2d-40          [-1, 256, 14, 14]          32,768\n      BatchNorm2d-41          [-1, 256, 14, 14]             512\n             ReLU-42          [-1, 256, 14, 14]               0\n       BasicBlock-43          [-1, 256, 14, 14]               0\n           Conv2d-44          [-1, 256, 14, 14]         589,824\n      BatchNorm2d-45          [-1, 256, 14, 14]             512\n             ReLU-46          [-1, 256, 14, 14]               0\n           Conv2d-47          [-1, 256, 14, 14]         589,824\n      BatchNorm2d-48          [-1, 256, 14, 14]             512\n             ReLU-49          [-1, 256, 14, 14]               0\n       BasicBlock-50          [-1, 256, 14, 14]               0\n           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n             ReLU-53            [-1, 512, 7, 7]               0\n           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n           Conv2d-56            [-1, 512, 7, 7]         131,072\n      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n             ReLU-58            [-1, 512, 7, 7]               0\n       BasicBlock-59            [-1, 512, 7, 7]               0\n           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n             ReLU-62            [-1, 512, 7, 7]               0\n           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n             ReLU-65            [-1, 512, 7, 7]               0\n       BasicBlock-66            [-1, 512, 7, 7]               0\nAdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n           Linear-68                 [-1, 1000]         513,000\n================================================================\nTotal params: 11,689,512\nTrainable params: 11,689,512\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 62.79\nParams size (MB): 44.59\nEstimated Total Size (MB): 107.96\n----------------------------------------------------------------\nout/dog.jpg\ntensor(2.6400) tensor(-2.1008)\nidx:258, name:Samoyed, Samoyede\n```\n\n可以看到模型有 11,689,512的参数， 即 11MiB左右， 这个大小也就几乎是实际在 831 上运行的模型的大小了\n\n## 将模型转换为 V831 能使用的模型文件\n转换过程如下：\n\n使用 Pytorch 将模型导出为 onnx模型， 得到onnx文件\n```python\ndef torch_to_onnx(net, input_shape, out_name=\"out/model.onnx\", input_names=[\"input0\"], output_names=[\"output0\"], device=\"cpu\"):\n    batch_size = 1\n    if len(input_shape) == 3:\n        x = torch.randn(batch_size, input_shape[0], input_shape[1], input_shape[2], dtype=torch.float32, requires_grad=True).to(device)\n    elif len(input_shape) == 1:\n        x = torch.randn(batch_size, input_shape[0], dtype=torch.float32, requires_grad=False).to(device)\n    else:\n        raise Exception(\"not support input shape\")\n    print(\"input shape:\", x.shape)\n    # torch.onnx._export(net, x, \"out/conv0.onnx\", export_params=True)\n    torch.onnx.export(net, x, out_name, export_params=True, input_names = input_names, output_names=output_names)\nonnx_out=\"out/resnet_1000.onnx\"\nncnn_out_param = \"out/resnet_1000.param\"\nncnn_out_bin = \"out/resnet_1000.bin\"\ninput_img = filename\ntorch_to_onnx(model, input_shape, onnx_out, device=\"cuda:0\")\n```\n\n如果你不是使用 pytorch 转换的, 而是使用了现成的 ncnn 模型, 不知道输出层的名字, 可以在 https://netron.app/ 打开模型查看输出层的名字\n\n## 使用 onnx2ncnn 工具将onnx转成ncnn模型，得到一个.param文件和一个.bin文件\n按照ncnn项目的编译说明编译，在build/tools/onnx目录下得到onnx2ncnn可执行文件\n```python\ndef onnx_to_ncnn(input_shape, onnx=\"out/model.onnx\", ncnn_param=\"out/conv0.param\", ncnn_bin = \"out/conv0.bin\"):\n    import os\n    # onnx2ncnn tool compiled from ncnn/tools/onnx, and in the buld dir\n    cmd = f\"onnx2ncnn {onnx} {ncnn_param} {ncnn_bin}\"\n    os.system(cmd)\n    with open(ncnn_param) as f:\n        content = f.read().split(\"\\n\")\n        if len(input_shape) == 1:\n            content[2] += \" 0={}\".format(input_shape[0])\n        else:\n            content[2] += \" 0={} 1={} 2={}\".format(input_shape[2], input_shape[1], input_shape[0])\n        content = \"\\n\".join(content)\n    with open(ncnn_param, \"w\") as f:\n        f.write(content)\nonnx_to_ncnn(input_shape, onnx=onnx_out, ncnn_param=ncnn_out_param, ncnn_bin=ncnn_out_bin)\n```\n## 使用全志提供的awnn工具将ncnn模型进行量化到int8模型\n在 maixhub 模型转换 将 ncnn 模型转换为 awnn 支持的 int8 模型 （网页在线转换很方便人为操作，另一个方面因为全志要求不开放 awnn 所以暂时只能这样做）\n\n阅读转换说明，可以获得更多详细的转换说明\n![](./asserts/maixhub.jpg)\n\n这里有几组参数：\n\n均值 和 归一化因子： 在 pytorch 中一般是 (输入值 - mean ) / std, awnn对输入的处理是 (输入值 - mean ) * norm, 总之，让你训练的时候的输入到第一层网络的值范围和给awnn量化工具经过(输入值 - mean ) * norm 计算后的值范围一致既可。 比如 这里打印了实际数据的输入范围是[-2.1008, 2.6400]， 是代码中preprocess 对象处理后得到的，即x = (x - mean) / std ==> (0-0.485)/0.229 = -2.1179, 到awnn就是x = (x - mean_2*255) * (1 / std * 255) 即 mean2 = mean * 255, norm = 1/(std * 255), 更多可以看这里。\n所以我们这里可以设置 均值为 0.485 * 255 = 123.675， 设置 归一化因子为1/ (0.229 * 255) = 0.017125， 另外两个通道同理，但是目前 awnn 只能支持三个通道值一样。。。所以填123.675, 123.675, 123.675，0.017125, 0.017125, 0.017125 即可，因为这里用了pytorch hub的预训练的参数，就这样吧， 如果自己训练，可以好好设置一下\n\n图片输入层尺寸（问不是图片怎么办？貌似 awnn 暂时之考虑到了图片。。）\n\nRGB 格式： 如果训练输入的图片是 RGB 就选 RGB\n量化图片， 选择一些和输入尺寸相同的图片，可以从测试集中拿一些，不一定要图片非常多，但尽量覆盖全场景（摊手\n自己写的其它模型转换如果失败，多半是啥算子不支持，需要在 使用说明里面看支持的 算子，比如现在的版本view、 flatten、reshape 都不支持所以写模型要相当小心， 后面的版本会支持 flatten reshape 等 CPU 算子\n\n如果不出意外， 终于得到了量化好的 awnn 能使用的模型， *.param 和 *.bin\n\n## 使用模型，在v831上推理\n可以使用 python 或者 C 写代码，以下两种方式\n\n### MaixPy3\npython 请看MaixPy3\n\n不想看文档的话，就是在系统开机使用的基础上， 更新 MaixPy3 就可以了：\n\n    pip install --upgrade maixpy3\n\n然后在终端使用 python 运行脚本（可能需要根据你的文件名参数什么的改一下代码）：\n\nhttps://github.com/sipeed/MaixPy3/blob/main/ext_modules/_maix_nn/example/load_forward_camera.py\n\nlabel 在这里： https://github.com/sipeed/MaixPy3/blob/main/ext_modules/_maix_nn/example/classes_label.py\n```python\nfrom maix import nn\nfrom PIL import Image, ImageDraw\nfrom maix import camera, display\ntest_jpg = \"/root/test_input/input.jpg\"\nmodel = {\n    \"param\": \"/root/models/resnet_awnn.param\",\n    \"bin\": \"/root/models/resnet_awnn.bin\"\n}\ncamera.config(size=(224, 224))\noptions = {\n    \"model_type\":  \"awnn\",\n    \"inputs\": {\n        \"input0\": (224, 224, 3)\n    },\n    \"outputs\": {\n        \"output0\": (1, 1, 1000)\n    },\n    \"first_layer_conv_no_pad\": False,\n    \"mean\": [127.5, 127.5, 127.5],\n    \"norm\": [0.00784313725490196, 0.00784313725490196, 0.00784313725490196],\n}\nprint(\"-- load model:\", model)\nm = nn.load(model, opt=options)\nprint(\"-- load ok\")\nprint(\"-- read image\")\nimg = Image.open(test_jpg)\nprint(\"-- read image ok\")\nprint(\"-- forward model with image as input\")\nout = m.forward(img, quantize=True)\nprint(\"-- read image ok\")\nprint(\"-- out:\", out.shape)\nout = nn.F.softmax(out)\nprint(out.max(), out.argmax())\nfrom classes_label import labels\nwhile 1:\n    img = camera.capture()\n    if not img:\n        time.sleep(0.02)\n        continue\n    out = m.forward(img, quantize=True)\n    out = nn.F.softmax(out)\n    msg = \"{:.2f}: {}\".format(out.max(), labels[out.argmax()])\n    print(msg)\n    draw = ImageDraw.Draw(img)\n    draw.text((0, 0), msg, fill=(255, 0, 0))\n    display.show(img)\n```\n\n### C语言 SDK， libmaix\n访问这里，按照 https://github.com/sipeed/libmaix 的说明克隆仓库，并编译 https://github.com/sipeed/libmaix/tree/master/examples/nn_resnet\n\n上传编译成功后dist目录下的所有内容到 v831, 然后执行./start_app.sh即可\n\n> 以上内容出至：<https://neucrack.com/p/358>"}, "/soft/maixpy3/zh/usage/hardware/back/GPIO_1.html": {"title": "GPIO", "content": "---\ntitle: GPIO\nkeywords: maixpy3, GPIO\ndesc: maixpy3 doc: GPIO\n---\n\n## 如何使用 GPIO 输出高低电平\n\nGPIO 是可以复用成别的通信接口，对于 Maixpy3 来说并不需要那么麻烦，GPIO 就用来输出高低电平，别的用法后面再说。\n\n下面以 MaixII-Dock 开发板为例子讲述如果使用 maixpy3 输出高低电平。\n\n通过查看 MaixII-Dock 的引出管脚图可以知道，那些管脚可以直接用来当 GPIO 口使用\n\n![](./../asserts/M2Dock_pin.png)\n\n> 以下代码由于 Maixpy3 还在优化中，可能不能运行，具体的代码到 [github](https://github.com/sipeed/MaixPy3) 上查看\n\n```python\nfrom maix import GPIO\nimport time\nled =GPIO.pin(\"PH\", 14)             # 设置使用 PH 14 管脚\nwhile led:\n    led.set_value(0)                # 设置低电平\n    time.sleep(0.5)\n    print(\"0\", led.get_value())     # 获取管脚当前状态\n    led.set_value(1)                # 设置高电平\n    time.sleep(0.5)\n    print(\"1\", led.get_value())     # 获取管脚当前状态\n\n```\n\n## 什么是 GPIO \nGPIO（英语：General-purpose input/output），通用型之输入输出的简称，功能类似8051的P0—P3，其接脚可以供使用者由程控自由使用，PIN脚依现实考量可作为通用输入（GPI）或通用输出（GPO）或通用输入与输出（GPIO），如当clk generator, chip select等。\n\n既然一个引脚可以用于输入、输出或其他特殊功能，那么一定有寄存器用来选择这些功能。对于输入，一定可以通过读取某个寄存器来确定引脚电位的高低；对于输出，一定可以通过写入某个寄存器来让这个引脚输出高电位或者低电位；对于其他特殊功能，则有另外的寄存器来控制它们。\n> 源自[百度百科](https://baike.baidu.com/item/gpio/4723219?fr=aladdin)\n\n## GPIO 的用途\n\n不同系统间的GPIO的确切作用不同。通用常有下面几种：\n\n1. 输出值可写（高=1，低=0）。一些芯片也可以选择驱动这些值的方式，以便支持“线-或”或类似方案（开漏信号线）。\n2. 输入值可读（1，0）。一些芯片支持输出管脚回读，这在线或的情况下非常有用（以支持双向信号线）。GPIO控制器可能具有一个输入防故障/防反跳逻辑，有时还会有软件控制。\n3. 输入经常被用作中断信号，通常是边沿触发，但也有可能是电平触发。这些中断可以配置为系统唤醒事件，从而将系统从低功耗模式唤醒。\n4. 一个GPIO经常被配置为输入/输出双向，根据不同的产品单板需求，但也存在单向的情况。\n5. 大多是GPIO可以在获取到spinlock自旋锁时访问，但那些通过串行总线访问的通常不能如此操作（休眠的原因）。一些系统中会同时存在这两种形式的GPIO。\n6. 在一个给定单板上，每个GPIO用于一个特定的目的，如监控MMC/SD卡的插入/移除，检查卡写保护状态，驱动LED，配置发送器，串行总线位拆，触发一个硬件看门狗，触发一个开关之类的。\n\n> 原则[电子发烧友论坛](http://www.elecfans.com/emb/jiekou/20171206595752.html)\n\n\n\n只需要修改对应的管脚口即可进行高低电平输出，对于图中别的通信使用方式会在后面讲述\n\n对于 GPIO 更多的使用方式，通过查看开发板的规格书得知"}, "/soft/maixpy3/zh/usage/hardware/back/UART_1.html": {"title": "UART", "content": "---\ntitle: UART\nkeywords: maixpy3, UART\ndesc: maixpy3 doc: UART\n---\n\n## UART 的使用\n\n串口可以用于与别的开发板或者是单片机进行数据的通信，用于链接别的开发板或者单片机。\n\n根据所接的串口号进行修改以下代码，\n\n> 以下代码由于 Maixpy3 还在优化中，可能不能运行，具体的代码到 [github](https://github.com/sipeed/MaixPy3) 上查看\n\n```python\nimport serial\n\nser = serial.Serial(\"/dev/ttyS1\",115200)    # 使用 UART1 ，波特率设置为 115200\n\nprint('serial test start ...')\nser.write(b\"Hello Wrold !!!\\n\")\ntry:\n    while True:\n        ser.setDTR(True)\n        ser.setRTS(True)\n        tmp = ser.readline()\n        print(tmp)\n        ser.write(tmp)\n        ser.setDTR(False)\n        ser.setRTS(False)\nexcept KeyboardInterrupt:\n    if ser != None:\n        ser.close()\n```\n\n## 什么是串口\n\n通用异步收发传输器（Universal Asynchronous Receiver/Transmitter，通常称作UART） 是一种串行异步收发协议，应用十分广泛。UART工作原理是将数据的二进制位一位一位的进行传输。在UART通讯协议中信号线上的状态位高电平代表’1’低电平代表’0’。当然两个设备使用UART串口通讯时，必须先约定好传输速率和一些数据位。\n\n## 硬件连接\n硬件连接比较简单，仅需要3条线，注意连接时两个设备UART电平，如电平范围不一致请做电平转换后再连接，如下图所示：\n\n- TX：发送数据端，要接对面设备的RX\n- RX：接收数据端，要接对面设备的TX\n- GND：保证两设备共地，有统一的参考平面\n\n![](./../asserts/UART.jpg)\n\n## 串口工作原理\n\n- 发送接收\n\n发送逻辑对从发送FIFO 读取的数据执行“并→串”转换。控制逻辑输出起始位在先的串行位流，并且根据控制寄存器中已编程的配置，后面紧跟着数据位（注意：最低位 LSB 先输出）、奇偶校验位和停止位。\n\n在检测到一个有效的起始脉冲后，接收逻辑对接收到的位流执行“串→并”转换。此外还会对溢出错误、奇偶校验错误、帧错误和线中止（line-break）错误进行检测，并将检测到的状态附加到被写入接收FIFO 的数据中。 [3] \n\n- 波特率产生\n\n波特率除数（baud-rate divisor）是一个22 位数，它由16 位整数和6 位小数组成。波特率发生器使用这两个值组成的数字来决定位周期。通过带有小数波特率的除法器，在足够高的系统时钟速率下，UART 可以产生所有标准的波特率，而误差很小。\n\n- 数据收发\n\n发送时，数据被写入发送FIFO。如果UART 被使能，则会按照预先设置好的参数（波特率、数据位、停止位、校验位等）开始发送数据，一直到发送FIFO 中没有数据。一旦向发送FIFO 写数据（如果FIFO 未空），UART 的忙标志位BUSY 就有效，并且在发送数据期间一直保持有效。BUSY 位仅在发送FIFO 为空，且已从移位寄存器发送最后一个字符，包括停止位时才变无效。即 UART 不再使能，它也可以指示忙状态。BUSY 位的相关库函数是UARTBusy( )\n\n在UART 接收器空闲时，如果数据输入变成“低电平”，即接收到了起始位，则接收计数器开始运行，并且数据在Baud16 的第8 个周期被采样。如果Rx 在Baud16 的第8 周期仍然为低电平，则起始位有效，否则会被认为是错误的起始位并将其忽略。\n\n如果起始位有效，则根据数据字符被编程的长度，在 Baud16 的每第 16 个周期（即一个位周期之后）对连续的数据位进行采样。如果奇偶校验模式使能，则还会检测奇偶校验位。\n最后，如果Rx 为高电平，则有效的停止位被确认，否则发生帧错误。当接收到一个完整的字符时，将数据存放在接收FIFO 中。\n\n- 中断控制\n    - 出现以下情况时，可使UART 产生中断：\n    - FIFO 溢出错误\n    - 线中止错误（line-break，即Rx 信号一直为0 的状态，包括校验位和停止位在内）\n    - 奇偶校验错误\n    - 帧错误（停止位不为1）\n    - 接收超时（接收FIFO 已有数据但未满，而后续数据长时间不来）\n    - 发送\n    - 接收\n    - 由于所有中断事件在发送到中断控制器之前会一起进行“或运算”操作，所以任意时刻 UART 只能向中断产生一个中断请求。通过查询中断状态函数UARTIntStatus( )，软件可以在同一个中断服务函数里处理多个中断事件（多个并列的if 语句）。\n\n- FIFO 操作\n\nFIFO 是“First-In First-Out”的缩写，意为“先进先出”，是一种常见的队列操作。 Stellaris 系列ARM 的UART 模块包含有2 个16 字节的FIFO：一个用于发送，另一个用于接收。可以将两个FIFO 分别配置为以不同深度触发中断。可供选择的配置包括：1/8、 1/4、1/2、3/4 和7/8 深度。例如，如果接收FIFO 选择1/4，则在UART 接收到4 个数据时产生接收中断。\n\n发送FIFO的基本工作过程： 只要有数据填充到发送FIFO 里，就会立即启动发送过程。由于发送本身是个相对缓慢的过程，因此在发送的同时其它需要发送的数据还可以继续填充到发送 FIFO 里。当发送 FIFO 被填满时就不能再继续填充了，否则会造成数据丢失，此时只能等待。这个等待并不会很久，以9600 的波特率为例，等待出现一个空位的时间在1ms 上下。发送 FIFO 会按照填入数据的先后顺序把数据一个个发送出去，直到发送 FIFO 全空时为止。已发送完毕的数据会被自动清除，在发送FIFO 里同时会多出一个空位。\n\n接收FIFO的基本工作过程： 当硬件逻辑接收到数据时，就会往接收FIFO 里填充接收到的数据。程序应当及时取走这些数据，数据被取走也是在接收FIFO 里被自动删除的过程，因此在接收 FIFO 里同时会多出一个空位。如果在接收 FIFO 里的数据未被及时取走而造成接收FIFO 已满，则以后再接收到数据时因无空位可以填充而造成数据丢失。\n\n收发FIFO 主要是为了解决UART 收发中断过于频繁而导致CPU 效率不高的问题而引入的。在进行 UART 通信时，中断方式比轮询方式要简便且效率高。但是，如果没有收发 FIFO，则每收发一个数据都要中断处理一次，效率仍然不够高。如果有了收发FIFO，则可以在连续收发若干个数据（可多至14 个）后才产生一次中断然后一并处理，这就大大提高了收发效率。\n\n完全不必要担心FIFO 机制可能带来的数据丢失或得不到及时处理的问题，因为它已经帮你想到了收发过程中存在的任何问题，只要在初始化配置UART 后，就可以放心收发了， FIFO 和中断例程会自动搞定一切。\n\n- 回环操作\nUART 可以进入一个内部回环（Loopback）模式，用于诊断或调试。在回环模式下，从Tx 上发送的数据将被Rx 输入端接收。\n\n- 串行红外协议\n\n在某些 Stellaris 系列 ARM 芯片里，UART 还包含一个 IrDA 串行红外（SIR）编码器/ 解码器模块。IrDA SIR 模块的作用是在异步UART数据流和半双工串行SIR 接口之间进行转换。片上不会执行任何模拟处理操作。SIR 模块的任务就是要给UART 提供一个数字编码输出和一个解码输入。UART 信号管脚可以和一个红外收发器连接以实现IrDA SIR物理层连接。\n\n\n> 参考：百度百科、CSDN博客"}, "/soft/maixpy3/zh/usage/hardware/back/SPI_1.html": {"title": "SPI", "content": "---\ntitle: SPI\nkeywords: maixpy3, SPI\ndesc: maixpy3 doc: SPI\n---\n\n## 使用 SPI\n\n> 以下代码由于 Maixpy3 还在优化中，可能不能运行，具体的代码到 [github](https://github.com/sipeed/MaixPy3) 上查看\n\n```python\nimport spidev, time\nspi = spidev.SpiDev(mode=SPI.MODE_MASTER, baudrate=10000000, polarity=0, phase=0, bits=8, firstbit=SPI.MSB)   # SPI 初始化\nspi.open(1, 0)                      # 使用  SPI 1.0 \n\nwhile True:\n  time.sleep(0.1)\n  to_send = [0x01, 0x02, 0x01]\n  to_get = []\n  print(spi.write_readinto(to_send, to_get, cs=SPI.CS0)) \n\n```\n\n## 什么是 SPI\nSPI是串行外设接口（Serial Peripheral Interface）的缩写，是一种高速的，全双工，同步的通信总线，并且在芯片的管脚上只占用四根线，节约了芯片的管脚，同时为PCB的布局上节省空间，提供方便，正是出于这种简单易用的特性，越来越多的芯片集成了这种通信协议，比如AT91RM9200。\n\n## SPI 工作原理\nSPI总线是一种4线总线，因其硬件功能很强，所以与SPI有关的软件就相当简单，使中央处理器（Central Processing Unit，CPU）有更多的时间处理其他事务。正是因为这种简单易用的特性，越来越多的芯片集成了这种通信协议，比如AT91RM9200。SPI是一种高速、高效率的串行接口技术。通常由一个主模块和一个或多个从模块组成，主模块选择一个从模块进行同步通信，从而完成数据的交换。SPI是一个环形结构，通信时需要至少4根线（事实上在单向传输时3根线也可以）。\n\nSPI的通信原理很简单，它以主从方式工作，这种模式通常有一个主设备和一个或多个从设备，需要至少4根线，事实上3根也可以（单向传输时）。也是所有基于SPI的设备共有的，它们是MISO（主设备数据输入）、MOSI（主设备数据输出）、SCLK（时钟）、CS（片选）。\n\n>（1）MISO– Master Input Slave Output，主设备数据输入，从设备数据输出；\n\n>（2）MOSI– Master Output Slave Input，主设备数据输出，从设备数据输入；\n\n>（3）SCLK – Serial Clock，时钟信号，由主设备产生；\n\n>（4）CS – Chip Select，从设备使能信号，由主设备控制。\n\n其中，CS是从芯片是否被主芯片选中的控制信号，也就是说只有片选信号为预先规定的使能信号时（高电位或低电位），主芯片对此从芯片的操作才有效。这就使在同一条总线上连接多个SPI设备成为可能。\n\n接下来就负责通讯的3根线了。通讯是通过数据交换完成的，这里先要知道SPI是串行通讯协议，也就是说数据是一位一位的传输的。这就是SCLK时钟线存在的原因，由SCLK提供时钟脉冲，SDI，SDO则基于此脉冲完成数据传输。数据输出通过 SDO线，数据在时钟上升沿或下降沿时改变，在紧接着的下降沿或上升沿被读取。完成一位数据传输，输入也使用同样原理。因此，至少需要8次时钟信号的改变（上沿和下沿为一次），才能完成8位数据的传输。\n\n时钟信号线SCLK只能由主设备控制，从设备不能控制。同样，在一个基于SPI的设备中，至少有一个主设备。这样的传输方式有一个优点，在数据位的传输过程中可以暂停，也就是时钟的周期可以为不等宽，因为时钟线由主设备控制，当没有时钟跳变时，从设备不采集或传送数据。SPI还是一个数据交换协议：因为SPI的数据输入和输出线独立，所以允许同时完成数据的输入和输出。芯片集成的SPI串行同步时钟极性和相位可以通过寄存器配置，IO模拟的SPI串行同步时钟需要根据从设备支持的时钟极性和相位来通讯。\n\n最后，SPI接口的一个缺点：没有指定的流控制，没有应答机制确认是否接收到数据。\n\nSPI的片选可以扩充选择16个外设,这时PCS输出=NPCS,说NPCS0~3接4-16译码器,这个译码器是需要外接4-16译码器，译码器的输入为NPCS0~3，输出用于16个外设的选择。"}, "/soft/maixpy3/zh/usage/hardware/back/PWM_1.html": {"title": "PWM", "content": "---\ntitle: PWM\nkeywords: maixpy3, PWM\ndesc: maixpy3 doc: PWM\n---\n\n## 使用 PWM\n\n当需要使用 PWM 驱动一些外设的时候，可以通过以下的代码进行驱动，对于不同的 Linux 开发板来说，PWM 信号输出的管脚号是不一样的，只需要修改 PWM 输出口\n\n> 以下代码由于 Maixpy3 还在优化中，可能不能运行，具体的代码到 [github](https://github.com/sipeed/MaixPy3) 上查看\n\n```python\nfrom maix import pwm\nimport time\npwm_output = pwm.PWM(6, freq=1000)          # s设置输出 PWM 的管脚和频率\nwhile True:\n    pwm_output.out(pulse_width_percent = 50)    # 设置 PWM 的占空比并开始输出\n    time.sleep(1)\n    pwm_output.step()                           # 停止输出 pwm 信号\n    time.sleep(0.1)\n\n```\n\n## 什么是 PWM？\n脉冲宽度调制是一种模拟控制方式，根据相应载荷的变化来调制晶体管基极或MOS管栅极的偏置，来实现晶体管或MOS管导通时间的改变，从而实现开关稳压电源输出的改变。这种方式能使电源的输出电压在工作条件变化时保持恒定，是利用微处理器的数字信号对模拟电路进行控制的一种非常有效的技术。脉冲宽度调制是利用微处理器的数字输出来对模拟电路进行控制的一种非常有效的技术，广泛应用在从测量、通信到功率控制与变换的许多领域中。\n\n## PWM 工作原理\n脉宽调制（PWM）基本原理：控制方式就是对逆变电路开关器件的通断进行控制，使输出端得到一系列幅值相等但宽度不一致的脉冲，用这些脉冲来代替正弦波或所需要的波形。也就是在输出波形的半个周期中产生多个脉冲，使各脉冲的等值电压为正弦波形，所获得的输出平滑且低次谐波少。按一定的规则对各脉冲的宽度进行调制，既可改变逆变电路输出电压的大小，也可改变输出频率。\n\n例如，把正弦半波波形分成N等份，就可把正弦半波看成由N个彼此相连的脉冲所组成的波形。这些脉冲宽度相等，都等于 π/n ，但幅值不等，且脉冲顶部不是水平直线，而是曲线，各脉冲的幅值按正弦规律变化。如果把上述脉冲序列用同样数量的等幅而不等宽的矩形脉冲序列代替，使矩形脉冲的中点和相应正弦等分的中点重合，且使矩形脉冲和相应正弦部分面积（即冲量）相等，就得到一组脉冲序列，这就是PWM波形。可以看出，各脉冲宽度是按正弦规律变化的。根据冲量相等效果相同的原理，PWM波形和正弦半波是等效的。对于正弦的负半周，也可以用同样的方法得到PWM波形。\n\n在PWM波形中，各脉冲的幅值是相等的，要改变等效输出正弦波的幅值时，只要按同一比例系数改变各脉冲的宽度即可，因此在交－直－交变频器中，PWM逆变电路输出的脉冲电压就是直流侧电压的幅值。\n\n根据上述原理，在给出了正弦波频率，幅值和半个周期内的脉冲数后，PWM波形各脉冲的宽度和间隔就可以准确计算出来。按照计算结果控制电路中各开关器件的通断，就可以得到所需要的PWM波形。下图为变频器输出的PWM波的实时波形。\n![](./../asserts/pwm.gif)\n![](./../asserts/pwm.jpg)\n\n\n\n> 源自百度百科"}, "/soft/maixpy3/zh/usage/hardware/back/I2C_1.html": {"title": "I2C", "content": "---\ntitle: I2C\nkeywords: maixpy3, I2C\ndesc: maixpy3 doc: I2C\n---\n\n## 如何使用 I2C \n\n通过查看开发板上的管脚引出 I2C 相关引脚，管脚图中得 TWI 对应的就是 I2C 管脚\n\n![](./../asserts/M2Dock_pin.png)\n\n> 以下代码由于 Maixpy3 还在优化中，可能不能运行，具体的代码到 [github](https://github.com/sipeed/MaixPy3) 上查看\n\n```python\nfrom maix import i2c\ni2c_address = i2c.I2CSecan('/dev/i2c-2')            # 获取设备在 I2C 的地址数据\nprint(i2c_address)\ni2c_im = i2c.read(i2c_address, 4)                   # 获取设备信息\ni2c_ID = i2c.read_register(i2c_address, 0x36, 4)    # 读取设备寄存器上的信息\ni2c.writes(i2c_address, 1)                          # 对设备上发送数据\ni2c.writes_register(i2c_address, 0x38, 0xab)        # 对设备上的寄存器写入数据\n```\n> 以上是 MaixII-Dock 开发板的板载三轴加速度传感器部分代码，完整代码在 [Github](https://github.com/sipeed/MaixPy3/blob/master/examples/maix_v831/usage/usage_v831_i2c-2.py)\n\n对于 I2C 别的使用方法，可以查看 Maixpy3 在 Github 上的源码\n\n## 什么是 I2C 总线\n\n1. I2C 总线是由 Philips 公司开发的一种简单、双向二线制同步串行总线。它只需要两根线即可在连接于总线上的设备之间传送信息。\n2. 主设备用于启动总线传送数据，并产生时钟以开放传送的设备，此时任何被寻址的设备均被认为是从设备．总线上主设备和从设备、发数据设备和收数据设备的关系不是恒定的，而取决于此时数据传送方向。\n3. 如果主设备要发送数据给从设备，则主设备首先要寻址从设备，然后主动发送数据至从设备，最后由主设备终止数据传送；如果主设备要接收从设备的数据，首先由主设备寻址从设备．然后主设备接收从设备发送的数据，最后由主设备终止接收过程。在这种情况下．主机负责产生定时时钟和终止数据传送。\n\n## I2C 通信设备原理\n\n1. 硬件结构：通信只需要两根传输线，结构上及其简单。\n    - SCL(serial clock)：时钟线，传输 CLK 信号，一般是 I2C 主设备向从设备提供时钟的通道。\n    - SDA(serial data): 数据线，通信数据都通过SDA线传输。\n\n2. 通信特征：串行、同步、非差分、低速率\n    - I2C 属于串行通信，所有的数据以位为单位在 SDA 线上串行传输。\n    - 同步通信就是通信双方工作在同一个时钟下，一般是通信的 A 方通过一根 CLK 信号线传输 A 自己的时钟给 B，B 工作在 A 传输的时钟下。所以同步通信的显著特征就是：通信线中有 CLK\n    - 非差分。因为 I2C 通信速率不高，而且通信双方距离很近，所以使用电平信号通信。\n    - 低速率。I2C 一般是用在同一个板子上的2个 IC 之间的通信，而且用来传输的数据量不大，所以本身通信速率很低（一般几百KHz，不同的 I2C 芯片的通信速率可能不同，具体在编程的时候要看自己所使用的设备允许的 I2C 通信最高速率，不能超过这个速率）\n\n3. 通信方向：主设备+从设备\n    - I2C 通信的时候，通信双方地位是不对等的，而是分主设备和从设备。通信由主设备发起，由主设备主导，从设备只是按照 I2C 协议被动的接受主设备的通信，并及时响应。\n    - 谁是主设备、谁是从设备是由通信双方来定的（ I2C 协议并无规定），一般来说一个芯片可以只能做主设备、也可以只能做从设备、也可以既能当主设备又能当从设备（软件配置）。\n\n4. 一对多通信\n    - I2C 通信可以一对一（1个主设备对1个从设备），也可以一对多（1个主设备对多个从设备）。\n    - 主设备来负责调度总线，决定某一时间和哪个从设备通信。注意：同一时间内，I2C的总线上只能传输一对设备的通信信息，所以同一时间只能有一个从设备和主设备通信，其他从设备处于“冬眠”状态，不能出来捣乱，否则通信就乱套了。\n    - 每一个 I2C 从设备在通信中都有一个 I2C 从设备地址，这个设备地址是从设备本身固有的属性，然后通信时主设备需要知道自己将要通信的那个从设备的地址，然后在通信中通过地址来甄别是不是自己要找的那个从设备。（这个地址是一个电路板上唯一的，不是全球唯一的）\n\n5. 主要用途\n    - 主要用途：SoC 和周边外设之间的通信（典型的如 EEPROM、电容触摸 IC、各种 sensor 等）\n\n\n> 原文链接：https://blog.csdn.net/weixin_46089486/article/details/108992588"}, "/soft/maixpy3/zh/usage/Audio/play_mp4.html": {"title": "", "content": "| 更新时间 | 负责人 | 内容 | 备注 |\n| --- | --- | --- | --- |\n| 2021年12月4日 | Rui | 初次编写文档 | ---- |\n| 2022年1月18日 | dalaoshu | 修改文档，增加效果图 | ---- |\n\n# MaixPy3 播放视频\n\n实际上它是由 ffmpeg + pyav 编译而来，它们分别是什么呢？\n\nFFmpeg 是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。\n\nhttps://pyav.org/docs/develop/\n\nPyAV 是一个用于 FFmpeg 的 python 绑定。通过容器、流、包、编解码器和帧直接和精确地访问媒体。它公开了一些数据的转换，并帮助您从其他包(例如 Numpy 和 Pillow )获取数据。\n\nhttps://pyav.org/docs/develop/\n\n目前测试的视频格式有 mp4 和 avi，其他格式还没有进行测试，以下是我们提供的测试视频供确认效果。\n\n<p align=\"center\">\n  <iframe src=\"//player.bilibili.com/player.html?aid=717126108&bvid=BV1dQ4y1f7RN&cid=385731209&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"max-width:640px; max-height:480px;\"> </iframe>\n</p>\n\n共有3个[测试视频](https://dl.sipeed.com/shareURL/MaixII/MaixII-Dock/example),将这里得到的视频存放到 Linux 系统的 root 目录中，将 `path_to_video` 的参数修改成所存放视频路径。\n\n```python\nfrom maix import display, camera\nimport pyaudio\nimport av\nimport threading\nimport time\n\nclass funation:\n    status = 0\n    def __init__(self,device=None):\n        self.event = self.run\n        display.show(camera.capture())\n        self.tim = time.time()\n        self.device = device\n    def __del__(self):\n        print(\"paly exit\")\n    def play(self):\n        try:\n            # recommend flv\n            # ffmpeg -r 30 -i bad_apple.mp4 -s 240x240 output.mp4\n            # adb push ./output.mp4 /mnt/UDISK/\n            # adb push ./test.py / && adb shell 'python ./test.py'\n            path_to_video = '/root/output.mp4'\n            container = av.open(path_to_video)\n            ai_stream = container.streams.audio[0]\n            vi_stream = container.streams.video[0]\n            fifo = av.AudioFifo()\n            p = pyaudio.PyAudio()\n            ao = p.open(format=pyaudio.paFloat32, channels=2, rate=22050, output=True)\n            for frame in container.decode(video=0, audio=0):\n                if 'Audio' in repr(frame):\n                    frame.pts = None\n                    fifo.write(frame)\n                    for frame in fifo.read_many(4096):\n                        ao.write(frame.planes[0].to_bytes())\n                if 'Video' in repr(frame):\n                    display.show(bytes(frame.to_rgb().planes[0]))\n                if self.device.funaction_status == -1:\n                    ao.stop_stream()\n                    ao.close()\n                    p.terminate()\n                    return\n        except Exception as e:\n            print(e)\n        finally:\n            ao.stop_stream()\n            ao.close()\n            p.terminate()\n    def run(self):\n        if self.status == 0:\n            threading.Thread(target=self.play).start()\n            self.status = 1\n        time.sleep(0.1)\n\n\nif __name__ == \"__main__\":\n    import signal\n    def handle_signal_z(signum,frame):\n        print(\"APP OVER\")\n        exit(0)\n    signal.signal(signal.SIGINT,handle_signal_z)\n    start = funation()\n    while True:\n        start.event()\n```"}, "/soft/maixpy3/zh/usage/Audio/audio.html": {"title": "音频操作", "content": "---\ntitle: 音频操作\nkeywords: 音频操作, MaixPy3, Python, Python3\ndesc: maixpy doc: 音频操作\n---\n\nMaixPy3 关于音频相关操作采用的是 库，PyAudio 库，PyAudio 为跨平台音频 I/O 库 PortAudio 提供了 Python 绑定，帮助用户轻松地在各种平台上播放和录制音频。\n\n[pyaudio 官方文档](http://people.csail.mit.edu/hubert/pyaudio/docs/)\n\n## 录音操作\n\n```python\nimport pyaudio\nimport wave\n\nCHUNK = 1024\nFORMAT = pyaudio.paInt16\nCHANNELS = 2\nRATE = 44100\nRECORD_SECONDS = 5\nWAVE_OUTPUT_FILENAME = \"output.wav\"\n\np = pyaudio.PyAudio()\n\nstream = p.open(format=FORMAT,\n                channels=CHANNELS,\n                rate=RATE,\n                input=True,\n                frames_per_buffer=CHUNK)\n\nprint(\"* recording\")\n\nframes = []\n\nfor i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n    data = stream.read(CHUNK)\n    frames.append(data)\n\nprint(\"* done recording\")\n\nstream.stop_stream()\nstream.close()\np.terminate()\n\nwf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\nwf.setnchannels(CHANNELS)\nwf.setsampwidth(p.get_sample_size(FORMAT))\nwf.setframerate(RATE)\nwf.writeframes(b''.join(frames))\nwf.close()\n```\n\n## 播放音频\n\n```python\n\nimport pyaudio\nimport wave\nimport sys\n\n# 定义数据流块\nCHUNK = 1024\n\nif len(sys.argv) < 2:\n    print(\"Plays a wave file.\\n\\nUsage: %s filename.wav\" % sys.argv[0])\n    sys.exit(-1)\n\n# 只读方式打开wav文件\nwf = wave.open(r'test.wav', 'rb')#(sys.argv[1], 'rb')\n\np = pyaudio.PyAudio()\n\n# 打开数据流\nstream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n                channels=wf.getnchannels(),\n                rate=wf.getframerate(),\n                output=True)\n\n# 读取数据\ndata = wf.readframes(CHUNK)\n\n# 播放\nwhile data != '':\n    stream.write(data)\n    data = wf.readframes(CHUNK)\n\n# 停止数据流\nstream.stop_stream()\nstream.close()\n\n# 关闭 PyAudio\np.terminate()\n```"}, "/soft/maixpy3/zh/usage/Audio/speech.html": {"title": "", "content": ""}, "/soft/maixpy3/zh/usage/train_AI/train_yolov2.html": {"title": "目标检测本地训练教程", "content": "# 目标检测本地训练教程\n\n| 时间 | 负责人 | 更新内容 | 备注 |\n| --- | --- | --- | :---: |\n| 2022年1月22日 | dianjixz | 编写初稿文档 | 训练教程只能在 Linux 系统中运行，<br>并只能部署到 MaixII-Dock 开发板上运行，<br>文档还需要二次整理 |\n\n> Windows 系统暂不支持！\n> 临时工程文件获取：https://github.com/dianjixz/v831_yolo\n\n## 基本概念\n目标检测（Object Detection）的任务是找出图像中所有感兴趣的目标（物体），确定它们的类别和位置，是计算机视觉领域的核心问题之一。由于各类物体有不同的外观、形状和姿态，加上成像时光照、遮挡等因素的干扰，目标检测一直是计算机视觉领域最具有挑战性的问题。\n\n计算机视觉中关于图像识别有四大类任务：\n\n（1）分类-Classification：解决“是什么？”的问题，即给定一张图片或一段视频判断里面包含什么类别的目标。\n\n（2）定位-Location：解决“在哪里？”的问题，即定位出这个目标的的位置。\n\n（3）检测-Detection：解决“在哪里？是什么？”的问题，即定位出这个目标的位置并且知道目标物是什么。\n\n（4）分割-Segmentation：分为实例的分割（Instance-level）和场景分割（Scene-level），解决“每一个像素属于哪个目标物或场景”的问题。\n\n![](./dnn/yolo.png)\n\n> 了解更多可以查看 CSDN 博文：<https://blog.csdn.net/yegeli/article/details/109861867>\n\n## 模型训练\n\n| 网络结构 | 训练平台 | 部署平台 | 模型转换工具 |\n| --- | --- | --- | -- | \n| YOLOv2 | PyTorch | MaixII-Dock | ncnn + MaixHub 在线转换工具 |\n\n### 数据集制作与使用  \n\nYOLOv2 默认使用 voc 格式的数据集,文件夹取名为 custom 放到 data 目录下, 比如:\n~~~ bash\n#voc格式的yolo训练数据集\n├── custom    #数据集文件夹名\n│   ├── Annotations\t\t#标注文件\n│   ├── ImageSets\t\t#训练参数划分\n│   │    └── Main\n│   │         ├── train.txt\n│   │         └── val.txt\n│   ├── JPEGImages\t\t#训练图片\n~~~\n\ntrain.txt 和 val.txt 中, 每一行是一个数据(图像)名, 路径相对于 `JPEGImages`\n~~~ bash\ntrain.txt 写着用于训练的图片名称\nval.txt  写着用于验证的图片名称\n~~~\n**修改配置**\n\n修改 `data/custom.py` 中的 `CUSTOM_CLASSES` 变量为正确的 `labels`\n~~~ python\nCUSTOM_CLASSES = [\n    \"mouse\",\n    \"sipeed_logo\"\n]\n~~~\n\n### 训练开始\n\n~~~ bash\npython3 train.py -d custom --cuda -v slim_yolo_v2 -hr -ms\n~~~\n\n[//]: # \"或者安装好horovod, 然后多卡训练\"\n[//]: # \"~~~ bash\"\n[//]: # \"horovodrun -np 4 python train.py -d custom --cuda -v slim_yolo_v2 -hr -ms\"\n[//]: # \"~~~\"\n\n训练完成后会在 weights/custom/slim_yolo_v2 目录下生成训练中保存的参数\n\n### 导出模型\n\n~~~ bash\npython3 test.py -d custom -v slim_yolo_v2 --trained_model weights/custom/slim_yolo_v2/slim_yolo_v2_1000.pth --visual_threshold 0.3 -size 224 --export\n~~~\n\n运行导出模型命令后会在 out 目录下生成 test 测试图片效果和模型文件,模型转换请参考上面模型转换章节.\n\n### 模型部署  \n等待模型转换完成,下载转换好的模型文件.  \n得到的 *.param 和 *.bin 文件就是部署在 MaixII-Dock 上的文件.  \n打开事例代码,替换模型文件名,分类标签和模型加载参数,然后运行即可. \n~~~ python\n#检测示例代码\n\nfrom maix import nn, camera, image, display\nfrom maix.nn import decoder\nimport time\n\nmodel = {\n    \"param\": \"/root/yolov2_int8.param\",\n    \"bin\": \"/root/yolov2_int8.bin\"\n}\noptions = {\n    \"model_type\":  \"awnn\",\n    \"inputs\": {\n        \"input0\": (224, 224, 3)\n    },\n    \"outputs\": {\n        \"output0\": (7, 7, (1+4+2)*5)    #输出参数修改,修改格式 (7 ,7 , (1 + 4 + \"类别数量\" ) * 5)\n    },\n    \"mean\": [127.5, 127.5, 127.5],\n    \"norm\": [0.0078125, 0.0078125, 0.0078125],\n}\n\nlabels = [\"mouse\",\"sipeed_logo\"]            #分类标签\nanchors = [1.19, 1.98, 2.79, 4.59, 4.53, 8.92, 8.06, 5.29, 10.32, 10.65]\n\nm = nn.load(model, opt=options)\nyolo2_decoder = decoder.Yolo2(len(labels), anchors, net_in_size=(options[\"inputs\"][\"input0\"][0], options[\"inputs\"][\"input0\"][1]), net_out_size=(7, 7))\n\nwhile True:\n    img = camera.capture()\n    AI_img = img.copy().resize(224, 224)\n    out = m.forward(AI_img.tobytes(), quantize=True, layout=\"hwc\")\n    boxes, probs = yolo2_decoder.run(out, nms=0.3, threshold=0.3, img_size=(options[\"inputs\"][\"input0\"][0], options[\"inputs\"][\"input0\"][1]))\n\n    if len(boxes):\n        for i, box in enumerate(boxes):\n            class_id = probs[i][0]\n            prob = probs[i][1][class_id]\n            disp_str = \"{}:{:.2f}%\".format(labels[class_id], prob*100)\n            img.draw_rectangle(box[0], box[1], box[0] + box[2], box[1] + box[3], color = (255, 255, 255))\n            x = box[0]\n            y = box[1] - 20\n            if y < 0:\n                y = 0\n            img.draw_string(x, y, disp_str, color = (255, 255, 255))\n\n    display.show(img)\n\n\n~~~\n\n运行效果图:\n\n![](./dnn/yolo_test.jpg)\n\n\n> 参考：\n>csdn 博客：https://blog.csdn.net/yegeli/article/details/109861867"}, "/soft/maixpy3/zh/usage/train_AI/information.html": {"title": "深度神经网络（DNN）基础知识", "content": "---\ntitle: 深度神经网络（DNN）基础知识\nkeywords: maixpy, k210, AIOT, 边缘计算\ndesc: maixpy doc: 深度神经网络（DNN）基础知识\n---\n\n\n这里介绍使用 MaixPy AI 相关功能需要了解的知识，让你能够理解后面的内容， 不在本篇中深入介绍。\n\n## 如何解决一个问题--引出机器解决问题\n\n一个问题， 通常分为 **输入** 和 **输出（结果）**\n\n比如： \n坐标系中的一条直线如下， 上面的数据点值是已知的:\n![y=kx+b](./dnn/ykxb.jpg)\n\n现在提问，假如数据点规律不变， 输入一个 x 坐标 20, y 的值是多少？\n按照大家的知识，都知道这是一个一元一次方程(`y = kx + b`能解决的， 带入两个点的值，算出方程为`y = 3x + 10`, 那么当 `x=20`, `y` 的值为`70`， 于是输入是`20`, 输出是`70`。\n\n这里就是 输入(`20`) + 算法（一元一次方程） = 输出（`70`）， 这就是我们在解决一个问题时的基本方法， 所以关键就是找到这个符合这条线段上数据点规律的一个算法。\n\n人类很强大，会从这些数据中归纳总结学习，最终得到了这个算法（方程），然后其他的人直接使用这个算法就可以快速用于解决同类问题，那么，有没有一种方法， 让机器自动去寻找这个算法呢？\n\n\n## 如何让机器总结出算法\n\n要让机器自动总结出算法，即机器学习（ML，Machine Learning）， 我们先看看，人类是如何得到这个算法（方程）的。\n\n* 步骤1： 首先，有大量数据点，然后人类根据这些数据点发现了直线都符合`y = kx + b`这个适应所有直线的算法, 但是发现，这里面有两个未知数`k`和`b`, 这就是适应任何直线的参数\n* 步骤2： 然后具体的是什么样的直线，因为方程有两个未知数，即参数，将实际的两个数据点带入这个方程，得到了`k = 3`和`b = 10`\n* 步骤3： 然后我们用在步骤2中没有用到的在线上的数据点，去试试这个算法（方程）是否正确，最终发现都验证正确\n* 步骤4： 然后要通过`x`的值知道其它的点的`y`的值，只需要代入`y = 3x + 10` 即可\n\n\n那么，机器学习是不是也可以利用这个步骤来做呢？\n\n* 我们认为地设计一个算法结构， 加入我们碰巧直接设计成了`y = kx + b`， 我们给具体的直线留下了两个参数，我们暂且称呼这个结构叫 **模型结构**，因为有未知参数，我们称之为未训练的模型结构。其中`x`称为**输入**, `y`称为**输出**\n\n* 现在，我们将我们这条直线的的几个点代入到这个方程，  我们称这个过程为 **训练**，得到`y = 3x + 10` 这个算法， 已经没有未知参数了， 我们现在称它为**模型** 或者 训练好的模型，其中`k b`是模型内的参数，`y = kx + b`是这个模型的结构。 而带入训练的数据点，就叫做**训练数据**，它们的统称就叫**训练数据集**\n\n* 然后，我们使用几个在 训练 过程中没有用到的在线段上的数据点作为输入，代入这个模型进行运算，得到结果，比如 `x = 10`, 得到`y = 40`, 然后对比输出值是否与预期相符，这里我们发现`x = 10, y = 40` 确实是在图中这条直线上的， 并且训练时没有使用这个点，说明我们得到的模型在此次核验中通过，这个过程叫 **验证**， `x = 10, y = 40` 这个数据叫验证数据。 如果我们用多组数据去验证这个模型， 这些数据的统称就叫**验证数据集**\n\n* 现在， 我们获得了一个**模型**，并且用**验证数据集**对这个模型进行了验证，貌似也是很准确了，那我们就可以假设这个模型基本满足了我们以后有一个`x`， 要求着图中线上任意一点的`y`值，都可以输入`x`给出这条直线上对应点的`y`坐标。 这个过程我们其实是在**使用模型**了，这个过程称之为**推理**\n\n其实这就算是机器学习了， 我们人类需要的事就是设计`y = kx + b`这个结构，以及给出**训练数据集**和**验证数据集**，经过**训练**和**验证**得到一个我们认为可用的模型，然后使用`输入 + 模型`就可以得到认为的正确`输出（结果）`了。\n\n\n\n## 什么是深度神经网络？\n\n深度神经网络（DNN）是机器学习（ML）领域中的一种技术。\n\n前面说了一个比较简单的例子， 根据一条直线数据来预测直线上的任何一个点， `y = kx + b`这个结构是人为设计的， 很简单，当用于复杂的数据，发现它就不适用了，比如“这张图片里面是球还是玩具”\n\n![小球](./dnn/ball.jpg) ![玩具](./dnn/toy.jpg)\n\n前面为了模型能够存下一条直线的信息， 用了结构`y = kx + b`，直线的特征都存在模型里面了。\n现在用来存一张图的特征，光是`y = kx + b`这个线性结构， 以及`k 和 b`两个参数显然无法满足了， 需要设计一个更好的结构， 这时 **神经网络** 就出现了， 一种网状结构，能更好地记住图片的特征信息， 而这个网状结构又是多层的，也就是有深度的，所以称之为深度神经网络（DNN， deep neural network）， 所以说 DNN 是一种网络结构，是为了实现机器学习的一种手段。 每一层由多个节点组成， 如下图， 一个 DNN 包含了 **输入层**， **隐藏层**， **输出层**， 这里隐藏层由三层组成（`A[1], A[2], A[3]`层），但是统称隐藏层：\n\n![深度神经网络](./dnn/dnn.jpg)\n\n**输入层**：\n图中就是一个深度神经网络结构， `x` 是输入， 比如`x`这里可以是图片, 输入有多个节点，每个节点可以是一个像素点值， 这里输入层画了 7 个节点， 加入我们有一张图片是 `10 x 10`的分辨率，则输入层共需要 `100` 个节点。\n这里输入层是一个一维结构，实际情况可能有多维结构， 比如输入如果是一张灰度图片，分辨率`3x3`，这其实是一个二维结构，即两行两列的矩阵（关于矩阵的概念请自行学习，或者暂且理解成二维数组），比如：\n```\n[[109  138  110]\n [220  37   166]\n [32   243  67]\n]\n```\n每个像素点的值取值范围∈[0, 255]，然后我们将其平铺后变成共 9 个数据的一维数组给输入层\n```\n[109 138 110 220  37 166  32 243  67]\n```\n\n> 另外， 一般也会将输入层的值归一化到范围`[0, 1]`\n\n如果是一张彩色图片，那就是三维，即`高、宽、颜色通道`，颜色通道比如`RGB`三个颜色通道，即，输入有形状（包含了维度和每个维度的数据数量），比如上面的一维输入形状为`(9)`，其它图像通常以`(高，宽，通道数)`来表示形状，比如`(10, 10, 3)`表示分辨率`10 x 10`， 并且有三个颜色通道， 比如`RGB`。\n\n这里为了入门好理解，原理只介绍一维的情况\n\n\n**输出层**：\n`y` 是输出，这里输出有两个值，你可以理解成就是 MaixPy 的两个浮点值的 `list` `[Y1, Y2]`， `Y1`是`是小球的概率`，值∈[0, 1], `Y2`是`是玩具的概率`。 所以最终我们使用这个模型，  就是给它一张图片， 机器按照这个模型规定的结构和算法进行计算后得到一个 `list`， 我们根据这个输出的值就知道图中是什么东西了。\n\n**隐藏层**:\n连接输入层和输出层的隐藏层，以及中间的连接，负责了将输入数据推算成合理的输出值。\n\n\n## 中间休息，总结\n\n到现在为止， 你知道， **模型**是什么：就是一组数据结构，保存了一个网络的形状，以及里面的参数， 通常，这个模型的数据可以被保存成文件，比如`.h5 .tflite .kmodel`等文件，都是用来阐述这个模型的形状结构和参数，只不过是不同软件使用。\n人们只需要设计模型结构以及参数，用来解决一类问题，比如常见的物体分类， 比如就是上面说的区分一张图里面是小球还是玩具。\n这个模型里面有很多参数，具体在需要识别物体的时候，使用已知分类的数据集让机器自动训练得出一套合适的模型参数。\n然后我们就可以输入数据，让通过模型推理出来输入的数据时什么类别了。\n\n所以， 如果我们不需要训练模型，直接使用别人训练好的模型，只需要：\n* 确认需求，找到现成的模型，因为模型已经是训练好的了，输入和输出的形状的含义都已经定了\n* 确认模型的输入形状，比如模型输入分辨率`10x10`的彩图，则使用时需要将符合要求的图片传个输入层\n* 确认输出层的含义，比如前面说的识别小球和玩具，最后输出是分别代表是该物体的概率的 list， 比如 `[0.9, 0.1]`, 第一个值代表是小球的概率，那我们就知道这张图里有 90% 的概率是小球， 只有 10% 的概率是玩具\n* 将模型放到推理程序进行运行。 具体用什么程序先不着急，会在下一章介绍\n\n到这里，应该大致上明白了以下东西：\n* 什么是机器学习\n* 什么是深度神经网络（简单概念）\n* 模型是什么\n* 什么是输入层，输出层，在上面举例的分类应用中分别表示什么含义，层形状是什么样的\n* 到此为止，我可能还不知道什么是模型训练\n* 如果我需要一个模型，我知道如何确认需求\n\n所以，**如果你只希望能够使用模型，不需要训练，到此即可**， 也不需要知道模型有些什么具体的东西，你就把它当成一个**黑盒工具箱**使用即可。 如果想要更深的了解，请继续看下面的内容。\n\n\n\n## 继续：深度神经网络（续\n\n既然设计了多层设计，那我们继续深入：\n\n**数据流** ， **权重**， **偏置**:\n在模型进行推理时，数据从输入层流动到输出层，就是这些网状箭头的方向（第三节网状图），每个箭头前一层到后一层的计算可以用一个熟悉的公式:`y = wx + b`, 称`w`为**权重**(weight), `b`为**偏置**（bias）, 注意是每个箭头都有一个单独的`w, b`, 也就是说后一层节点的值等于前一层节点经过这个公式计算过后的值， 后一层的节点有多个前一层节点指向，那就等于所有前一层节点的值经过这个公式计算后的值的和。\n就这样经历了无数次运算后，结果终于在输出层以一个值的形式出现了，整个推理也就完成了\n\n**激活函数**：\n\n上面的模型虽然可以通过输入得到结果，但是会发现，所有层计算都是线性函数，那么不管有多少层，整体其实还是一个线性函数，即`y0 = w1x + b1` + `y = w2y0 + b2` ==> `y = w2(w1x + b1) + b2` ==> `y = w2w1x + w2b1 + b2`, 其实还是一个线性函数，那么多层的意义就没有了，于是我们需要在中间加入非线性函数，让网络内部更加复杂一点， 于是就在每个节点上做手脚， 在每个节点输出数据前，先对其用一个非线性函数运算，比如`sigmod`或者`relu`函数，别听到名字害怕，其实很简单，看下图, 总之就是 x 和 y 不成线性关系：\n![sigmod](./dnn/sigmod.jpg) ![relu](./dnn/relu.jpg)\n\n即到现在为止， 除了输入层，所有节点输出的值都需要经过`Sigmod(∑(Wn * x + Bn))`, 输出一个浮点数值\n\n**softmax**:\n\n输出层在最后输出的时候，因为前面的运算，值的范围不是很统一，虽然我们可以同过比大小，值最大的即认为是答案，但是为了统一而且可以直观地知道每个类别的可能性（另外也为了训练的准确性，这里不讲），正如前面讲到，我们最后输出的一个类别的概率，取值范围∈[0, 1]， 且所有输出的值和为`1`，所以在输出层后面对输出层的所有值进行处理，公式为\n![softmax](./dnn/softmax.jpg)\n\n到此，从输入到输出的推理过程就结束了\n\n## 深度神经网络训练\n\n前面简单介绍了深度神经网络的结构组成， 以及从输入层到输出层的正向过程，在我们使用模型时，就是这个正向过程。\n那么，模型定好了，里面的参数（比如`w,b`）都是随机的值，怎么让它自动训练得到模型中参数的值呢？ 在前面我们讲到， 使用一些我们已知结果的数据输入，来得到参数，同样地，这里我们也输入已知结果的数据，得到第一次的输出结果\n\n**判定输出正确性(accuracy)（或者说误差/loss）** 和 **损失函数**：\n\n在输出层得出结果，比如得到了`[0.6, 0.4]` 代表是小球的概率`0.9`, 是玩具的概率`0.1`, 但是因为是已知答案的数据， 实际正确答案是`[1.0, 0.0]`, 这明显不符合要求。\n所以我们得出正确答案和推算的答案的误差为： `[0.4, -0.4]`, 但是发现一个问题就是这个误差值的范围不太好看，要是误差的取值范围∈`[0, ∞]` 就好了。 在高中数学中有个函数`y = log10(x)`, 坐标图如下：\n![log10](./dnn/log10x.jpg)\n发现`x`取值∈`[0, 1]`时， `-y`的取值刚好∈`[0, ∞]`， 而我们的输出结果也刚好∈`[0, 1]`！ 所以，我们直接这样计算误差： `error = -log10(输出)`， 也就是输出越接近`1`，误差就越接近 `0`，这种方法称之为`交叉熵损失（CEE, Cross Entropy Error)`， 除了这种方法还有其它的比如均方误差（MSE，Mean Squared Error）等\n\n至此，我们知道了现在结果和实际结果的误差\n\n**误差的反向传播** 和 **参数优化（权重更新）**：\n因为模型的参数还不符合我们的预期， 那我们需要对参数进行修正，我们使用反向传播的方式。\n前面我们得出了误差， 因为参数不够正确， 我们用这个误差去修改模型中的参数，来达到微调模型内参数的效果。 就好像你在开一个水龙头， 水打了（即误差大了），就把开关拧紧一点，小了就拧松一点，对其做调整。\n就像我们正向推算一样，这次换成了反向，从后往前，可以得到在每个节点处的误差值，然后再根据一定的学习率去更新模型内参数。这里暂时就不仔细展开讲了。\n\n总之，经过一轮反向的调整参数之后，得到了新的模型\n\n**衡量模型好坏：训练集误差和验证集误差**：\n\n我们使用训练数据集里面的数据反复去进行正向推理得出误差，然后反向调整这个过程，在使用完训练数据集后，可能会得到误差比较小，但是这只能说明这个模型对这批数据来说比较准确，换一些新的数据可能就不准确了，所以我们要用一些训练集里没有的数据去**验证**模型的效果：\n我们使用 **验证数据集** 去正向推算，得到误差，因为验证数据集没有参与训练，也就是说现在模型的参数和验证数据集没有任何关系，我们用这个得到的误差来恒定这个模型的好坏，误差越小则认为效果越好\n\n**多次迭代**：\n\n如果将所有数据集训练完了，发现误差依然很大，那么可以用多次训练的方法来继续训练，即**多次迭代**，每次迭代完成后都用 验证数据集 去验证效果如何， 如果训练集的误差和验证集的误差都足够小，我们就可以暂且认为模型已经有不错的效果了。\n\n**测试集**：\n这时，我们就可以用又一批新的数据去测试我们的模型效果如何，因为这是全新的数据，没有参与到训练也没参与到验证（即确定什么时候停止训练），理论上更有公信力。如果测试误差较小，那么训练就算成功了\n\n**优化训练**：\n如果最终效果不太好， 有很多地方可以调整， 比如\n* 训练迭代的次数，并不是越多越好，过多的在一批数据集上训练可能导致模型只对这批数据有效，泛化能力不够， 也就是**过度拟合**\n* 每次训练的学习率也可以调整\n* 检查数据集，是否有一些影响分类的数据存在\n* 优化网络结构，不管是输入输出还是内部结构和参数，根据不同的数据和任务可以有更优的设计，也叫**特征工程**\n\n\n## 说在最后\n\n到这里，应该大致上明白了以下东西：\n* 什么是机器学习\n* 什么是深度神经网络\n* 模型是什么\n* 什么是输入层，输出层，在上面举例的分类应用中分别表示什么含义，层形状是什么样的\n* 什么是训练，有什么作用\n* 数据训练集，验证集，测试集分别是什么，用在什么地方，需要注意什么\n* 衡量模型好坏的标准是什么\n\n如果还不明白的，可以再仔细理解一遍，或者查阅相关资料，如果你发现有更好的阐述方法，欢迎按照左边目录的文档贡献方法参与贡献\n\n\n## 修改记录\n\n| 日期 | 作者 | 备注 |\n| ---  | ---- | --- |\n| 2020.11.17 | [neucrack](https://neucrack.com) | 初始版本，根据 MaixPy 的需要介绍深度神经网络基本概念，初稿 |"}, "/soft/maixpy3/zh/usage/train_AI/train_resnet.html": {"title": "图像分类模型训练过程", "content": "# 图像分类模型训练过程\n\n| 时间 | 负责人 | 更新内容 | 备注 |\n| --- | --- | --- | :---: |\n| 2022年1月22日 | dianjixz | 编写初稿文档 | 训练教程只能在 Linux 系统中运行，<br>并只能部署到 MaixII-Dock 开发板上运行，<br>文档还需要二次整理 |\n\n> Windows 系统暂不支持！\n> 临时工程文件获取：https://github.com/dianjixz/v831_restnet18\n\n\n图像分类主要采用 resnet18 网络结构，使用 Pytorch 框架进行搭建，再将经过**训练、转换和量化**后的模型文件部署到 MaixII-Dock 上。\n\n## 准备\n\n### 获取训练工程文件\n\n可以在 GitHub 上下载压缩包或者是通过 git 克隆到本地\n\n    git clone https://github.com/dianjixz/v831_restnet18\n\n工程文件结构介绍：\n```shell\n├── classes_label.py                            #分类标签\n├── classifier_resnet_test.py                   #测试程序\n├── classifier_resnet_train.py                  #训练程序\n├── convert.py                                  #模型转换程序\n├── convs_data                                  #存放经过 onnx2ncnn 转换之后的模型文件\n├── data                                        #训练数据文件夹\n├── out                                         #训练模型输出文件夹，每隔一定训练周期输出一个模型参数\n└── test                                        #测试数据集文件夹（不分类别）\n```\n\n### 数据集的制作与使用\n\n使用手机或者 MaixII-Dock 来对物品进行拍摄，将拍摄的图片进行导出，并按照类别分类到文件夹中，文件夹名为类别的名字。图片最好是以数字进行命名，这样可以减少一些奇怪的 BUG。\n\n> 注意！数据集中图片的分辨率需要是 224*224 ，有能力的可以自行修改源码来适配别的分辨率，我们并不提供这样的服务！\n\n数据集 data 文件夹结构\n~~~ c\n── mouse\n│   ├── 1.jpg\n...\n├── sipeed_logo\n│   ├── 2.jpg\n...\n...\n~~~\n\n将整理好的数据集，复制到训练工程文件中的 data 文件夹下，将 classes_label.py 里面的 labels 值修改成 data 下的文件夹名字。\n\n- 例如：data文件夹内为\n![resnet-data](./dnn/resnet-data.png)\n则需要将 `classes_label.py` 修改成\n    ```python\nlabels = [\"mouse\",\"sipeed_logo\"]\n    ```\n\n## 训练:\n\n训练的相关参数，在工程中的 classifier_resnet_train.py 文件里面，可以根据自己的需要进行修改，不懂怎么修改的，就保持默认就好了\n\n~~~ python\ndataset_path = \"data\"\t\t#训练集的路径\nval_split_from_data = 0.1 # 10%\t\t#学习率\nbatch_size = 4\t\t\t\t\t\t#训练批次\nlearn_rate = 0.001\t                #学习率\ntotal_epoch = 100\t\t\t\t\t#训练循环，总共需要训练100个循环\neval_every_epoch = 5\t\t\t\t#每个循环训练次数\nsave_every_epoch = 20\t\t\t\t#多少个循环保存一次\ndataload_num_workers = 2\t\t\t\ninput_shape = (3, 224, 224)\t\t\t#输入尺寸\ncards_id = [0]\t\t\t\t\t#使用的训练卡\nparam_save_path = './out/classifier_{}.pth'\t#参数保存路径\n~~~\n\n开始训练，在 resnet18 工程文件夹目录下运行\n\n~~~ bash\npython classifier_resnet_train.py\n~~~\n\n训练完成后，会在工程目录下生成一个 out 文件夹，在 out 文件夹下存放着训练过程中保存的训练参数。\n\n例如：\n~~~ bash\n.\n├── classifier_99.pth             #训练过程中保存的参数\n├── classifier_final.pth          #训练完成后保存的参数\n└── classifier.onnx               #生成的onnx深度学习网络文件\n~~~\n\n## 测试  \n\n准备好你的测试图片，注意和数据集中的图片尺寸一样。新建一个 test 目录，并放在该目录下。   \n\n运行 `python classifier_resnet_test.py images_folder_path model_param_path` 命令进行测试。\n\n在该命令中会调用用户环境中的 ncnn 工具，请确保[训练环境](./ready.html)已经搭建好了。  \n\n模型测试并生成 ncnn 模型文件：  \n~~~ bash \npython3 classifier_resnet_test.py ./test ./out/classifier_final.pth\n~~~\n\n\n运行完测试后，会生成 ncnn 模型和 ncnn 模型参数。\n~~~\nnihao@nihao:~/work/work_space/v831_restnet18/out$ ls\nclassifier_2.pth  classifier.bin  opt.bin\nclassifier_1.pth  classifier.onnx  opt.param\nclassifier_3.pth  classifier.param  opt.table\n~~~\n\n在线 maixhub 量化为 int8 模型才可以被使用。\n\n## 模型转换 \n\n生成的 ncnn 模型此时还无法被 v831 直接使用，需要使用 [MaixHub](https://maixhub.com/modelConvert) 在线模型转换工具进行量化模型，转换成 MaixII-Dock 可以直接使用的 awnn 模型\n将一下内容整合到一个压缩包中：\n- 创建为 images 的文件夹，内容一些较正图片，可考虑直接采用训练中的验证数据集，并务必保证矫正时图像的预处理方式与训练和部署时一致。（数量在50张左右）\n- 将训练结束之后得到的模型文件一个 xxx.bin 和一个 xxx.param。\n- 压缩包内文件结构如图：\n    ![resnet-zip](./dnn/resnet-zip.png)\n> 注意：确保 images 目录内没有混入其他文件，否则会导致模型量化错误。\n\n注册登录并激活账号后,上传你的压缩包等待模型转换任务完成。\n\n## 模型部署  \n\n等待模型转换完成,下载转换好的模型文件。将得到的 *.param 、 *.bin 和训练工程中 classes_label.py 文件上传到 MaixII-Dock 上。\n\n将以下代码复制到开发板上即可使用\n\n~~~ python\nfrom maix import nn, display, camera, image\nfrom root.classes_label import labels    #分类标签,需要替换\nimport time\n\nmodel = {\n    \"param\": \"/root/restnet18_int8.param\",        #模型文件,需要替换成自己训练的模型路劲\n    \"bin\": \"/root/restnet18_int8.bin\"\n}\noptions = {\n    \"model_type\":  \"awnn\",\n    \"inputs\": {\n        \"input0\": (224, 224, 3)\n    },\n    \"outputs\": {\n        \"output0\": (1, 1, len(labels))           \n    },\n    \"first_layer_conv_no_pad\": False,\n    \"mean\": [127.5, 127.5, 127.5],\n    \"norm\": [0.00784313725490196, 0.00784313725490196, 0.00784313725490196],\n}\n\nprint(\"-- load model:\", model)\nm = nn.load(model, opt=options)\nprint(\"-- load ok\")\n\nwhile True:\n    img = camera.capture()\n    AI_img = img.copy().resize(224, 224)\n    t = time.time()\n    out,  = m.forward(AI_img, quantize=True)\n    t = time.time() - t\n    print(\"-- forward time: {}s\".format(t))\n    msg = \"{}%: {}\".format(int(out.max() * 10), labels[out.argmax()])\n    print(msg)\n    img.draw_string(0, 0, msg, color = (255, 0, 0))\n    display.show(img)\n~~~\n\n运行效果：  \n![](./dnn/restnet_img.jpeg)"}, "/soft/maixpy3/zh/usage/train_AI/ready.html": {"title": "Linux 本地训练环境搭建", "content": "# Linux 本地训练环境搭建\n\n| 时间 | 负责人 | 更新内容 | 备注 |\n| --- | --- | --- | :---: |\n| 2022年1月22日 | Rui | 编写初稿文档 | ------------------------------------- |\n\n> 现在只能在 Linux 系统上进行训练\n\n由于训练需要用到显卡，关于安装显卡驱动、CUDA、CUDNN、OpenCv 请自行百度查阅安装，本文不做详细说明。本文章是在 Ubuntu 环境下，使用英伟达 GTX1080 显卡所编写完成的，请以该环境为参考。（ADM 显卡或者无显卡的，可以使用 CPU 进行训练）\n\n## 安装 Python 软件包\n\n本地训练时使用 Python 进行搭建的，需要在电脑上安装 Python，请自行[百度 Python ](https://www.baidu.com/s?ie=UTF-8&wd=python)如何安装。我们所有的训练工程都是使用 PyTorch 框架进行搭建 \n\n需要安装以下 Python 软件包：\n- PyTorch ：基础训练框架。\n- torchsummary ： 格式化打印模型信息。\n- pycocotools : 数据集相关工具\n\n### 安装 PyToch\n\n进入 Pytorch 下载帮助[网页](https://pytorch.org/get-started/locally/)，根据自己所用系统的环境情况，选择对应的 CUDA 版本和安装包的类型，这里所选用的是 CUDA 10.2、Linux 系统、稳定版、pip包（30 系列显卡只能使用11.2以上的版本）\n\n    pip3 install torch torchvision torchaudio\n\n\n### 安装 torchsummary\n\n然后再通过 pip 进行安装 torchsummary\n\n    pip3 install torchsummary\n\n\n### 安装 pycocotools\n\n进行目标检测模型训练，需要安装 pycocotools 软件包\n\n    pip3 install pycocotools\n\n##  onnx2ncnn 模型转换工具\n\nPyTorch 不能直接将模型导出成 ncnn 格式，需要使用 onnx2ncnn 转换工具进行转换，需要用户自行去编译出对应的可执行文件,具体的编译步骤如下\n\n1. 安装编译环境所需要用到的软件\n    ```shell\n    sudo apt install build-essential git cmake libprotobuf-dev protobuf-compiler libvulkan-dev vulkan-utils libopencv-dev\n    ```\n2. 需要先拉取整个 ncnn 转换工具的工程，在任意的文件夹位置中\n    ```shell\n    git clone https://github.com/Tencent/ncnn.git\n    ```\n3. 工程编译初始化\n    ```shell\n    cd ncnn\n    git submodule update --init\n    ```\n4. 开始编译\n    ```shell\n    mkdir build\n    cd build\n    cmake -DCMAKE_BUILD_TYPE=Release -DNCNN_VULKAN=ON -DNCNN_SYSTEM_GLSLANG=OFF -DNCNN_BUILD_EXAMPLES=ON ..\n    make\n    ```\n    \n编译结束之后，可以在 ncnn/build/tools/onnx 目录下，能得到 **onnx2ncnn** 模型转换工具，执行以下命令添加到系统的环境变量中\n\n    sudo nano ~/.bashrc\n\n打开.bashrc文件之后，将下面这句代码添加到最后一行\n\n```shell\nexport PATH=$PATH:`pwd`/tools/onnx\n```\n\n## 文章参考\n\n* 显卡驱动安装：https://neucrack.com/p/252\n* opencv 多版本共存：https://neucrack.com/p/349"}, "/soft/maixpy3/zh/usage/train_AI/test.html": {"title": "将自己的神经网络部署的到 MaixII-Dock 上", "content": "# 将自己的神经网络部署的到 MaixII-Dock 上\n\n| 时间 | 负责人 | 更新内容 | 备注 |\n| --- | --- | --- | --- |\n| 2022年1月26日 | Rui | 编写文档 | --- |\n\n对于一些自定义的神经网络结构，可以通过 MaixPy3 部署到所支持的开发板上。将边缘检测部署到 MaixII-Dock 为例，讲述一下部署的思路\n\n## 前置知识\n\n进行之前，需要学习神经网络的基础知识，可以通过查看前面的 【[深度神经网络基础知识](./information.html)】 快速的了解一下，想要了解更多可以自行百度神经网络的相关教程\n\n## 边缘检测原理介绍\n\n边缘就是值变化剧烈的地方, 如果对值的变化求导, 则边缘部分就是导数局部最大。但是在图像处理时没有具体的函数让我们求导, 使用卷积运算则可以很好的近似替代。\n\n如下图, 假设左上为坐标原点, 横轴为 x, 纵轴为y, 如下图左上角9个像素点, P(x, y)表示坐标(x, y)的点, 要求P(1, 1)处在x轴的变化率, 则只需将P(2, 1) - P(0, 1) 得到值为0, P(1, 0)处为1-3 = -2, 这个差值即变化率, 类比成导数, 我们就能知道横轴在哪些地方变化率更大。\n\n![](https://neucrack.com/image/1/377/conv.jpg)\n\n上面这种方法我们可以得到横轴的变化率, 这里使用**横轴卷积核**\n\n~~~ python\n[-1, 0, 1],\n[-2, 0, 2],\n[-1, 0, 1]\n~~~\n\n对图像进行卷积运算, 如图中的计算方法, 像素点左右权值取2, 角上的也参与计算,但是权值为1,没有左右边的权值高。这样我们就得到了横轴的变化率图, 即边缘检测图。\n\n注意, 这里是对横轴计算了, 比较的点左右的值变化, 所以实际看到的图像会出现明显的纵轴边缘, 如下图左边\n\n![](https://neucrack.com/image/1/377/vertical_horizontal.jpg)\n\n同理, 上图右边的图使用**纵轴卷积核**\n```\n[1, 2, 1],\n[0, 0, 0],\n[-1, -2, -1]\n```\n得到的纵轴的边缘图。\n\n注意这里用右边减左边, 如果右边的值比左边的小会是负数, 如果我们希望只检测颜色值变大(变白)则可以直接使用, 如果两个变化方向都要检测, 则可以取绝对值. 比如下图左边是没有取绝对值, 右边取了绝对值\n\n![](https://neucrack.com/image/1/377/without_with_abs.jpg)\n\n得到两个方向的图后, 对其进行合并, 对每个像素平方和开方即可\n\n![](https://neucrack.com/image/1/377/final.jpg)\n\n这张图左边是使用 GIMP 的 sobel 边缘检测(垂直+水平)的效果, 略微有点不同:\n\n![](https://neucrack.com/image/1/377/sobel_edge2.jpg)\n\n不同的原因是使用水平和垂直的图平方和开根后, 直接用 `plt.imshow` 显示, 和 GIMP 的处理方式不同\n```python\nout = np.sqrt(np.square(out_v) + np.square(out_h))\nplt.imshow(out)\n```\n简单地直接将值规范到`[0, 255]`就和 GIMP 的图相似了(但不完全一样)\n```python\nout = np.sqrt(np.square(out_v) + np.square(out_h))\nout = out * 255.0 / out.max()\nplt.imshow(out.astype(np.uint8))\n```\n![](https://neucrack.com/image/1/377/sobel_v_h.jpg)\n\n## 定义卷积核\n\n除了上面说了使用两次卷积计算, 也可以用只计算一次的卷积核, 比如:\n```bash\n[-1, -1, -1],\n[ -1, 8, -1],\n[ -1, -1, -1]\n```\n这是对于一个通道(灰度图)来说, 如果要扩充到三个通道(RGB), 卷积核参数就是如下形式\n```bash\n# 全边缘卷积核\nconv_rgb_core_sobel = [\n                        [[-1,-1,-1],[-1,8,-1], [-1,-1,-1],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],\n\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [-1,-1,-1],[-1,8,-1], [-1,-1,-1],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],a\n\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [-1,-1,-1],[-1,8,-1], [-1,-1,-1],\n                        ]]\n```\n\n前面所有介绍的横轴边缘和纵轴边缘卷积核参数形式同理\n\n## 代码实现边缘检测\n\n整个边缘检测的网络模型只有一层卷积核\n\n### 定义网络模型\n\n```python\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 3, 3, padding=(0, 0), bias=False)\n    def forward(self, x):\n        x = self.conv1(x)\n        return x\nnet = Net()\n```\n\n### 定义卷积核参数\n\n```python\nconv_rgb_core_sobel = [\n                        [[-1,-1,-1],[-1,8,-1], [-1,    -1,    -1],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [-1,-1,-1],[-1,8,-1], [-1,    -1,    -1],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [-1,-1,-1],[-1,8,-1], [-1,    -1,    -1],\n                        ]]\n```\n\n### 定义载入权重函数\n\n```python\ndef sobel(net, kernel):\n    sobel_kernel = np.array(kernel,    dtype='float32')\n    sobel_kernel = sobel_kernel.reshape((3,    3,    3,    3))\n    net.conv1.weight.data = torch.from_numpy(sobel_kernel)\nparams = list(net.parameters())\n```\n\n### 输入数据进行处理\n\n加载一张图片\n\n```python\npil_img = Image.open(\"./images/class1_5.jpg\")\ndisplay(pil_img)\ninput_img = np.array(pil_img)\nprint(input_img.shape)\n```\n\n对图片进行归一化处理并转换成 PyTorch 张量\n\n```python\n# 归一化处理\ninput_tensor = (input_img.astype(np.float32) - 127.5) / 128 # to [-1, 1]\nprint(input_tensor.shape)\ninput_tensor = torch.Tensor(input_tensor).permute((2, 0, 1))\ninput_tensor = input_tensor.unsqueeze(0)\nprint(\"input shape:\", input_tensor.shape)\n\n# 转换成 PyTorch 张量\ninput_tensor = (input_img.astype(np.float32) - 127.5) / 128 # to [-1, 1]\ninput_tensor = torch.Tensor(input_tensor).permute((2, 0, 1))\nprint(input_tensor.shape)\ninput_tensor = input_tensor.unsqueeze(0)\nprint(\"input shape:\", input_tensor.shape)\n```\n\n### 进行边缘检测\n\n```python\n# 载入网络权重\nsobel(net, conv_rgb_core_sobel)\n\n# 输入图片到网络中进行处理\nwith torch.no_grad():\n    out = net(input_tensor)   \n    sobel_img_t = out.numpy()[0].transpose([1,2,0])\n\n# 显示输出结果\nplt.figure()\nplt.subplot(1, 5, 1)\nplt.imshow(input_img)\nplt.subplot(1, 5, 2)\nplt.imshow(sobel_img_t)\n```\n\n经过卷积运算后, 前后图如下:\n\n![](https://neucrack.com/image/1/377/sobel_edge.jpg)\n\n注意, 输入值范围如果为`[0, 255]`, 输出值则范围会变化, 以图片形式查看时需要注意加以处理, 这里使用了`plt.imshow(out)`来显示, 这个函数会自动对图像做简单的处理, 才会看起来是黑色背景\n\n## 模型导出"}, "/soft/maixpy3/zh/usage/net.html": {"title": "Python3 网络应用", "content": "---\ntitle: Python3 网络应用\nkeywords: MaixPy3,net, Python3\ndesc: maixpy doc: net\n---\n\n\n| 更新时间 | 负责人 | 内容 | 备注 |\n| --- | --- | --- | --- |\n| 2022年1月17日 | dalaoshu | 编写文档 | 本文讲述用户常问的实际需求所写的经验文，有经验的可以忽略本节内容，至于如何联网、配网请看类似于 [MaixII-Dock 连接网络](http://wiki.sipeed.com/soft/maixpy3/zh/tools/0.MaixII-Dock.html#%E5%A6%82%E4%BD%95%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C) 的产品说明|\n\n## 关于 Python 网络应用的一些常用例子。\n\n因为是通用的 python3 环境，所以关于网络方面的库很多，最终目的都是为了上云。\n\n- [requests](https://github.com/psf/requests)\n\n- [paho.mqtt.python](https://github.com/eclipse/paho.mqtt.python)\n\n在 AIOT 领域中，常用的网络请求接口为 mqtt 和 http ，它们均基于 socket 这个模块提供的 tcp 、udp 实现帮助用户方便进行网络传输数据。\n\n与经典的 TCP 、UDP 相比，HTTP 和 MQTT 则更是符合互联网、物联网特征的传输协议。\n\n例如 HTTP 将网络行为描述成从某个服务器上获取数据的 GET ，将某个数据提交给服务器的 POST 协议描述，意味着用户不需要对此重新设计协议，根据业务逻辑使用就行。\n\n而 MQTT 让用户忽略对服务器的部署和开发，将其作为数据中转服务，将两个设备的链接行为描述成互相通信行为，而非请求服务行为，让用户只需要关注客户端的发送行为即可，而不需要考虑服务端的接收。\n\n简化的背后是需要很多逻辑维持的，同时还存在一些安全隐患问题，如早期的 HTTP 是明文传输，MQTT 是公开通信，如果要商用就需要配置相关的安全功能。\n\n## HTTP 有什么用？怎么用？\n\n> 如果你想要获取网页的数据，或是向服务器提交数据，那 HTTP 就是你最好的朋友。\n\nRequests 唯一的一个非转基因的 Python HTTP 库，人类可以安全享用。\n\n**警告**：非专业使用其他 HTTP 库会导致危险的副作用，包括：安全缺陷症、冗余代码症、重新发明轮子症、啃文档症、抑郁、头疼、甚至死亡。\n\n看吧，这就是 Requests 的威力：\n\n```\n>>> r = requests.get('https://api.github.com/user', auth=('user', 'pass'))\n>>> r.status_code\n200\n>>> r.headers['content-type']\n'application/json; charset=utf8'\n>>> r.encoding\n'utf-8'\n>>> r.text\nu'{\"type\":\"User\"...'\n>>> r.json()\n{u'private_gists': 419, u'total_private_repos': 77, ...}\n```\n\n[参见 未使用 Requests 的相似代码.](https://gist.github.com/kennethreitz/973705)\n\nRequests 允许你发送纯天然，植物饲养的 HTTP/1.1 请求，无需手工劳动。你不需要手动为 URL 添加查询字串，也不需要对 POST 数据进行表单编码。Keep-alive 和 HTTP 连接池的功能是 100% 自动化的，一切动力都来自于根植在 Requests 内部的 urllib3。\n\n更多请看该文档[Requests: 让 HTTP 服务人类](https://docs.python-requests.org/zh_CN/latest/)。\n\n## MQTT 有什么用？怎么用？\n\n> 如果没有服务器也想要一对多采集数据，或是许多设备彼此建立通信，那 MQTT 就是你最好的朋友。\n\n使用 MQTT 服务需要一台运行 MQTT 的服务，网上有许多公共服务器供你使用，而对于任何一台机器，只要是运行 python 代码，只会发生 订阅主题 和 推送主题 两个逻辑，这个主题就是一间房，在这间房的所有连接都会收到关于这个主题的信息，它就像一个聊天室，设备加入了，可以收到所有通知。\n\n### 如何推送？\n\n向公共服务 mqtt.eclipseprojects.io 发送主题 `paho/test/single` 内容为 `boo123` 的消息。\n\n```python\n>>> import paho.mqtt.publish as publish\n>>>\n>>> publish.single(\"paho/test/single\", \"boo123\", hostname=\"mqtt.eclipseprojects.io\")\n>>>\n```\n\n### 如何订阅？\n\n那发出去的数据如何收到呢？看下图代码示例\n\n```python\n>>> import paho.mqtt.subscribe as subscribe\n>>>\n>>> topics = ['paho/test/single']\n>>>\n>>> m = subscribe.simple(topics, hostname=\"mqtt.eclipseprojects.io\", retained=False)\n>>> m.topic\n'paho/test/single'\n>>> m.payload\nb'boo123'\n>>>\n```\n\n这两个逻辑，在任何设备上都是一样的代码，用户不需要写服务端的代码，而服务端的任务就是负责转发数据和保护整个传输内容的安全、可靠性。\n\n> 关于 MQTT 的官网 [MQTT: The Standard for IoT Messaging](https://mqtt.org/)。"}, "/soft/maixpy3/zh/guide/feedback.html": {"title": "如何反馈问题", "content": "---\ntitle: 如何反馈问题\nkeywords: MaixPy, MaixPy3, Python, Python3, MicroPython\ndesc: maixpy doc: 如何反馈问题\n---\n\n在没开始使用 MaixPy3 开源项目之前，建议先看一下如何反馈问题，免得之后使用过程中出了问题，不知道在哪反馈，也不知道在哪获取解决方法。在开源项目上反馈的问题通常需要一些时间才能得到解决。\n\n## 找到反馈的地方\n\n按问题的严重性和客户的重要性依次排列反馈的地方，注意商业支持邮件不对个人用户开放，勿扰。\n\n- MaixPy 开源群组\n  - QQ 交流群 878189804 / 1129095405 / 756313869 等\n  - [telgram-sipeed](https://t.me/sipeed)\n- 开源社区\\论坛\\官博等\n  - [bbs.sipeed.com](https://bbs.sipeed.com)\n  - [twitter-sipeedio](https://twitter.com/sipeedio)\n- MaixPy3 开源项目的 issue 区\n  - [github.com/sipeed/MaixPy3/issues](https://github.com/sipeed/MaixPy3/issues)\n- 商业支持邮件\n  - 从 [sipeed.com](https://sipeed.com) 底部获取。\n\n如果是交流群反馈可能会被聊天消息刷下去，建议发到社区或 issue 保证问题可以被记录和得到解决，因为在聊天群组反馈的问题可能不会被解决。\n\n## 正确的反馈问题\n\n在遇到问题之前，请浏览一下（项目、社区）是否有相关的问题反馈记录，再把你遇到的问题，操作，环境，现象都写下来。\n\n- 遇到了什么问题？\n- 你做了什么操作？要有截图或代码！\n- 你在什么系统环境下进行的操作？\n- 期望的现象与实际的现象有什么不符？（有图有真相！）\n\n## 尊重开源开发者\n\n请反馈问题的小白用户们尊重每一位参与开源的开发者，参与其中并没有为此获取利益，仅仅是出于对技术的热爱和分享，以及展现自己技术实力。\n\n> *不要任性，不要耍脾气，更不要玻璃心，要认真的虚心学习！！！！*"}, "/soft/maixpy3/zh/guide/project.html": {"title": "项目使用说明", "content": "---\ntitle: 项目使用说明\nkeywords: MaixPy, MaixPy3, Python, Python3, MicroPython\ndesc: maixpy doc: 项目使用说明\n---\n\n## 认识 MaixPy3 项目\n\n请点此进入 [MaixPy3](https://github.com/sipeed/maixpy3) 的开源项目仓库。\n\n## 如何安装使用？\n\nMaixPy3 是通过 pip 安装得到的，适用于 Python3 环境，请查阅左侧目录的 [如何安装](../install/index.html) 。\n\n> MaixPy3 在安装的时候可能会依赖一些需要编译才能安装的 Python 包，这需要通过镜像内置依赖包来解决这个问题。\n\n## 支持哪些开发工具？\n\n推荐使用 jupyter 或 VSCode 进行开发，使用串口终端也可以直接进行粘贴运行。\n\n请查阅左侧目录的 [常用的开发工具](../tools/mobaxterm.html) 进行安装与配置。\n\n## 在哪获取示例代码呢？\n\n将会使用 jupyter 文档提供所见即所得的结果。\n\n请查阅左侧目录的 [一些使用案例](../usage/00_hello_world.html) 完成基本的使用。\n\n## 关于内置模块的说明？\n\n对于一些底层实现的模块 API 说明，会统一放到【内置模块说明】当中。\n\n## 其他？\n\n更多的就自己探索吧。"}, "/soft/maixpy3/zh/guide/participate.html": {"title": "如何参与项目", "content": "---\ntitle: 如何参与项目\nkeywords: MaixPy, MaixPy3, Python, Python3, MicroPython\ndesc: maixpy doc: 如何参与项目\n---\n\n如果你对开源社区文化很感兴趣，也想一同加入其中学习和分享，那了解 MaixPy3 开源项目可能是一个好的开始。\n\n## 什么是开源文化\n\n> 下文内容选自 [什么是开源文化？](https://www.cnblogs.com/hdwl/archive/2013/04/23/3037549.html)\n\n所谓“开源”，就是开放资源（Open Source）的意思。不过在程序界更多人习惯把它理解为“开放源代码”的意思。\n\n在计算机发展的早期阶段，软件几乎都是开放的，任何人使用软件的同时都可以查看软件的源代码，或者根据自己的需要去修改它。在程序员的社团中大家互相分享软件，共同提高知识水平。这种自由的风气给大家带来了欢乐，也带来了进步。\n\n“自由软件”的英文是“Free Software”，这不免为许多人所误解，人们经常把它和“免费软件”连系在一起，免费的恰恰都是些低级的，这使得自由软件蒙上了一层阴影。于是大家决定给自由软件一个更易理解的别名“开源软件”。开源一词则由此得来。 \n\n所以，开源即是自由的化身。它讲述了一种公开的、自由的精神。软件开源的发展历程 ，为我们软件行业以及非软件行业的人都带来的巨大的参考价值。\n## 可以如何参与开源项目？\n\n以 MaixPy3 为例，如果你对此项目感兴趣，想参与到其中，除了一般的开发活动，您的关注（给个 Star ）已经是最好的开源项目参与方式了，此外参与项目的方法还可以是通过提意见、提 bug 、反馈问题、修改文档说明、修改源代码并提交等等方式，值得注意的是，你要尊重这些开源项目所选取的开源协议。\n\nMaixPy3 开源项目采用 MIT 许可证。\n\n- 您可以使用复制和修改软件。\n- 您可以免费使用软件或出售。\n- 唯一的限制是，它是必须附有MIT授权协议。\n\n您可以在 [MaixPy3](https://github.com/sipeed/MaixPy3) 上公开获取它的项目源码，可以任意修改或提交，也可以学习它是如何实现的或是软件设计。\n\n您也可以在其他开源社区里公开的讨论和交流这个事物，开源总是期望用户能够提出自己的想法和宝贵的建议。\n\n若是有经验的开发人员，还可以阅读【MaixPy3开发文档】尝试提交或适配不同平台的软件。\n\n## 附录：GNU/Linux 和开源文化的背后\n\n> 下文内容选自 [GNU/Linux与开源文化的那些人和事](https://linux.cn/article-6270-1.html)\n\nGNU/Linux 来了，虽然没成为大多数人电脑里的系统，但每个人都离不开它。诸多互联网公司的服务器里都跑着 GNU/Linux ，名单不完全确认，Google、Facebook、淘宝、百度、腾讯、小说阅读网等等。\n\n大多人使用的安卓手机的系统也是基于 Linux 内核。\n\nGNU/Linux 的繁荣有宏伟的规划，有个人的努力，也有很多无形的力量在起着作用。\n\n没有 Unix 就没有 GNU/Linux ，是 Unix 给予了伟大的启示。\n\n没有 C 语言就有没有 GNU/Linux ， C 语言简单，优雅，介于高级语言和低级语言之间，开发系统软件的首选编程语言。\n\n没有一系列 Unix 标准的制定就没有 GNU/Linux 的繁荣。标准就是“车同轨、书同文、统一度量衡”，秦始皇可算最早的标准制订者。遵循 Posix 标准为 GNU/Linux 发展铺平了道路。\n\n没有互联网就没有 GNU/Linux ， GNU/Linux 不是一个人在开发，是全球无数人协作的结果。如果没有互联网实在不可想象。当然， GNU/Linux 也反哺了互联网，无数互联网公司采用GNU/Linux搭建服务器， GNU/Linux 也促进了互联网的繁荣。\n\n还有 GNU/Linux 诞生之前就开发开源项目的人和组织。Larry Wall因为懒，整天被报表搞得焦头烂额，发布了 Perl 语言；高德纳教授因为对排版工人不满意，十年时间停止重要工作，发明了伟大的排版软件 TeX ； Guido 为了打发圣诞节的无聊，编写了新的脚本语言 Python ……\n\n版本管理软件对 GNU/Linux 的发展和开源文化运动也功不可没。 Linux 内核开发起初使用的是商用版本管理软件，某天 Linus Torvalds 先生不开心了，就自己动手搞了一个。他好取自嘲调侃的名字，命名为 Git，意为没什么用的东西。\n\nGit 可不是没什么用，太好用了，Linux 内核源码从此都用 Git 管理。Git 免费、开源， Git 成就了一家伟大的网站 github.com ，伟大的源码项目托管网站。很多开源项目纷纷把源码托管到了 Github 上。"}, "/soft/maixpy3/zh/api/maix/nn.html": {"title": "MaixPy3 nn模块(maix.nn)", "content": "---\ntitle: MaixPy3 nn模块(maix.nn)\nkeywords: MaixPy3, maix.nn, MaixPy3运行模型, maix.nn API\ndesc: MaixPy3 nn模块 API文档, 以及使用说明\n---\n\n>! API 仍处于非完全稳定状态, 可能在未来会有小幅改动, 如果你遇到了语法错误， 记得回来看更新哦~\n\n## maix.nn 基本使用介绍\n\n* 准备模型\n\n比如从 maixhub 下载, 这里以边缘检测模型为例, 先[下载模型](https://maixhub.com/modelInfo?modelId=24)(需要先注册登录)\n\n* 准备一张 `224 x 224` 分辨率的图像, 比如这里放到了开发板文件系统的`/root/test.png`位置\n\n* 运行代码, 将下面的代码保存到开发板的`test_model.py`中, 然后运行`python test_model.py`\n\n其中最重要的就是`m = nn.load`和`m.forward()`两个函数, 即加载模型, 和进行模型前向推理\n\n```python\nfrom maix import nn, display\nfrom PIL import Image\nimport numpy as np\n\ntest_jpg = \"/root/test.png\"\n\nmodel = {\n    \"param\": \"/root/models/sobel_int8.param\",\n    \"bin\": \"/root/models/sobel_int8.bin\"\n}\n\ninput_size = (224, 224, 3)\noutput_size = (222, 222, 3)\n\noptions = {\n    \"model_type\":  \"awnn\",\n    \"inputs\": {\n        \"input0\": input_size\n    },\n    \"outputs\": {\n        \"output0\": output_size\n    },\n    \"mean\": [127.5, 127.5, 127.5],\n    \"norm\": [0.0078125, 0.0078125, 0.0078125],\n}\nprint(\"-- load model:\", model)\nm = nn.load(model, opt=options)\nprint(\"-- load ok\")\n\nprint(\"-- read image\")\nimg = Image.open(test_jpg).resize(input_size[:2])\nprint(\"-- read image ok\")\nprint(\"-- forward model with image as input\")\nout = m.forward(img, quantize=True)\nprint(\"-- forward ok\")\nout = out.astype(np.float32).reshape(output_size)\nout = (np.abs(out) * 255 / out.max()).astype(np.uint8)\nimg2 = Image.fromarray(out, mode=\"RGB\")\n\ndisplay.show(img2)\n```\n\n## 方法 maix.nn.load()\n\n加载模型, 返回 `maix.nn.Model` 对象\n\n### 参数\n\n* `model_path`: 模型路径, 可以是字符串或者字典的形式, 目前只支持字典形式\n比如:\n```python\n{\n    \"param\": \"/root/models/sobel_int8.param\",\n    \"bin\": \"/root/models/sobel_int8.bin\"\n}\n```\n\n* `opt`: 设置项, 字典形式, 包括了:\n  * `model_type`: 模型类别, 目前仅支持 `awnn`\n  * `inputs`: 输入层, 字典形式, 关键字是层名称, 为字符串, 如果是加密模型, 需要使用整型; 值是层形状, 为一个`tuple`类型:`(h, w, c)`. 目前只支持单层输入层(未来会支持多层输入, 欢迎提交 `PR`)\n  比如:\n```python\n    # 未加密模型\n    \"inputs\": {\n        \"input0\": (224, 224, 3)\n    }\n    # 加密模型\n    \"inputs\": {\n        0: (224, 224, 3)\n    }\n```\n  * `outputs`: 输出层, 同理输入层. 支持多层输出\n  * `mean`: 如果在`forward`使参数`quantize=True`, 则会使用这个参数对输入数据进行归一化, 计算方法为`(x - mean) * norm`; 格式为`list` 或者 `float`(未支持, 欢迎提交 PR)\n  * `norm`: 看`mean`\n\n### 返回值\n\n返回 `maix.nn.Model` 对象\n\n\n## 类 maix.nn.Model\n\n包含了一系列神经网络操作,  `maix.nn.load()` 会返回其对象\n\n### maix.nn.Model.forward()\n\n只能由具体的对象调用, 不能类直接调用\n\n#### 参数\n\n* `inputs`: 输入, 可以是`Pillow`的`Image`对象, 也可以是`HWC`排列的`bytes`对象, 也可以是`HWC`排列的`numpy.ndarray`对象(还未支持), 多层输入使用`list`(还未支持)\n>! 这个参数未来可能会进行优化\n* `quantize`: 为`True`, 会使用 `load()` 时 `opt` 的`mean norm`参数对数据进行归一化, 并进行`int8`量化； `False`则不会对输入数据进行处理, 则输入需要先自己手动规范量化到`-128~127`范围.  \n>! 这个参数未来可能会进行优化, 将归一化和量化分开\n\n* `layout`: `\"hwc\"` 或者 `\"chw\"`(默认, 推荐)\n* `debug`: 输出`debug`信息, 包含了底层`forward`用时等\n\n#### 返回值\n\n特征图, 如果是单层输出, 是一个浮点类型的 `numpy.ndarray` 对象, 如果是多层输出, 会是一个`list`对象, 包含了多个`numpy.ndarray`对象.\n\n\n### maix.nn.Model.__del__()\n\n删除对象, 内存回收时会自动调用这个函数, 会释放模型占用的资源\n```python\ndel m\n```\n\n## 模块 maix.nn.decoder\n\n`nn` 后处理模块, 集成了常见的模型的后处理, 使用 `forward` 进行模型推理后得到特征图输出, 使用这个模块下的方法对输出的特征图进行后处理\n\n### 类 maix.nn.decoder.Yolo2\n\n`YOLO V2` 的后处理模块, 使用时需要创建一个对象,调用`run`方法对模型推理输出进行解码得到物体的坐标和类别.\n\n等价于如下`python`伪代码:\n\n```python\nclass Yolo2:\n    def __init__(self, class_num, anchors, net_in_size=(224, 244), net_out_size=(7, 7)):\n        pass\n\n    def run(self, fmap, nms = 0.3, threshold = 0.5, img_size = None):\n        boxes = []\n        probs = []\n        for x, y, w, h, _probs in valid_results:\n            if img:\n                x *= img_size[0]\n                y *= img_size[1]\n                w *= img_size[0]\n                h *= img_size[1]\n                x, y, w, h = int(x), int(y), int(w), int(h)\n            boxes.append([x, y, w, h])  # item type is float if img_size == 0, else int type\n            probs.append([max_probs_index, _probs]) # probs is list type, item type is float\n        return [boxes, probs]\n\n```\n\n使用时:\n\n```python\nfrom maix.nn import decoder\n\nlabels = [\"A\", \"B\", \"C\"]\nanchors = [1.19, 1.98, 2.79, 4.59, 4.53, 8.92, 8.06, 5.29, 10.32, 10.65]\n\nyolo2_decoder = decoder.Yolo2(len(labels), anchors)\nyolo2_decoder.run(bytes([0]*10))\n\n...\n\nout = m.forwar(img, layout=\"hwc\")\nboxes, probs = yolo2_decoder.run(out, thres=0.5, nms=0.3, img_size=(img.width, img.height))\nfor i, box in enumerate(boxes):\n    class_id = probs[i][0]\n    prob = probs[i][1][class_id]\n    disp_str = \"{}:{:.2f}%\".format(labels[class_id], prob*100)\n    print(\"final box: {}, {}\".format(box, disp_str))\n\n```\n\n#### maix.nn.decoder.Yolo2.__init__()\n\n构造对象时会自动调用\n\n##### 参数\n\n\n* `class_num`: 类别数量\n* `anchors`: 预选框, `list` 类型, 数量为偶数, 必须要和训练时使用的`anchors` 相同, 也就是说跟模型绑定的参数, 如果你不知道, 请找提供模型的人提供\n* `net_in_size`: 网络输入层分辨率, 默认`(224, 244)`\n* `net_out_size`: 网络输出层分辨率, 默认 `(7, 7)`\n\n\n\n#### maix.nn.decoder.Yolo2.run()\n\n执行解码(后处理), 只能对象进行调用, 不能类直接调用\n\n##### 参数\n\n* `fmap`: 网路输出的特征图, 一般是`forward` 函数的结果\n* `nms`: 非极大值抑制(Non-Maximum Suppression), 用来去掉重复的框, `IOU`(两个框的重叠区域)大于这个值就只取概率大的一个, 取值范围:`[0, 1]`, 默认值为 `0.3`\n* `threshold`: 置信度阈值, 大于这个值才认为物体有效, 取值范围:`[0, 1]`, 默认 `0.5`\n* `img_size`: 源图像大小, `tuple`类型, 比如`(320, 240)`, 这会使返回值的`box` 坐标自动计算为相对于源图的坐标, 并且类型为整型, 默认`None` 则不会计算, `box` 返回相对值(百分比), 浮点类型, 范围:`[0, 1]`\n\n\n##### 返回值\n\n`[boxes, probs]`, `list` 类型, 可以参考上面的使用例子, 其中:\n\n* `boxes`: `list` 类型, 每个元素也是一个`list`, 包含`[x, y, w, h]`, 分别代表了框左上角坐标, 以及框的宽高\n* `probs`: `list` 类型, 每个元素也是一个`list`, 包含`[max_prob_idx, all_classes_probs]`\n  * `all_classes_probs`: `list` 类型, 包含了该框所有类别的置信度\n  * `max_prob_idx`: 整型, 代表了`all_classes_probs`中最大值的下标, 取值范围: `[0, classes_num - 1]`\n\n\n\n\n\n## 模块 maix.nn.app\n\n应用模块， 包含了一些有意思的应用模块\n\n### 模块 maix.nn.app.classifier\n\n自学习分类器（视觉）， 无需训练模型， 只使用特征提取模型， 在运行时学习多个物体特征，然后即可对物体进行分类识别。 适用于简单的分类场景。\n\n`maix.nn.app.classifier`的`python`伪代码:\n\n```python\nclass Classifier:\n    def __init__(self, model, class_num, sample_num, feature_len, input_w, input_h):\n        pass\n\n    def add_class_img(self, img):\n        return idx\n\n    def add_sample_img(self, img):\n        return idx\n\n    def train(self):\n        pass\n\n    def predict(self, img):\n        return idx, min_dist\n\n    def save(self, path):\n        pass\n\ndef load(model, path):\n    return Classifier()\n\n```\n\n#### 类 Classifier\n\n使用时需要指定类别数量，通过`add_class_img`函数传入物体图像来获得物体的特征值， 然后通过`add_sample_img`获取这几个类别的图像，用以对开始采集的图像特征值进行优化， `sample`的图像和开始采集的类别图像可以有一定的差异， 但是不要相差太大， 采集的顺序无所谓；\n然后调用`train`方法进行训练(其实就是`kmeans` 聚类)， 就可以得到使用`sample`图像特征值优化过后的几个分类的特征值；\n最后使用`predict`就可以对输入图像的类别进行识别\n\n##### 构造方法： __init__(self, model, class_num, sample_num, feature_len, input_w, input_h)\n\n* 参数：\n  * `model`: `maix.nn.Model`对象， 用于获得图片的特征值\n  * `class_num`: 要学习的物体类别数量， 比如 `3`\n  * `sample_num`: 用以学习特征的物体数量， 比如`3*5 => 15`\n  * `feature_len`: 特征值的长度， 取决于特征提取模型的输出形状， 比如例程使用`resnet18 1000 分类`模型， 倒数第二层输出长度是`512`\n  * `input_w`: 输入的图像的宽度\n  * `input_h`: 输入的图像的高度\n\n##### 方法: add_class_img(self, img)\n\n添加分类图片， 会自动调用模型推理获取图片的特征值\n\n* 参数：\n  * `img`: 输入图像， 可以是`Pillow`的`Image`对象, 也可以是`HWC`排列的`bytes`对象\n\n* 返回值： `int` 类型, 代表返回成功添加第几个类别的特征值， 取值∈`[0, class_num)`\n\n* 抛出错误： 如果出现错误， 比如添加图片超过类别数量等， 会抛出错误信息\n\n\n##### 方法: add_sample_img(self, img)\n\n添加样本图片， 会自动调用模型推理获取图片的特征值\n\n* 参数：\n  * `img`: 输入图像， 可以是`Pillow`的`Image`对象, 也可以是`HWC`排列的`bytes`对象\n\n* 返回值： `int` 类型, 代表返回成功添加第几个样本图片的特征值， 取值∈`[0, sample_num)`\n\n* 抛出错误： 如果出现错误， 比如添加图片超过设置的样本数量等， 会抛出错误信息\n\n\n##### 方法: train(self)\n\n训练样本（本质上是聚类分类）， 需要在`add_class_img`和`add_sample_img`完成后才能调用，否则会出现误差\n\n\n* 抛出错误： 如果出现错误， 比如类别或者样本采集未完成， 会抛出错误信息\n\n\n##### 方法： predict(self, img)\n\n预测给定的图片所属的类别\n\n* 参数：\n  * `img`: 输入图像， 可以是`Pillow`的`Image`对象, 也可以是`HWC`排列的`bytes`对象\n\n* 返回值：\n  * `idx`: `int` 类型, 代表给定的图片的特征和这个分类最接近， 取值∈`[0, sample_num)`\n  * `min_dist`: 图片的特征和`idx`类别的特征的距离， 距离越小则代表和该类越相似\n\n* 抛出错误： 如果出现错误， 比如参数错误等， 会抛出错误\n\n\n##### 方法： save(self, path)\n\n保存当前的特征值参数到文件， 方便断电保存并下次加载使用\n\n* 参数：\n  * `path`: 保存的路径， 字符串\n\n* 抛出错误： 保存出错， 会抛出错误信息\n\n\n#### 方法 load(model, path)\n\n加载保存的特征值参数文件， 获得[类 Classifier](#类-Classifier)的对象， 加载完成后可直接使用`predict`函数\n\n* 参数：\n  * `model`: `maix.nn.Model`对象， 用于获得图片的特征值， 需要和保存的时候使用的模型相同\n  * `path`: 保存参数的路径\n\n* 返回值： 获得[类 Classifier](#类-Classifier)的对象\n\n\n### 模块 maix.nn.app.face\n\n人脸识别模块， [这里](https://github.com/sipeed/MaixPy3/blob/main/ext_modules/_maix_nn/example/face_recognize.py)有一个`Face_Recognizer`类提供了人脸识别的简单封装， 推荐使用\n\n#### 类 FaceRecognize\n\n伪代码：\n\n```python\nclass FaceRecognize:\n  def __init__(self, model_detect, model_fea, fea_len, input_shape, threshold, nms, max_face_num)\n    pass\n\n  def get_faces(self, img, std_img = False):\n    return [ prob, [x,y,w,h], [[x,y], [x,y], [x,y], [x,y], [x,y]], feature ]\n\n  def compare(self, feature_a, feature_b):\n    return score\n```\n\n[这里](https://github.com/sipeed/MaixPy3/blob/main/ext_modules/_maix_nn/example/face_recognize.py)有一个`Face_Recognizer`类提供了人脸识别的简单封装， 推荐使用\n\n使用的模型可以到[这里下载](https://maixhub.com/modelInfo?modelId=29)\n\n##### 构造方法: __init__(self, model_detect, model_fea, fea_len, input_shape, threshold, nms, max_face_num)\n\n\n* 参数\n  * `model_detect`: 检测模型， [maix.nn.Model](#类-maix.nn.Model) 对象\n  * `model_fea`: 特征提取模型， [maix.nn.Model](#类-maix.nn.Model) 对象\n  * `fea_len`: 人脸特征的长度，比如 `256`\n  * `input_shape`: 输入图像的形状，`(w, h, c)`格式， 比如`(224, 224, 3)`\n  * `threshold`: 人脸检测阈值， 默认`0.5`\n  * `nms`: 人脸检测非极大值抑制值，即用来防止重复框一个人脸， 默认`0.3`\n  * `max_face_num`: 支持的同时框的人脸数量，取`1`或者更多\n\n##### 获取人脸信息: get_faces(self, img, std_img = False)\n\n获取人脸信息， 包括位置和特征值等\n\n* 参数\n  * `img`: 输入图像， 分辨率需要和检测模型的输入相同，  比如`224 x 224`， 可以是`PIL.Image.Image`对象， 或者`bytes`对象\n  * `std_img`: 取值`True`或者`False`, 选择是否返回纠正过的标准人脸图片\n\n* 返回值: 返回一个 `list` 对象，`[ prob, box, landmarks, feature, std_img ]`，其中`std_img`根据构造函数的参数`std_img`决定是否存在\n  * `prob`: 检测到人脸的概率， 比设置的`threshold`大\n  * `box`: 人脸框， 值为`[x,y,w,h]` ， 分别代表左上角坐标和框的宽高\n  * `landmarks`: 人脸关键点， 共`5`个点, 格式`[[x,y], [x,y], [x,y], [x,y], [x,y]]`，分别代表了左眼、右眼、鼻子、左嘴角、右嘴角的坐标\n  * `feature`: 人物脸的特征值， 一个`list`，`list`中的项目值类型为`float`（未来有可能会有`feature`为`bytes`的可选项）\n  * `std_img`: 人脸图像，`PIL.Image.Image`对象， 只有当构造函数的参数`std_img`为`True`时才会有这个返回值\n\n##### 对比人脸特征: compare(self, feature_a, feature_b)\n\n对比两个人脸特征值相似度，并返回相似度百分比\n\n* 参数\n  * `feature_a`: `get_faces`函数的返回值, 一个`list`对象或者`bytes`对象\n  * `feature_b`: `get_faces`函数的返回值, 一个`list`对象或者`bytes`对象\n\n* 返回值： 返回两个人脸特征值的对比相似度分数（百分比），取值范围 `∈` `[0.0, 100.0]`"}, "/soft/maixpy3/zh/api/maix/pwm.html": {"title": "MaixII M2dock PWM 调试", "content": "---\ntitle: MaixII M2dock PWM 调试\nkeywords: MaixII, MaixPy3, Python, Python3, M2dock\ndesc: maixpy doc: MaixII M2dock PWM 调试\n---\n\n## PWM介绍\n\nPWM（Pulse Width Modulation）控制——脉冲宽度调制技术，通过对一系列脉冲的宽度进行调制，来等效地获得所需要波形（含形状和幅值）.PWM控制技术在逆变电路中应用最广，应用的逆变电路绝大部分是PWM型，PWM控制技术正是有赖于在逆变电路中的应用，才确定了它在电力电子技术中的重要地位。V831的PWM功能是由硬件产生的,所以我们只用配置好硬件寄存器即可.芯片寄存器请参考[V833／V831 Datasheet V1.0.pdf](https://linux-sunxi.org/images/b/b9/V833%EF%BC%8FV831_Datasheet_V1.0.pdf).\n\n\n\n## V831 Dock PWM 引脚\n\n如下图所示,V831有8个引脚可以输出PWM波,但是由于复用关系,我们并不能随心所欲的使用这8个引脚.所以我们要注意他们的复用关系,以PH0为例,但是这个引脚被SPI功能所占用,所以我们使用时,需要改变PWM功能所在引脚的复用功能才能正常使用PWM功能.能够被我们正常使用的功能引脚是`PH6`、`PH7` 和 `PH8`引脚,其他引脚使用时需要注意引脚复用关系.如需一定要使用,请参考 [改变引脚复用关系](/soft/maixpy3/zh/module/linux/pwm.html#V831-Dock-改变引脚复用关系).\n\n![](./../../assets/linux/PWM/2021-09-22_10-27.png)\n\n| PIN Number  | PIN      | function                                   | 设备树配置     | 功能        | 备注  |\n| ----------- | -------- | ------------------------------------------ | --------- | --------- | --- |\n| 238(224+14) | PH14     | SPI1_CS0TWI3_SDAPH_EINT14                  |           | State_LED |     |\n| ---         | ---      |                                            |           | ---       | --- |\n| 166(160+6)  | PF6      | PF_EINT6                                   |           |           |     |\n|             | RST      |                                            |           |           |     |\n| 199(192+7)  | PG7      | UART1_RXPG_EINT7                           |           |           |     |\n| 198(192+6)  | PG6      | UART1_TXPG_EINT6                           |           |           |     |\n| 236(224+12) | PH12     | JTAG_CKRMII_TXENSPI1_MOSITWI2_SDAPH_EINT12 | TWI2_SDA  |           |     |\n| 235(224+11) | PH11     | JTAG_MSRMII_TXCKSPI1_CLKTWI2_SCKPH_EINT11  | TWI2_SCK  |           |     |\n| 238(224+14) | PH14     | JTAG_DIMDIOSPI1_CS0TWI3_SDAPH_EINT14       |           |           |     |\n| 237(224+13) | PH13     | JTAG_DOMDCSPI1_MISOTWI3_SCKPH_EINT13       |           |           |     |\n| 234(224+10) | PH10     | RMII_TXD0TWI3_SDAUART0_RXPH_EINT10         |           |           |     |\n|             | CPUX-RX  |                                            |           |           |     |\n|             | UART0-TX | PWM_9RMII_TXD1TWI3_SCKUART0_TXPH_EINT9     |           |           |     |\n| ---         | ---      |                                            |           | ---       | --- |\n|             | GND      |                                            |           |           |     |\n|             | 5V       |                                            |           |           |     |\n| 230(224+6)  | PH6      | PWM_6RMII_RXD0TWI2_SDAUART2_RXPH_EINT6     |           |           |     |\n| 231(224+7)  | PH7      | PWM_7RMII_CRS_DVUART0_TXUART2_RTSPH_EINT7  |           |           |     |\n| 232(224+8)  | PH8      | PWM_8RMII_RXERUART0_RXUART2_CTSPH_EINT8    |           |           |     |\n|             | GPADC0   |                                            |           |           |     |\n| 224(224+0)  | PH0      | PWM_0I2S0_MCLKSPI1_CLKUART3_TXPH_EINT0     | SPI1_CLK  |           |     |\n| 225(224+1)  | PH1      | PWM_1I2S0_BCLKSPI1_MOSIUART3_RXPH_EINT1    | SPI1_MOSI |           |     |\n| 226(224+2)  | PH2      | PWM_2I2S0_LRCKSPI1_MISOUART3_CTSPH_EINT2   | SPI1_MISO |           |     |\n| 227(224+3)  | PH3      | PWM_3I2S0_DOUTSPI1_CS0UART3_RTSPH_EINT3    | SPI1_CS0  |           |     |\n\n\n\n\n\n## PWM LED 测试\n\n使用 sysfs 操作 PWM 的例子：\n     \n<!-- 678 -->\n\n```shell\n#首先打开PWM6通道\ncd /sys/devices/platform/soc/300a000.pwm/pwm/pwmchip0\n\nroot@sipeed:/sys/devices/platform/soc/300a000.pwm/pwm/pwmchip0# echo 6 > export \n\nroot@sipeed:/sys/devices/platform/soc/300a000.pwm/pwm/pwmchip0# ls\ndevice     export     npwm       pwm6       subsystem  uevent     unexport\n\n#设置PWM周期\ncd /sys/devices/platform/soc/300a000.pwm/pwm/pwmchip0/pwm6\nroot@sipeed:/sys/devices/platform/soc/300a000.pwm/pwm/pwmchip0/pwm6# echo 1000000 > period \n\n#设置PWM占空比\nroot@sipeed:/sys/devices/platform/soc/300a000.pwm/pwm/pwmchip0/pwm6# echo 10000 > duty_cycle\n\n#开启PWM功能\nroot@sipeed:/sys/devices/platform/soc/300a000.pwm/pwm/pwmchip0/pwm6# echo 1 > enable\n\n#用示波器或者LED灯观察PH0端口是否有PWM波输出\n```\n\n## Python-PWM\n\n```python\nimport time\nfrom maix import pwm\nimport signal\n\n\ndef handle_signal_z(signum,frame):\n    print(\"APP OVER\")\n    exit(0)\n\n\nsignal.signal(signal.SIGINT,handle_signal_z)\n\n\nwith pwm.PWM(6) as pwm6:\n        pwm6.period = 1000000\n        pwm6.duty_cycle = 10000\n        pwm6.enable = True\n        duty_cycle = 10000\n        while True:\n            for i in range(1,10):\n                pwm6.duty_cycle = 10000 * i\n                time.sleep(1)\n```\n\n\n## V831 Dock 改变引脚复用关系\n\n以PH0为例,查询v831的datasheet手册我们能得到:\n![](./../../assets/linux/PWM/2021-09-22_10-37.png)\n![](./../../assets/linux/PWM/2021-09-22_10-35.png)\n`0x0300B0FC`寄存器的最低三位是控制PH0的引脚复用关系的,我们通过linux指令进行查看该寄存器中的值.\n\n~~~ shell\nroot@sipeed:/sys/class/sunxi_dump# ls\ncompare  dump     rw_byte  write\nroot@sipeed:/sys/class/sunxi_dump# echo 0x0300B0FC > dump \nroot@sipeed:/sys/class/sunxi_dump# cat dump \n0x77114444\n~~~\n由寄存器中的值我们知道最低两位是00,为此我们改变最低位的值,然后再写回去.\n\n~~~ shell\nroot@sipeed:/sys/class/sunxi_dump# echo 0x0300B0FC 0x77114442 > write \nroot@sipeed:/sys/class/sunxi_dump# cat dump \n0x77114442\n~~~\n修改成功后,我们就可以正常使用PWM0通道的PWM波输出了.\n\n\n~~~ python\n#使用PWM0的python3模块,使用其他复用引脚可以参考该写法\n#import PWM就可以使用\n\"\"\"Linux PWM driver sysfs interface\"\"\"\n\nimport os\nimport struct\n__author__ = 'Scott Ellis'\n__version__ = '1.0'\n__license__ = 'New BSD'\n__copyright__ = 'Copyright (c) 2016 Scott Ellis'\nfrom types import (\n    TracebackType,\n)\nfrom typing import (\n    Optional,\n    Type,\n)\nclass PWM(object):\n    \"\"\"\n    A class to work with the Linux PWM driver sysfs interface\n    \"\"\"\n\n    def __init__(self, channel: int = 0, chip: int = 0) -> None:\n        \"\"\" Specify channel and chip when creating an instance\n        The Linux kernel driver exports a sysfs interface like this\n            /sys/class/pwm/pwmchip<chip>/pwm<channel>\n        A <chip> can have multiple <channels>.\n        The channel and chip are determined by the kernel driver.\n        For example the two PWM timers from the RPi kernel driver\n        show up like this\n            /sys/class/pwm/pwmchip0/pwm0\n            /sys/class/pwm/pwmchip0/pwm1\n        To use the RPi timers create instances this way\n            pwm0 = PWM(0) or PWM(0,0)\n            pwm1 = PWM(1) or PWM(1,0)\n        \"\"\"\n        self._channel = channel\n        self._chip = chip\n        self.base = '/sys/class/pwm/pwmchip{:d}'.format(self._chip)\n        self.path = self.base + '/pwm{:d}'.format(self._channel)\n        #调整引脚复用功能\n        with open(\"/sys/class/sunxi_dump/dump\",\"wb\") as f:\n            f.write(b'0x0300B0FC')\n        with open(\"/sys/class/sunxi_dump/dump\",\"rb\") as f:\n            self.gpio = f.read()\n            self.gpio = self.gpio[:-1]\n        with open(\"/sys/class/sunxi_dump/write\",\"wb\") as f:\n            gpio_H0 = int(self.gpio,16)\n            gpio_H0 &= ~0x00000007\n            gpio_H0 |= 0x00000002\n            gpio_io = b'0x0300B0FC ' + bytes(hex(gpio_H0), 'ascii')\n            f.write(gpio_io)\n        if not os.path.isdir(self.base):\n            raise FileNotFoundError('Directory not found: ' + self.base)\n\n    # enable class as a context manager\n    def __enter__(self) -> 'PWM':\n        self.export()\n        return self\n\n    def __exit__(self,\n            exc_type: Optional[Type[BaseException]],\n            exc_value: Optional[BaseException],\n            traceback: Optional[TracebackType]) -> None:\n        self.enable = False\n        self.inversed = False\n        self.unexport()\n        #还原引脚复用功能\n        with open(\"/sys/class/sunxi_dump/dump\",\"wb\") as f:\n            f.write(b'0x0300B0FC')\n        with open(\"/sys/class/sunxi_dump/dump\",\"rb\") as f:\n            self.gpio_o = f.read()\n            self.gpio_o = self.gpio[:-1]\n        with open(\"/sys/class/sunxi_dump/write\",\"wb\") as f:\n            gpio_H0 = int(self.gpio,16)\n            gpio_H0 &= 0x00000007\n            gpio_H0_o = int(self.gpio_o,16)\n            gpio_H0_o &= ~0x00000007\n            gpio_H0_o |= gpio_H0\n            gpio_io = b'0x0300B0FC ' + bytes(hex(gpio_H0_o), 'ascii')\n            f.write(gpio_io)\n        return\n\n    def export(self) -> None:\n        \"\"\"Export the channel for use through the sysfs interface.\n        Required before first use.\n        \"\"\"\n        if not os.path.isdir(self.path):\n            with open(self.base + '/export', 'w') as f:\n                f.write('{:d}'.format(self._channel))\n\n    def unexport(self) -> None:\n        \"\"\"Unexport the channel.\n        The sysfs interface is no longer usable until it is exported again.\n        \"\"\"\n        if os.path.isdir(self.path):\n            with open(self.base + '/unexport', 'w') as f:\n                f.write('{:d}'.format(self._channel))\n\n    @property\n    def channel(self) -> int:\n        \"\"\"The channel used by this instance.\n        Read-only, set in the constructor.\n        \"\"\"\n        return self._channel\n\n    @property\n    def chip(self) -> int:\n        \"\"\"The chip used by this instance.\n        Read-only, set in the constructor.\n        \"\"\"\n        return self._chip\n\n    @property\n    def period(self) -> int:\n        \"\"\"The period of the pwm timer in nanoseconds.\"\"\"\n        with open(self.path + '/period', 'r') as f:\n            value = f.readline().strip()\n\n        return int(value)\n\n    @period.setter\n    def period(self, value: int) -> None:\n        with open(self.path + '/period', 'w') as f:\n            f.write('{:d}'.format(value))\n\n    @property\n    def duty_cycle(self) -> int:\n        \"\"\"The duty_cycle (the ON pulse) of the timer in nanoseconds.\"\"\"\n        with open(self.path + '/duty_cycle', 'r') as f:\n            value = f.readline().strip()\n\n        return int(value)\n\n    @duty_cycle.setter\n    def duty_cycle(self, value: int) -> None:\n        with open(self.path + '/duty_cycle', 'w') as f:\n            f.write('{:d}'.format(value))\n\n    @property\n    def enable(self) -> bool:\n        \"\"\"Enable or disable the timer, boolean\"\"\"\n        with open(self.path + '/enable', 'r') as f:\n            value = f.readline().strip()\n\n        return True if value == '1' else False\n\n    @enable.setter\n    def enable(self, value: bool) -> None:\n        with open(self.path + '/enable', 'w') as f:\n            if value:\n                f.write('1')\n            else:\n                f.write('0')\n\n    @property\n    def inversed(self) -> bool:\n        \"\"\"normal polarity or inversed, boolean\"\"\"\n        with open(self.path + '/polarity', 'r') as f:\n            value = f.readline().strip()\n\n        return True if value == 'inversed' else False\n\n    @inversed.setter\n    def inversed(self, value: bool) -> None:\n        with open(self.path + '/polarity', 'w') as f:\n            if value:\n                f.write('inversed')\n            else:\n                f.write('normal')\n~~~"}, "/soft/maixpy3/zh/api/maix/gpio.html": {"title": "MaixII M2dock I2C gpio 调试", "content": "---\ntitle: MaixII M2dock I2C gpio 调试\nkeywords: MaixII, MaixPy3, Python, Python3, M2dock\ndesc: maixpy doc: MaixII M2dock gpio 调试\n---\n\n## PIN_CTL\n\n- lichee/linux-4.9/drivers/pinctrl/sunxi/pinctrl-sun8iw19p1-r.c\n\n- lichee/linux-4.9/drivers/pinctrl/sunxi/pinctrl-sun8iw19p1.c\n\n![](./asserts/v831_pin_maps.png)\n\n### V831 Dock PIN Maps\n\n- PINCTRL_PIN(64 + (0), \"P\" \"C\" \"0\")\n- PINCTRL_PIN(96 + (0), \"P\" \"D\" \"0\")\n- PINCTRL_PIN(128 + (0), \"P\" \"E\" \"0\")\n- PINCTRL_PIN(160 + (0), \"P\" \"F\" \"0\")\n- PINCTRL_PIN(192 + (0), \"P\" \"G\" \"0\")\n- PINCTRL_PIN(224 + (0), \"P\" \"H\" \"0\")\n- PINCTRL_PIN(256 + (0), \"P\" \"I\" \"0\")\n\n| PIN Number  | PIN      | function                                   | 设备树配置     | 功能        | 备注  |\n| ----------- | -------- | ------------------------------------------ | --------- | --------- | --- |\n| 238(224+14) | PH14     | SPI1_CS0TWI3_SDAPH_EINT14                  |           | State_LED |     |\n| ---         | ---      |                                            |           | ---       | --- |\n| 166(160+6)  | PF6      | PF_EINT6                                   |           |           |     |\n|             | RST      |                                            |           |           |     |\n| 199(192+7)  | PG7      | UART1_RXPG_EINT7                           |           |           |     |\n| 198(192+6)  | PG6      | UART1_TXPG_EINT6                           |           |           |     |\n| 236(224+12) | PH12     | JTAG_CKRMII_TXENSPI1_MOSITWI2_SDAPH_EINT12 | TWI2_SDA  |           |     |\n| 235(224+11) | PH11     | JTAG_MSRMII_TXCKSPI1_CLKTWI2_SCKPH_EINT11  | TWI2_SCK  |           |     |\n| 238(224+14) | PH14     | JTAG_DIMDIOSPI1_CS0TWI3_SDAPH_EINT14       |           |           |     |\n| 237(224+13) | PH13     | JTAG_DOMDCSPI1_MISOTWI3_SCKPH_EINT13       |           |           |     |\n| 234(224+10) | PH10     | RMII_TXD0TWI3_SDAUART0_RXPH_EINT10         |           |           |     |\n|             | CPUX-RX  |                                            |           |           |     |\n|             | UART0-TX | PWM_9RMII_TXD1TWI3_SCKUART0_TXPH_EINT9     |           |           |     |\n| ---         | ---      |                                            |           | ---       | --- |\n|             | GND      |                                            |           |           |     |\n|             | 5V       |                                            |           |           |     |\n| 230(224+6)  | PH6      | PWM_6RMII_RXD0TWI2_SDAUART2_RXPH_EINT6     |           |           |     |\n| 231(224+7)  | PH7      | PWM_7RMII_CRS_DVUART0_TXUART2_RTSPH_EINT7  |           |           |     |\n| 232(224+8)  | PH8      | PWM_8RMII_RXERUART0_RXUART2_CTSPH_EINT8    |           |           |     |\n|             | GPADC0   |                                            |           |           |     |\n| 224(224+0)  | PH0      | PWM_0I2S0_MCLKSPI1_CLKUART3_TXPH_EINT0     | SPI1_CLK  |           |     |\n| 225(224+1)  | PH1      | PWM_1I2S0_BCLKSPI1_MOSIUART3_RXPH_EINT1    | SPI1_MOSI |           |     |\n| 226(224+2)  | PH2      | PWM_2I2S0_LRCKSPI1_MISOUART3_CTSPH_EINT2   | SPI1_MISO |           |     |\n| 227(224+3)  | PH3      | PWM_3I2S0_DOUTSPI1_CS0UART3_RTSPH_EINT3    | SPI1_CS0  |           |     |\n\n## sysfs 操作 GPIO\n\n```shell\nroot@sipeed:/# ls -l /sys/class/gpio\n--w-------    1 root     root          4096 Dec  9 08:54 export\nlrwxrwxrwx    1 root     root             0 Dec  9 08:54 gpiochip0 -> ../../devices/platform/soc/pio/gpio/gpiochip0\nlrwxrwxrwx    1 root     root             0 Dec  9 08:54 gpiochip352 -> ../../devices/platform/soc/r_pio/gpio/gpiochip352\n--w-------    1 root     root          4096 Dec  9 08:54 unexport\nroot@sipeed:/#\n```\n\n/sys/class/gpio 目录下的三种文件：\n\n- export/unexport 文件:  `/sys/class/gpio/export`，只写，写入 GPIO 编号来向内核申请 GPIO 控制权（前提是没有内核代码申请这个 GPIO 端口）, 成功后会在目录下生成 gpioN 目录, `/sys/class/gpio/unexport` 和导出的效果相反。\n\n- gpioN 指代具体的 gpio 引脚:  指代某个具体的 gpio 端口, 内有以下属性文件：\n\n| Attribution | Read/Write | Value                          | Function     |\n| ----------- | ---------- | ------------------------------ | ------------ |\n| direction   | RW         | in,out;low,high                | 设置输入输出       |\n| value       | RW         | 0,非零                           | 读取或者写入 IO 电平 |\n| edge        | RW         | none , rising , falling , both | 配置中断触发方式     |\n| active_low  | RW         | 0,非零                           | 设置低电平有效      |\n\n- gpiochipN 指代 gpio 控制器:  gpiochipN 表示的就是一个 gpio_chip, 用来管理和控制一组 gpio 端口的控制器，该目录下存在以下属性文件：\n\n| Attribution | Function                      |\n| ----------- | ----------------------------- |\n| base        | 和N相同，表示控制器管理的最小的端口编号。         |\n| lable       | 诊断使用的标志，寄存器地址，1c20800.pinctrl |\n| ngpio       | 表示控制器管理的 gpio 端口数量，A~G，224    |\n\n### LED 测试\n\n使用 sysfs 操作 GPIO 的例子：\n\n```shell\nls -l /sys/class/gpio/ # show gpio\necho 238 > /sys/class/gpio/export  #export PH14(238), State_LED\nls -l /sys/class/gpio/ # show gpio\n# output test\necho \"out\" > /sys/class/gpio/gpio238/direction # set gpio mode: direction\necho 0 > /sys/class/gpio/gpio238/value # set gpio output level: low\necho 1 > /sys/class/gpio/gpio238/value # set gpio output level: height\n# input test\necho \"in\" > /sys/class/gpio/gpio238/direction #设置为输入\ncat /sys/class/gpio/gpio192/value #读取电平\n\n```\n\n```bash\nll /sys/devices/platform/soc/r_pio/\n```\n\n## Python-gpiod\n\n![](./asserts/v831_gpio.png)\n\n```python\nimport gpiod\nc = gpiod.chip(\"gpiochip1\")\n# pylint: disable=missing-docstring\nimport sys\nimport time\nimport pytest\nfrom gpiod import chip, line, line_request\n\ntry:\n    if len(sys.argv) > 2:\n        LED_CHIP = sys.argv[1]\n        LED_LINE_OFFSET = int(sys.argv[2])\n    else:\n        raise Exception()\n# pylint: disable=broad-except\nexcept Exception:\n    print(\n        \"\"\"Usage:\n    python3 -m gpiod.test.blink <chip> <line offset>\"\"\"\n    )\n    sys.exit()\n\nc = chip(LED_CHIP)\n\nprint(\"chip name: \", c.name)\nprint(\"chip label: \", c.label)\nprint(\"number of lines: \", c.num_lines)\n\nprint()\n\nled = c.get_line(LED_LINE_OFFSET)\n\nprint(\"line offset: \", led.offset)\nprint(\"line name: \", led.name)\nprint(\"line consumer: \", led.consumer)\nprint(\n    \"line direction: \",\n    \"input\" if led.direction == line.DIRECTION_INPUT else \"output\",\n)\nprint(\n    \"line active state: \",\n    \"active low\" if led.active_state == line.ACTIVE_LOW else \"active high\",\n)\nprint(\"is line used: \", led.is_used)\nprint(\"is line open drain: \", led.is_open_drain)\nprint(\"is_open_source: \", led.is_open_source)\nprint(\"is line requested: \", led.is_requested)\n\nprint(\"\\nrequest line\\n\")\n\nconfig = line_request()\nconfig.consumer = \"Blink\"\nconfig.request_type = line_request.DIRECTION_OUTPUT\n\nled.request(config)\n\nprint(\"line consumer: \", led.consumer)\nprint(\n    \"line direction: \",\n    \"input\" if led.direction == line.DIRECTION_INPUT else \"output\",\n)\nprint(\n    \"line active state: \",\n    \"active low\" if led.active_state == line.ACTIVE_LOW else \"active high\",\n)\nprint(\"is line used: \", led.is_used)\nprint(\"is line open drain: \", led.is_open_drain)\nprint(\"is_open_source: \", led.is_open_source)\nprint(\"is line requested: \", led.is_requested)\n\nwhile True:\n    led.set_value(0)\n    time.sleep(0.1)\n    led.set_value(1)\n    time.sleep(0.1)\n```\n\n```python\npython test_blink.py gpiochip0 238\n```"}, "/soft/maixpy3/zh/api/maix/camera.html": {"title": "", "content": ""}, "/soft/maixpy3/zh/api/maix/display.html": {"title": "", "content": ""}, "/soft/maixpy3/zh/api/maix/i2c.html": {"title": "MaixII M2dock I2C 调试", "content": "---\ntitle: MaixII M2dock I2C 调试\nkeywords: MaixII, MaixPy3, Python, Python3, M2dock\ndesc: maixpy doc: MaixII M2dock I2C 调试\n---\n\nV831 镜像中默认包含 **i2c-tools**, i2c-tools 包含如下四条命令\n\n## 1. i2cdetect\n\n**查询 I2C 用法**\n\n```shell\nUsage: i2cdetect [-y] [-a] [-q|-r] I2CBUS [FIRST LAST]\n       i2cdetect -F I2CBUS\n       i2cdetect -l\n  I2CBUS is an integer or an I2C bus name\n```\n\n**查询 I2C 总线**\n\n```shell\ni2cdetect -l\n```\n\n\n\n**查询 I2C 总线上挂载的设备**\n\n| -y   | 取消交互过程，直接执行指令 |\n| ---- | ------------- |\n| twi2 | I2C 总线编号      |\n\n```shell\ni2cdetect -y 1\n```\n\n\n\n## 2. i2cdump\n\n扫描寄存器内容：\n\n```shell\ni2cdump -y 1 0x68\n```\n\n\n\n## 3. i2cget\n\n```shell\ni2cget -y 1 0x68 0x00\n```\n\n| -y   | 取消交互过程，直接执行指令                 |\n| ---- | ----------------------------- |\n| 1    | I2C 总线编号                      |\n| 0x68 | I2C 设备地址，此处表示 DS3231 RTC 时钟芯片 |\n| 0x00 | 代表存储器地址                       |\n\n\n\n## 4. i2cset\n\n**寄存器内容写入：**\n\n```shell\ni2cset -y 1 0x68 0x00 0x13\n```\n\n| -y   | 取消交互过程，直接执行指令                 |\n| ---- | ----------------------------- |\n| 1    | I2C 总线编号                      |\n| 0x68 | I2C 设备地址，此处表示 DS3231 RTC 时钟芯片 |\n| 0x00 | 寄存器地址                         |\n| 0x13 | 需要写入的寄存器值                     |\n\n## python\n\n```python\nfrom maix import i2c\ni2c = i2c.I2CDevice('/dev/i2c-2', 0x26)\nprint(i2c)\nprint(i2c.read(0x1, 1))\n```"}, "/soft/maixpy3/zh/api/maix/imagee.html": {"title": "", "content": ""}, "/soft/maixpy3/zh/api/maix/v831_wifi.html": {"title": "MaixII M2dock wifi 调试", "content": "---\ntitle: MaixII M2dock wifi 调试\nkeywords: MaixII, MaixPy3, Python, Python3, M2dock\ndesc: maixpy doc: MaixII M2dock wifi 调试\n---\n\n\n## V831 WIFI 调试\n\n在 /etc/wpa_supplicant.conf 中新增用户 WIFI \n\n```text\nctrl_interface=/tmp/wpa_supplicant\nupdate_config=1\n\nnetwork={\n    ssid=\"Sipeed\"\n    psk=\"123456789\"\n}\n# 自己可以配置多个 wifi\nnetwork={\n    ssid=\"Geek-mi\"\n    psk=\"Geek.99110099\"\n}\n```\n\n重启系统（重新上电）之后板子就能自动连接 WIFI\n\n***\n\n## 调试使用\n\n开启 WIFI 网络相关工具包的编译\n\n开启 WIFI， 连接网络过程\n\n1. 挂载网卡\n\n```text\ninsmod /lib/modules/4.9.118/8189fs.ko\n```\n\n2. 开启网口 wlan0\n\n```text\nifconfig wlan0 up\n```\n\n3. 添加/修改网络配置文件\n\n```text\nvi /etc/wpa_supplicant.conf\n```\n\n\n\n在 /etc/wpa_supplicant.conf 中新增内容(该步骤可省略)\n\n```text\nctrl_interface=/tmp/wpa_supplicant\nupdate_config=1\n\nnetwork={\n    ssid=\"Sipeed\"\n    psk=\"1234567890\"\n}\n# 自己可以配置多个 wifi\nnetwork={\n    ssid=\"Geek-mi\"\n    psk=\"Geek.99110099\"\n}\n```\n\n\n\n4. 启用配置文件，连接网络\n\n```text\nwpa_supplicant -B -i wlan0 -c /etc/wpa_supplicant.conf\n```\n\n\n\n5. 启用 DHCP 分配 IP\n\n> 注意：需要先安装好天线\n\n```text\nudhcpc -i wlan0\n```\n\n6. 测试 ping\n\n```text\nping www.baidu.com\n```\n\n### 配置 WIFI 自动连接\n\n\n\n在用户自定义路径下新建文件内容如下：\n\n> 文件路径: ` /root/develop/wifi_connect.sh`\n\n```text\nmkdir -p /root/develop/ # 创建路径\nvim /root/develop/wifi_connect.sh # 创建 sh 文件\nchmod +x /root/develop/wifi_connect.sh # 修改脚本权限\n\n```\n\n\n\n```text\ninsmod /lib/modules/4.9.118/8189fs.ko\nsleep 1s\n\nifconfig wlan0 up\nsleep 1s\n\nwpa_supplicant -B -i wlan0 -c /etc/wpa_supplicant.conf\nsleep 3s\n\nkillall udhcpc\nsleep 1s\n\nudhcpc -i wlan0\n```\n\n\n\n```text\necho -e  \"sh /root/develop/wifi_connect.sh\" >> /etc/init.d/rcS\n```\n\n```text\n# 1. 挂载网卡驱动\ninsmod /lib/modules/4.9.118/8189fs.ko\nsleep 1s\n# 2. 开启网口 wlan0\nifconfig wlan0 up\nsleep 1s\n# 3. 启用配置文件，连接网络\nwpa_supplicant -B -i wlan0 -c /etc/wpa_supplicant.conf\nsleep 3s\n# 4. 杀死以前的dhcp进程\nkillall udhcpc\nsleep 1s\n# 5. 启用 DHCP 分配 IP\nudhcpc -i wlan0\n```\n\n\n\n```text\n# 关闭有线连接\nifconfig eth0 down\n# 打开无线连接\nifconfig wlan0 up\n# 杀死以前配置进程\nkillall wpa_supplicant\n# 启动wifi配置，使文件生效\nwpa_supplicant -B -Dwext -iwlan0 -c/etc/wpa_supplicant.conf\n# 启动有点慢，等一下启动完毕\nsleep 3s\n# 杀死以前的dhcp进程\nkillall udhcpc\n# 启动dhcp获取ip\nudhcpc -b -i wlan0\n# static ip\n# ifconfig wlan0 192.168.134.250 netmask 255.255.255.0\n# route add default gw 192.168.134.1\n\n```\n\n\n\n## WIFI 带宽/延迟测试\n\n使用 iperf3 测试网络带宽\n\niperf3,默认端口: 5210\n\n\n\n服务端（这里使用 PC）：\n\n```text\niperf3 -s\n```\n\n客户端（这里使用 V831）：\n\n```text\niperf3 -c [serve ip] -p [port]\n```\n\n测试项目：\n\n- WIFI 吞吐量（带宽测试）\n\n- WIFI 丢包/时延测试"}, "/soft/maixpy3/zh/index.html": {"title": "What is MaixPy3?", "content": "---\ntitle: What is MaixPy3?\nkeywords: Maixpy3 官方文档\ndesc: maixpy doc: MaixPy3 是什么？能做什么？\n---\n\n\n<p align=\"center\">\n    <iframe src=\"//player.bilibili.com/player.html?aid=465792152&bvid=BV1ZL411c7kc&cid=489256831&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"max-width:640px; max-height:480px;\"> </iframe>\n</p>\n\n中国的 [Sipeed 开源组织](https://github.com/sipeed) 在 2020 年底推出了 [MaixPy3](https://github.com/sipeed/MaixPy3) 开源软件，这是一款基于 [linux cpython](https://github.com/python/cpython) 的 Python3 软件开发工具包（SDK），借助开源 Python 编程语言实现跨平台统一和简化 Linux 嵌入式设备上开发 AIoT （人工智能物联网） = AI（人工智能） + IoT（物联网）应用，意在打造可落地的视觉 AI 应用生态，帮助更多人了解、使用 AI 技术来解决实际问题，推进全球边缘 AI 的落地化进程。\n\n> **自言自语：怎样才能让初学者轻松地【学会视觉 AI 应用】和【开发出可落地的产品】呢？**\n\n\n\n> 2022年01月21日 粗剪版视频还缺少【训练模型流程】和【产品特色亮点】\n\n## 本开源项目适用于以下人群：\n\n1. 想要了解与学习应用视觉 AI 开发的学生、爱好者、创客等。\n2. 想要应用视觉 AI 功能解决问题，但不想浪费生命在底层原理实现的同学们。\n3. 需要对 Python AI 教学、电赛毕设、视觉应用等功能评估与验证的同行们。\n4. 有过 opencv 、openmv 、 maixpy 使用基础的老朋友们！！！\n\n## 本开源项目建议具备的背景知识\n\n- 有过 Python 语言编程基础，了解基本语法，如面向对象、交互解释等概念。\n\n- 有过嵌入式、单片机的基本概念，了解 IO 口、电压、串口、外设等概念。\n\n- 有使用过 maixpy K210 AI 开发板的基础（与上代[MaixPy](https://github.com/sipeed/MaixPy)开源产品联动）。\n\n当你有这些基础概念后，你可以减少很多犯错的次数，避免踩到一些不必要的坑。\n\n## 可适配平台\n\n目前 MaixPy3 支持的平台主要如下，未来会进一步适配其他低端嵌入式 Linux 平台。\n\n- [MaixII-Dock](/hardware/zh/maixII/M2/resources.html)\n\n- [MaixSense](/hardware/zh/maixII/M2A/R329.html)\n\n- [Linux Desktop](https://github.com/sipeed/MaixPy3)\n\n## [MaixPy3](https://github.com/sipeed/MaixPy3) star-history\n\n![GitHub forks](https://img.shields.io/github/forks/sipeed/maixpy3.svg?style=social) ![GitHub stars](https://img.shields.io/github/stars/sipeed/maixpy3.svg?style=social) ![GitHub watchers](https://img.shields.io/github/watchers/sipeed/maixpy3.svg?style=social)\n\n<iframe style=\"width:100%;height:auto;min-width:600px;min-height:400px;\" src=\"https://star-history.com/embed?secret=#sipeed/MaixPy3&Date\" frameBorder=\"0\"></iframe>\n\n> 快来与我们一起同行吧！ “Life is short. You need Sipeed.”"}, "/soft/maixpy3/zh/usage/AI_net/self_learn.html": {"title": "自学习", "content": "|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|Rui|初次编写文档|----||2022年1月8日|dianjixz|修改文档的编写方式|使用Jupyternotebook进行编写文档||2022年1月18日|Rui|修改文档，增加效果图|通过测试的平台有MaixII-Dock，使用的是MaixPy30.4.0|##运行效果<palign=\"center\"><iframesrc=\"//player.bilibili.com/player.html?aid=808318247&bvid=BV1C34y1i7QZ&cid=487776187&page=1\"scrolling=\"no\"border=\"0\"frameborder=\"no\"framespacing=\"0\"allowfullscreen=\"true\"style=\"max-width:640px;max-height:480px;\"></iframe></p>##准备-在[MaixHub](https://www.maixhub.com/modelInfo?modelId=24)上获取模型文件和运行源码（最新版本的系统内置了模型文件`/home/model/resnet18_1000_awnn*`）-确认MaixPy3版本为0.4.3以上-使用的硬件为MaixII-Dock-内存卡内是最新版本的镜像系统-插卡启动硬件##自学习训练与保存将模型读取到python环境中！frommaiximportnnfrommaiximportcamera,displayimporttimefrommaix.nn.app.classifierimportClassifierclassSelf_learn:model={\"param\":\"/home/model/resnet18_1000_awnn.param\",\"bin\":\"/home/model/resnet18_1000_awnn.bin\"}options={\"model_type\":\"awnn\",\"inputs\":{\"input0\":(224,224,3)},\"outputs\":{\"190\":(1,1,512)},\"mean\":[127.5,127.5,127.5],\"norm\":[0.0176,0.0176,0.0176],}class_num=3#学习类别sample_num=15#学习类别总数量curr_class=0curr_sample=0def__init__(self):frommaiximportnnfrommaix.nn.app.classifierimportClassifierprint(\"--loadmodel:\",self.model)self.m=nn.load(self.model,opt=self.options)print(\"--loadok\")print(\"--loadclassifier\")self.classifier=Classifier(self.m,self.class_num,self.sample_num,512,224,224)print(\"--loadok\")globalself_learnself_learn=Self_learn()[ rpyc-kernel ]( running at Thu Jan 20 09:45:15 2022 )\n-- load model: {'param': '/home/model/resnet18_1000_awnn.param', 'bin': '/home/model/resnet18_1000_awnn.bin'}\n-- load ok\n-- load classifier\n-- load ok###添加分类的类别通过摄像头拍摄物体2秒来进行添加，当画面卡住不动的时候，就需要移动到下一个类别等待摄像头启动，进行添加>一下代码只能添加3个类别，模型是没有上限的importtimefrommaiximportnnfrommaiximportcamera,displayforxinrange(3):t=time.time()whileTrue:if(time.time()-t)>2:img=camera.capture()AI_img=img.copy().resize(224,224)self_learn.classifier.add_class_img(AI_img)display.show(img)time.sleep(2)print(\"addok!\")breakimg=camera.capture()display.show(img)add ok!###制作模型训练的数据集运行代码之后，通过每个物品给摄像头拍摄2秒，当画面卡住不动的时候就可以移动下一个物品，进行拍摄数据集importtimefrommaiximportnnfrommaiximportcamera,displayforxinrange(3):t=time.time()whileTrue:if(time.time()-t)>2:foriinrange(5):img=camera.capture()AI_img=img.copy().resize(224,224)self_learn.classifier.add_sample_img(AI_img)display.show(img)time.sleep(2)breakimg=camera.capture()AI_img=img.copy().resize(224,224)display.show(img)进行图片自学习self_learn.classifier.train()print(\"trainover\")[ rpyc-kernel ]( running at Thu Jan 20 09:31:48 2022 )训练结束后保存模型self_learn.classifier.save(\"./module.bin\")print(\"saveover\")[ rpyc-kernel ]( running at Wed Jan 19 15:43:36 2022 )开始进行分类验证importtimefrommaiximportnnfrommaiximportcamera,displaywhileTrue:img=camera.capture()AI_img=img.copy().resize(224,224)idx,distance=self_learn.classifier.predict(AI_img)msg=\"predictclass:\"+str(idx+1)+\",conf:\"+str(100-distance)print(msg)img.draw_string(10,10,msg,color=(255,0,0))display.show(img)predict class: 2, conf: 88##读取自学习模型frommaiximportnnfrommaiximportcamera,displayimporttimefrommaix.nn.app.classifierimportClassifierfrommaix.nn.app.classifierimportloadclassSelf_learn:model={\"param\":\"/home/model/resnet18_1000_awnn.param\",\"bin\":\"/home/model/resnet18_1000_awnn.bin\"}options={\"model_type\":\"awnn\",\"inputs\":{\"input0\":(224,224,3)},\"outputs\":{\"190\":(1,1,512)},\"mean\":[127.5,127.5,127.5],\"norm\":[0.0176,0.0176,0.0176],}class_num=3#学习类别sample_num=15#学习类别总数量curr_class=0curr_sample=0def__init__(self):frommaiximportnnfrommaix.nn.app.classifierimportClassifierfrommaix.nn.app.classifierimportloadimportos.pathifos.path.isfile(\"./module.bin\"):print(\"--loadmodel:\",self.model)self.m=nn.load(self.model,opt=self.options)print(\"--loadok\")print(\"--loadclassifier\")self.classifier=load(self.m,\"./module.bin\")print(\"--loadok\")else:print(\"nothavemodel!\")print(\"pleaserunnn_self_learn_classifier.pygetmodel!\")globalself_learnself_learn=Self_learn()[ rpyc-kernel ]( running at Wed Jan 19 15:44:46 2022 )\n-- load model: {'param': '/home/model/resnet18_1000_awnn.param', 'bin': '/home/model/resnet18_1000_awnn.bin'}\n-- load ok\n-- load classifier\n-- load ok自学习预测importtimefrommaiximportnnfrommaiximportcamera,displaywhileTrue:img=camera.capture()AI_img=img.copy().resize(224,224)idx,distance=self_learn.classifier.predict(AI_img)msg=\"predictclass:\"+str(idx+1)+\",conf:\"+str(100-distance)#print(msg)img.draw_string(10,10,msg,color=(255,0,0))display.show(img)"}, "/soft/maixpy3/zh/usage/AI_net/find_face.html": {"title": "人脸检测", "content": "|更新时间|负责人|内容|备注||---|---|---|---||2021年12月2日|Rui|初次编写文档|----||2022年12月15日|Rui|修改文档的编写方式|使用Jupyternotebook进行编写文档||2022年1月18日|Rui|修改文档，增加效果图|通过测试的平台有MaixII-Dock，使用的是MaixPy30.4.0|##运行效果<palign=\"center\"><iframesrc=\"//player.bilibili.com/player.html?aid=720490332&bvid=BV15Q4y1r7HV&cid=405128041&page=1\"scrolling=\"no\"border=\"0\"frameborder=\"no\"framespacing=\"0\"allowfullscreen=\"true\"style=\"max-width:640px;max-height:480px;\"></iframe></p>##准备-在[MaixHub](https://www.maixhub.com/modelInfo?modelId=26)上获取模型文件和运行源码（最新版本的系统内置了模型文件`/home/model/face/yolo2_face_awnn.*`）-确认MaixPy3版本为0.4.3以上-使用的硬件为MaixII-Dock-内存卡内是最新版本的镜像系统-插卡启动硬件##运行开始人脸检测读取人脸检测模型文件，并部署到MaixII-Dock上classface:labels=[\"person\"]anchors=[1.19,1.98,2.79,4.59,4.53,8.92,8.06,5.29,10.32,10.65]m={\"param\":\"/home/model/face/yolo2_face_awnn.param\",\"bin\":\"/home/model/face/yolo2_face_awnn.bin\"}options={\"model_type\":\"awnn\",\"inputs\":{\"input0\":(224,224,3)},\"outputs\":{\"output0\":(7,7,(1+4+1)*5)},\"mean\":[127.5,127.5,127.5],\"norm\":[0.0078125,0.0078125,0.0078125],}def__init__(self):frommaiximportnnfrommaix.nnimportdecoderself.model=nn.load(self.m,opt=self.options)self.yolo=decoder.Yolo2(len(self.labels),self.anchors,net_in_size=(224,224),net_out_size=(7,7))def__del__(self):delself.modeldelself.yologlobalFaceFace=face()print(Face)[ rpyc-kernel ]( running at Thu Jan 20 13:46:59 2022 )\n<rpyc.core.protocol.face object at 0xd8d7f8>运行网络，进行人脸检测frommaiximportcamera,displayfrommaix.nnimportdecoderlabels=[\"person\"]whileTrue:img=camera.capture().resize(224,224)out,=Face.model.forward(img,quantize=True,layout=\"hwc\")boxes,probs=Face.yolo.run(out,nms=0.3,threshold=0.5,img_size=(224,224))iflen(boxes):fori,boxinenumerate(boxes):img.draw_rectangle(box[0],box[1],box[0]+box[2],box[1]+box[3],(255,0,0),1)display.show(img)else:display.show(img)"}, "/soft/maixpy3/zh/usage/AI_net/face_recognize.html": {"title": "人脸识别", "content": "|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|Rui|初次编写文档|----||2022年1月8日|dianjixz|修改文档的编写方式<br>调整运行逻辑|使用Jupyternotebook进行编写文档||2022年1月18日|Rui|修改文档，增加效果图|通过测试的平台有MaixII-Dock，使用的是MaixPy30.4.0|##运行效果<palign=\"center\"><iframesrc=\"//player.bilibili.com/player.html?aid=714915927&bvid=BV1MX4y1g7cE&cid=321380350&page=1\"scrolling=\"no\"border=\"0\"frameborder=\"no\"framespacing=\"0\"allowfullscreen=\"true\"style=\"max-width:640px;max-height:480px;\"></iframe></p>##准备-在[MaixHub](https://www.maixhub.com/modelInfo?modelId=29)上获取模型文件和运行源码（最新版本的系统内置了模型文件`/home/model/face_recognize/*`）-确认MaixPy3版本为0.4.0以上-使用的硬件为MaixII-Dock-内存卡内是最新版本的镜像系统-插卡启动硬件##人脸识别###读取模型文件并部署这里是最多同时检测3个人脸，需要识别更多人脸可以运行**附录**中的完整代码（带有按键控制的喔！）classFace_recognize:score_threshold=70#识别分数阈值input_size=(224,224,3)#输入图片尺寸input_size_fe=(128,128,3)#输入人脸数据feature_len=256#人脸数据宽度steps=[8,16,32]#channel_num=0#通道数量users=[]#初始化用户列表threshold=0.5#人脸阈值nms=0.3max_face_num=3#输出的画面中的人脸的最大个数names=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]#人脸标签定义model={\"param\":\"/home/model/face_recognize/model_int8.param\",\"bin\":\"/home/model/face_recognize/model_int8.bin\"}model_fe={\"param\":\"/home/model/face_recognize/fe_res18_117.param\",\"bin\":\"/home/model/face_recognize/fe_res18_117.bin\"}def__init__(self):frommaiximportnn,camera,image,displayfrommaix.nn.app.faceimportFaceRecognizeforiinrange(len(self.steps)):self.channel_num+=self.input_size[1]/self.steps[i]*(self.input_size[0]/self.steps[i])*2self.channel_num=int(self.channel_num)#统计通道数量self.options={#准备人脸输出参数\"model_type\":\"awnn\",\"inputs\":{\"input0\":self.input_size},\"outputs\":{\"output0\":(1,4,self.channel_num),\"431\":(1,2,self.channel_num),\"output2\":(1,10,self.channel_num)},\"mean\":[127.5,127.5,127.5],\"norm\":[0.0078125,0.0078125,0.0078125],}self.options_fe={#准备特征提取参数\"model_type\":\"awnn\",\"inputs\":{\"inputs_blob\":self.input_size_fe},\"outputs\":{\"FC_blob\":(1,1,self.feature_len)},\"mean\":[127.5,127.5,127.5],\"norm\":[0.0078125,0.0078125,0.0078125],}print(\"--loadmodel:\",self.model)self.m=nn.load(self.model,opt=self.options)print(\"--loadok\")print(\"--loadmodel:\",self.model_fe)self.m_fe=nn.load(self.model_fe,opt=self.options_fe)print(\"--loadok\")self.face_recognizer=FaceRecognize(self.m,self.m_fe,self.feature_len,self.input_size,self.threshold,self.nms,self.max_face_num)defmap_face(self,box,points):#将224*224空间的位置转换到240*240空间内deftran(x):returnint(x/224*240)box=list(map(tran,box))deftran_p(p):returnlist(map(tran,p))points=list(map(tran_p,points))returnbox,pointsdefrecognize(self,feature):#进行人脸匹配def_compare(user):#定义映射函数returnself.face_recognizer.compare(user,feature)#推测匹配分数score相关分数face_score_l=list(map(_compare,self.users))#映射特征数据在记录中的比对分数returnmax(enumerate(face_score_l),key=lambdax:x[-1])#提取出人脸分数最大值和最大值所在的位置def__del__(self):delself.face_recognizerdelself.m_fedelself.mglobalface_recognizerface_recognizer=Face_recognize()[ rpyc-kernel ]( running at Thu Jan 20 14:20:31 2022 )\n-- load model: {'param': '/home/model/face_recognize/model_int8.param', 'bin': '/home/model/face_recognize/model_int8.bin'}\n-- load ok\n-- load model: {'param': '/home/model/face_recognize/fe_res18_117.param', 'bin': '/home/model/face_recognize/fe_res18_117.bin'}\n-- load ok###寻找人脸需要先确定，可以检测到对应需要识别的人脸frommaiximportcamera,image,displaywhileTrue:img=camera.capture()#获取224*224*3的图像数据AI_img=img.copy().resize(224,224)faces=face_recognizer.face_recognizer.get_faces(AI_img.tobytes(),False)#提取人脸特征信息iffaces:forprob,box,landmarks,featureinfaces:disp_str=\"Unmarkedface\"bg_color=(255,0,0)font_color=(255,255,255)box,points=face_recognizer.map_face(box,landmarks)font_wh=img.get_string_size(disp_str)forpinpoints:img.draw_rectangle(p[0]-1,p[1]-1,p[0]+1,p[1]+1,color=bg_color)img.draw_rectangle(box[0],box[1],box[0]+box[2],box[1]+box[3],color=bg_color,thickness=2)img.draw_rectangle(box[0],box[1]-font_wh[1],box[0]+font_wh[0],box[1],color=bg_color,thickness=-1)img.draw_string(box[0],box[1]-font_wh[1],disp_str,color=font_color)display.show(img)###添加一张人脸运行代码之后，会直接添加检测到的所有人脸，需要单独的去添加人脸的信息，添加到人脸信息就会自动停止运行frommaiximportcamera,image,displayface_flage=1whileface_flage:img=camera.capture()#获取224*224*3的图像数据AI_img=img.copy().resize(224,224)faces=face_recognizer.face_recognizer.get_faces(AI_img.tobytes(),False)#提取人脸特征信息iffaces:forprob,box,landmarks,featureinfaces:iflen(face_recognizer.users)<len(face_recognizer.names):face_recognizer.users.append(feature)face_flage=0else:print(\"userfull\")disp_str=\"addface\"bg_color=(0,255,0)font_color=(0,0,255)box,points=face_recognizer.map_face(box,landmarks)font_wh=img.get_string_size(disp_str)forpinpoints:img.draw_rectangle(p[0]-1,p[1]-1,p[0]+1,p[1]+1,color=bg_color)img.draw_rectangle(box[0],box[1],box[0]+box[2],box[1]+box[3],color=bg_color,thickness=2)img.draw_rectangle(box[0],box[1]-font_wh[1],box[0]+font_wh[0],box[1],color=bg_color,thickness=-1)img.draw_string(box[0],box[1]-font_wh[1],disp_str,color=font_color)display.show(img)###识别人脸这时会将所识别的人脸和所添加的人脸信息进行对比，将对比得到相似度最高的人脸识别的正确人脸并用绿色框标记出来。frommaiximportcamera,image,displaywhileTrue:img=camera.capture()#获取224*224*3的图像数据AI_img=img.copy().resize(224,224)faces=face_recognizer.face_recognizer.get_faces(AI_img.tobytes(),False)#提取人脸特征信息iffaces:forprob,box,landmarks,featureinfaces:iflen(face_recognizer.users):#判断是否记录人脸maxIndex=face_recognizer.recognize(feature)ifmaxIndex[1]>face_recognizer.score_threshold:#判断人脸识别阈值,当分数大于阈值时认为是同一张脸,当分数小于阈值时认为是相似脸disp_str=\"{}\".format(face_recognizer.names[maxIndex[0]])bg_color=(0,255,0)font_color=(0,0,255)box,points=face_recognizer.map_face(box,landmarks)font_wh=img.get_string_size(disp_str)forpinpoints:img.draw_rectangle(p[0]-1,p[1]-1,p[0]+1,p[1]+1,color=bg_color)img.draw_rectangle(box[0],box[1],box[0]+box[2],box[1]+box[3],color=bg_color,thickness=2)img.draw_rectangle(box[0],box[1]-font_wh[1],box[0]+font_wh[0],box[1],color=bg_color,thickness=-1)img.draw_string(box[0],box[1]-font_wh[1],disp_str,color=font_color)else:disp_str=\"errorface\"bg_color=(255,0,0)font_color=(255,255,255)box,points=face_recognizer.map_face(box,landmarks)font_wh=img.get_string_size(disp_str)forpinpoints:img.draw_rectangle(p[0]-1,p[1]-1,p[0]+1,p[1]+1,color=bg_color)img.draw_rectangle(box[0],box[1],box[0]+box[2],box[1]+box[3],color=bg_color,thickness=2)img.draw_rectangle(box[0],box[1]-font_wh[1],box[0]+font_wh[0],box[1],color=bg_color,thickness=-1)img.draw_string(box[0],box[1]-font_wh[1],disp_str,color=font_color)else:#没有记录脸disp_str=\"errorface\"bg_color=(255,0,0)font_color=(255,255,255)box,points=face_recognizer.map_face(box,landmarks)font_wh=img.get_string_size(disp_str)forpinpoints:img.draw_rectangle(p[0]-1,p[1]-1,p[0]+1,p[1]+1,color=bg_color)img.draw_rectangle(box[0],box[1],box[0]+box[2],box[1]+box[3],color=bg_color,thickness=2)img.draw_rectangle(box[0],box[1]-font_wh[1],box[0]+font_wh[0],box[1],color=bg_color,thickness=-1)img.draw_string(box[0],box[1]-font_wh[1],disp_str,color=font_color)display.show(img)###删除一张人脸iflen(face_recognizer.users)>0:print(\"removeuser:\",face_recognizer.names[len(face_recognizer.users)-1])face_recognizer.users.pop()else:print(\"userempty\")###人脸保存将所添加的人脸信息保存到/root/目录下importpicklewithopen(\"/root/face_data.pickle\",'wb')asf:pickle.dump(face_recognizer.users,f)[ rpyc-kernel ]( running at Wed Jan 19 18:13:25 2022 )###加载人脸信息加载保存到/root/目录下的人脸信息importpicklewithopen(\"/root/face_data.pickle\",'rb')asf:face_recognizer.users=pickle.load(f)##附录下面是运行人脸识别的完整脚本代码，可以部署到MaixII-Dock直接运行，按下右键添加人脸信息，按下左键删除人脸信息，运行效果为上方的视频中frommaiximportnn,camera,image,displayfrommaix.nn.app.faceimportFaceRecognizeimporttimefromevdevimportInputDevicefromselectimportselectscore_threshold=70#识别分数阈值input_size=(224,224,3)#输入图片尺寸input_size_fe=(128,128,3)#输入人脸数据feature_len=256#人脸数据宽度steps=[8,16,32]#channel_num=0#通道数量users=[]#初始化用户列表names=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]#人脸标签定义model={\"param\":\"/home/model/face_recognize/model_int8.param\",\"bin\":\"/home/model/face_recognize/model_int8.bin\"}model_fe={\"param\":\"/home/model/face_recognize/fe_res18_117.param\",\"bin\":\"/home/model/face_recognize/fe_res18_117.bin\"}foriinrange(len(steps)):channel_num+=input_size[1]/steps[i]*(input_size[0]/steps[i])*2channel_num=int(channel_num)#统计通道数量options={#准备人脸输出参数\"model_type\":\"awnn\",\"inputs\":{\"input0\":input_size},\"outputs\":{\"output0\":(1,4,channel_num),\"431\":(1,2,channel_num),\"output2\":(1,10,channel_num)},\"mean\":[127.5,127.5,127.5],\"norm\":[0.0078125,0.0078125,0.0078125],}options_fe={#准备特征提取参数\"model_type\":\"awnn\",\"inputs\":{\"inputs_blob\":input_size_fe},\"outputs\":{\"FC_blob\":(1,1,feature_len)},\"mean\":[127.5,127.5,127.5],\"norm\":[0.0078125,0.0078125,0.0078125],}keys=InputDevice('/dev/input/event0')threshold=0.5#人脸阈值nms=0.3max_face_num=1#输出的画面中的人脸的最大个数print(\"--loadmodel:\",model)m=nn.load(model,opt=options)print(\"--loadok\")print(\"--loadmodel:\",model_fe)m_fe=nn.load(model_fe,opt=options_fe)print(\"--loadok\")face_recognizer=FaceRecognize(m,m_fe,feature_len,input_size,threshold,nms,max_face_num)defget_key():#按键检测函数r,w,x=select([keys],[],[],0)ifr:foreventinkeys.read():ifevent.value==1andevent.code==0x02:#右键return1elifevent.value==1andevent.code==0x03:#左键return2elifevent.value==2andevent.code==0x03:#左键连按return3return0defmap_face(box,points):#将224*224空间的位置转换到240*240空间内deftran(x):returnint(x/224*240)box=list(map(tran,box))deftran_p(p):returnlist(map(tran,p))points=list(map(tran_p,points))returnbox,pointsdefdarw_info(draw,box,points,disp_str,bg_color=(255,0,0),font_color=(255,255,255)):#画框函数box,points=map_face(box,points)font_wh=draw.get_string_size(disp_str)forpinpoints:draw.draw_rectangle(p[0]-1,p[1]-1,p[0]+1,p[1]+1,color=bg_color)draw.draw_rectangle(box[0],box[1],box[0]+box[2],box[1]+box[3],color=bg_color,thickness=2)draw.draw_rectangle(box[0],box[1]-font_wh[1],box[0]+font_wh[0],box[1],color=bg_color,thickness=-1)draw.draw_string(box[0],box[1]-font_wh[1],disp_str,color=font_color)defrecognize(feature):#进行人脸匹配def_compare(user):#定义映射函数returnface_recognizer.compare(user,feature)#推测匹配分数score相关分数face_score_l=list(map(_compare,users))#映射特征数据在记录中的比对分数returnmax(enumerate(face_score_l),key=lambdax:x[-1])#提取出人脸分数最大值和最大值所在的位置defrun():img=camera.capture()#获取224*224*3的图像数据AI_img=img.copy().resize(224,224)ifnotimg:time.sleep(0.02)returnfaces=face_recognizer.get_faces(AI_img.tobytes(),False)#提取人脸特征信息iffaces:forprob,box,landmarks,featureinfaces:key_val=get_key()ifkey_val==1:#右键添加人脸记录iflen(users)<len(names):print(\"adduser:\",len(users))users.append(feature)else:print(\"userfull\")elifkey_val==2:#左键删除人脸记录iflen(users)>0:print(\"removeuser:\",names[len(users)-1])users.pop()else:print(\"userempty\")iflen(users):#判断是否记录人脸maxIndex=recognize(feature)ifmaxIndex[1]>score_threshold:#判断人脸识别阈值,当分数大于阈值时认为是同一张脸,当分数小于阈值时认为是相似脸darw_info(img,box,landmarks,\"{}:{:.2f}\".format(names[maxIndex[0]],maxIndex[1]),font_color=(0,0,255,255),bg_color=(0,255,0,255))print(\"user:{},score:{:.2f}\".format(names[maxIndex[0]],maxIndex[1]))else:darw_info(img,box,landmarks,\"{}:{:.2f}\".format(names[maxIndex[0]],maxIndex[1]),font_color=(255,255,255,255),bg_color=(255,0,0,255))print(\"maybeuser:{},score:{:.2f}\".format(names[maxIndex[0]],maxIndex[1]))else:#没有记录脸darw_info(img,box,landmarks,\"errorface\",font_color=(255,255,255,255),bg_color=(255,0,0,255))display.show(img)if__name__==\"__main__\":importsignaldefhandle_signal_z(signum,frame):print(\"APPOVER\")exit(0)signal.signal(signal.SIGINT,handle_signal_z)whileTrue:run()"}, "/soft/maixpy3/zh/usage/AI_net/resnet.html": {"title": "1000种物品分类", "content": "|更新时间|负责人|内容|备注||---|---|---|---||2021年12月2日|Rui|初次编写文档|----||2022年12月15日|Rui|修改文档的编写方式|使用Jupyternotebook进行编写文档||2022年1月18日|Rui|修改文档，增加效果图|通过测试的平台有MaixII-Dock，使用的是MaixPy30.4.0|##流程**非小白用户**：获取Pytorch提供的标准模型-->使用ncnn转换模型结构-->使用Maixhub在线量化工具-->部署模型文件-->运行代码，开始进行分类识别（[具体教程](./../AI/resnet.md)）**小白用户**：完成准备工作的检查-->打开MaixPy3IDE-->运行3.usage_ai_nn.ipynb中的分类网络代码块##运行效果<palign=\"center\"><iframesrc=\"//player.bilibili.com/player.html?aid=886250113&bvid=BV1ZK4y1W7DM&cid=288110985&page=1\"scrolling=\"no\"border=\"0\"frameborder=\"no\"framespacing=\"0\"allowfullscreen=\"true\"style=\"max-width:640px;max-height:480px;\"></iframe></p>##准备-最新版本的系统内置了模型文件`/home/model/resnet18_1000_awnn.*`（可以自行[手动转换](./../../develop/resnet.md)）-确认MaixPy3版本为0.4.3以上-使用的硬件为MaixII-Dock-内存卡内是最新版本的镜像系统-插卡启动硬件##运行网络结构读取对应的模型文件，并部署到MaixII-Dock上classResnset:m={\"param\":\"/home/model/resnet18_1000_awnn.param\",\"bin\":\"/home/model/resnet18_1000_awnn.bin\"}options={\"model_type\":\"awnn\",\"inputs\":{\"input0\":(224,224,3)},\"outputs\":{\"output0\":(1,1,1000)},\"first_layer_conv_no_pad\":False,\"mean\":[127.5,127.5,127.5],\"norm\":[0.00784313725490196,0.00784313725490196,0.00784313725490196],}def__init__(self):frommaiximportnnself.model=nn.load(self.m,opt=self.options)def__del__(self):delself.modelglobalresnsetresnset=Resnset()[ rpyc-kernel ]( running at Wed Jan 19 16:18:45 2022 )进行分类识别print(resnset.model)frommaiximportcamera,nn,displayfromhome.res.classes_labelimportlabelswhileTrue:img=camera.capture().resize(224,224)out,=resnset.model.forward(img,quantize=True)msg=\"{:.2f}:{}\".format(out.max(),labels[out.argmax()])img.draw_string(0,0,str(msg),1,(255,0,0),1)display.show(img)"}, "/soft/maixpy3/zh/usage/AI_net/Edge_detection.html": {"title": "边缘检测", "content": "|更新时间|负责人|内容|备注||---|---|---|---||2021年12月2日|Rui|初次编写文档|----||2022年12月15日|Rui|修改文档的编写方式|使用Jupyternotebook进行编写文档||2022年1月18日|Rui|修改文档，增加效果图|通过测试的平台有MaixII-Dock，使用的是MaixPy30.4.0|通过(卷积/conv)实现sobel(索贝尔)边缘检测（目前是只能在MaixII-Dock上进行部署）##运行效果![](./../asserts/sobel_v831.jpg)<palign=\"center\"><iframesrc=\"//player.bilibili.com/player.html?aid=808373936&bvid=BV1F34y1q7TB&cid=487496493&page=1\"scrolling=\"no\"border=\"0\"frameborder=\"no\"framespacing=\"0\"allowfullscreen=\"true\"style=\"width:640px;height:480px;\"></iframe></p>##准备-在[MaixHub](https://www.maixhub.com/modelInfo?modelId=24)上获取模型文件和运行源码（最新版本的系统内置了模型文件`/home/model/sobel_int8.*`）-确认MaixPy3版本为0.4.3以上-使用的硬件为MaixII-Dock-内存卡内是最新版本的镜像系统-插卡启动硬件##边缘检测读取模型文件，并部署到MaixII-Dock上classEdge:model={\"param\":\"/home/model/sobel_int8.param\",\"bin\":\"/home/model/sobel_int8.bin\"}input_size=(224,224,3)output_size=(222,222,3)options={\"model_type\":\"awnn\",\"inputs\":{\"input0\":input_size},\"outputs\":{\"output0\":output_size},\"mean\":[127.5,127.5,127.5],\"norm\":[0.0078125,0.0078125,0.0078125],}def__init__(self):frommaiximportnnprint(\"--loadmodel:\",self.model)self.model=nn.load(self.model,opt=self.options)print(\"--loadok\")def__del__(self):delself.modeldelself.yologlobalmm=Edge()[ rpyc-kernel ]( running at Fri Mar 11 14:07:06 2022 )\n-- load model: {'param': '/home/model/sobel_int8.param', 'bin': '/home/model/sobel_int8.bin'}\n-- load okException ignored in: <function Edge.__del__ at 0x26d9478>\nTraceback (most recent call last):\n  File \"<string>\", line 29, in __del__\nAttributeError: yolo开始进行边缘检测frommaiximportcamera,displayimportnumpyasnpwhileTrue:img=camera.capture().resize(224,224)out,=m.model.forward(img,quantize=True,layout=\"hwc\")out=out.astype(np.float32).reshape(m.output_size)out=(np.ndarray.__abs__(out)*255/out.max()).astype(np.uint8)data=out.tobytes()img2=img.load(data,(222,222),mode=\"RGB\")display.show(img2)##了解更多可以查看Neutree的[博客](https://neucrack.com/p/377)，了解边缘检测开发过程"}, "/soft/maixpy3/zh/usage/AI_net/number_recognize.html": {"title": "数字识别", "content": "|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|Rui|初次编写文档|----||2022年1月18日|dianjixz|修改文档的编写方式|使用Jupyternotebook进行编写文档||2022年1月19日|Rui|修改文档，增加效果图|通过测试的平台有MaixII-Dock，使用的是MaixPy30.4.0|>内容参考至Neutree的博客[使用V831AI检测数字卡片](https://neucrack.com/p/384)##背景数字识别是2021年电赛F题**智能送药小车**，节选题目部分内容![](./../asserts/number_1.jpg)**识别的数字**为：![](./../asserts/number.jpg)##运行效果<palign=\"center\"><iframesrc=\"//player.bilibili.com/player.html?aid=678372862&bvid=BV18m4y1S7qk&cid=488266454&page=1\"scrolling=\"no\"border=\"0\"frameborder=\"no\"framespacing=\"0\"allowfullscreen=\"true\"style=\"max-width:640px;max-height:480px;\"></iframe></p>##准备-在[MaixHub](https://www.maixhub.com/modelInfo?modelId=32)上获取模型文件，并将模型文件存放到U盘中-确认MaixPy3版本为0.4.0以上-使用的硬件为MaixII-Dock-内存卡内是最新版本的镜像系统-插卡启动硬件##数字识别将模型读取到python环境中！classNumber_recognition:labels=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"]anchors=[2.44,2.25,5.03,4.91,3.5,3.53,4.16,3.94,2.97,2.84]model={\"param\":\"/root/number_awnn.param\",\"bin\":\"/root/number_awnn.bin\"}options={\"model_type\":\"awnn\",\"inputs\":{\"input0\":(224,224,3)},\"outputs\":{\"output0\":(7,7,(1+4+len(labels))*5)},\"mean\":[127.5,127.5,127.5],\"norm\":[0.0078125,0.0078125,0.0078125],}w=options[\"inputs\"][\"input0\"][1]h=options[\"inputs\"][\"input0\"][0]def__init__(self):frommaiximportnnfrommaix.nnimportdecoderself.m=nn.load(self.model,opt=self.options)self.yolo2_decoder=decoder.Yolo2(len(self.labels),self.anchors,net_in_size=(self.w,self.h),net_out_size=(7,7))defmap_face(self,box):#将224*224空间的位置转换到240*240空间内deftran(x):returnint(x/224*240)box=list(map(tran,box))returnboxglobalnumber_recognitionnumber_recognition=Number_recognition()print(\"initover\")[ rpyc-kernel ]( running at Wed Jan 19 19:32:13 2022 )\ninit over开始数字识别frommaiximportcamera,display,nn,imagefrommaix.nnimportdecoderimporttimewhileTrue:t=time.time()img=camera.capture()ifnotimg:time.sleep(0.01)continueAI_img=img.copy().resize(224,224)t=time.time()out=number_recognition.m.forward(AI_img.tobytes(),quantize=True,layout=\"hwc\")t=time.time()boxes,probs=number_recognition.yolo2_decoder.run(out,nms=0.3,threshold=0.5,img_size=(240,240))t=time.time()fori,boxinenumerate(boxes):class_id=probs[i][0]prob=probs[i][1][class_id]disp_str=\"{}:{:.2f}%\".format(number_recognition.labels[class_id],prob*100)font_wh=img.get_string_size(disp_str)box=number_recognition.map_face(box)img.draw_rectangle(box[0],box[1],box[0]+box[2],box[1]+box[3],color=(255,0,0),thickness=2)img.draw_rectangle(box[0],box[1]-font_wh[1],box[0]+font_wh[0],box[1],color=(255,0,0))img.draw_string(box[0],box[1]-font_wh[1],disp_str,color=(255,0,0))t=time.time()display.show(img)"}, "/soft/maixpy3/zh/usage/hardware/PWM.html": {"title": "Linux PWM 的使用", "content": "---|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|Rui|初次编写文档|---||2022年1月8日|Rui|修改文档的编写方式|使用Jupyternotebook进行编写文档||2022年1月18日|Rui|修改文档，增加效果图|外设文档通过测试的平台有MaixII-Dock,使用的是MaixPy30.4.0|MaixPy3把Linux系统中的PWM的使用方法进行封装和简化使用，让用户使用起来更加的简单##使用方式PWM的使用方式和GPIO的类似，需要根据管脚定义图确定所使用的PWM通道序号，下面以MaixII-Dock为例子讲述如何使用MaixPy3中的PWM###准备查看开发板的管脚定义图，选择PWM输出通道序号，PWM-x是指PWM的输出通道序号![MaixII-Dock管脚图](./../asserts/M2Dock_pin.jpg)这里选择使用PWM-6###开始先将PWM-6实例化，设置周期和占空比，最后是使能PWM，就可以输出了，具体代码看下面frommaiximportpwmimporttimepwm6=pwm.PWM(6)pwm6.export()pwm6.period=20000000#表示pwm的周期，单位nspwm6.duty_cycle=500000#表示占空比，单位nspwm6.enable=True#表示是否使能pwmfortinrange(3):foriinrange(500000,15000000,+100000):pwm6.duty_cycle=itime.sleep(0.05)foriinrange(15000000,500000,-100000):pwm6.duty_cycle=itime.sleep(0.05)[ rpyc-kernel ]( running at Mon Jan 17 16:58:42 2022 )别的开发板使用方式是同样的流程，包括树莓派>注明：>建议小白使用在对应开发管脚定义图上的对应PWM通道，别的通道需要自行查看[LinuxPWM](https://www.baidu.com/s?ie=UTF-8&wd=Linux%20PWM)使用方法。##PWM用途1.呼吸灯![PWM](./../asserts/PWM.gif)2.PWM可以作为电机驱动控制信号，驱动舵机。但是外接电机的时候需要做好电源隔离，不要直接将舵机接到开发板上，舵机产生的反向电流会把开发板上的芯片给击穿。![](./../asserts/PWM_1.gif)##了解更多更多关于LinuxPWM的可以查看大老鼠写的[博客](https://www.cnblogs.com/juwan/p/14343977.html)"}, "/soft/maixpy3/zh/usage/hardware/GPIO.html": {"title": "GPIO 的使用", "content": "---|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|Rui|初次编写文档|----||2022年1月8日|Rui|修改文档的编写方式|使用Jupyternotebook进行编写文档||2022年1月18日|Rui|修改文档，增加效果图|通过测试的平台有MaixII-Dock、树莓派、maixsense，使用的是MaixPy30.4.0|##简介GPIO,全称General-PurposeInput/Output（通用输入输出），是一种软件运行期间能够动态配置和控制的通用引脚。所有的GPIO在上电后的初始状态都是输入模式，可以控制电平的输出和获取外设的电平变化。##使用方法不同的平台上使用GPIO只需要使用gpio.load()加载对应的配置，才能进行GPIO的相关操作。例如在MaixII-Dock平台上使用，使用`gpio.load(gpio.m2dock)`加载配置，对GPIO6进行是实例化（对应图中的PWM-6）![111](./../asserts/M2Dock_pin.jpg)###GPIO输出模式设置GPIO-6输出高电平，具体代码如下：importtimefrommaiximportgpiogpio.load(gpio.m2dock)led=gpio.gpio(6)print(led.source)foriinrange(3):led.set_value(0)print(led.get_value())time.sleep(0.5)led.set_value(1)print(led.get_value())time.sleep(0.5)led.release()[ rpyc-kernel ]( running at Wed Jan  5 17:30:51 2022 )\nGPIO chip 1 bank H line 6\n0\n1\n0\n1\n0\n1接上一个LED灯，运行效果如下![GPIO](./../asserts/GPIO.gif)>没有LED灯的，可以通过直接操作GPIO-14来控制板载对于其他的开发板同理，我们只需要通过查看管脚定义图或者是原理图来获取到GPIO_line、GPIO_bank这两个参数，再通过查询可使用的gpio_chip，就可以通过MaixPy3来进行GPIO的控制。###GPIO输入模式>后期也许会优化成不需要设置模式将GPIO设置成输入模式，才能获取外设的电平变化。在将GPIO实例化的时候添加多一个参数，来初始化GPIO的模式。具体代码为：```pythonfrommaiximportgpioled=gpio.gpio(6,\"H\",1,2)```2为设置成输入模式，该参数默认为1，即输出模式|API|功能||---|---||gpio.load()|加载配置项||gpio.set_value()|设置管脚电平||gpio.get_value()|获取管脚电平|>当导入配置项之后，发现所对应的GPIO管脚并不能使用的时候，需要自行使用下面的[手动配置](#了解更多)方式，有的GPIO管脚不建议使用##了解更多Linux系统中，使用GPIO作为电平的输出口，我们需要关注[GPIO_line、GPIO_bank和GPIO_chip](https://www.baidu.com/s?ie=utf-8&wd=GPIO_line%20%20GPIO_bank%20GPIO_chip)，这个三个参数。以上面的例程为例子来说，使用MaixII-Dock上的GPIO6，通过查看开发板上引出口的丝印，可以知道GPIO6绑定在PH6的这个管脚上。通过查看[V831_PIN功能介绍](https://thoughts.teambition.com/share/600659e9823a3d004a4e1c7a#slate-title)得知，V831只能使用gpiochip1。这时我们知道了三个参数分别为6、H和1。这时可以使用以下的代码进行GPIO的实例化frommaiximportgpioimporttimeled=gpio.gpio(6,\"H\",1)print(led.source)foriinrange(3):led.set_value(0)print(led.get_value())time.sleep(0.5)led.set_value(1)print(led.get_value())time.sleep(0.5)led.release()[ rpyc-kernel ]( running at Wed Jan  5 17:31:00 2022 )\nGPIO chip 1 bank H line 6\n0\n1\n0\n1\n0\n1>如果gpio_chip值选择错误了，就会报`lineoffsetoutofrange`错误>更多的关于Linux_gpio的使用可以查看[juwan](https://www.cnblogs.com/juwan/p/14336100.html)的博客"}, "/soft/maixpy3/zh/usage/hardware/ADC.html": {"title": "ADC 的使用", "content": "---|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|Rui|初次编写文档|---||2022年1月8日|Rui|修改文档的编写方式|使用Jupyternotebook进行编写文档||2022年1月18日|Rui|修改文档，增加效果图|外设文档通过测试的平台有MaixII-Dock，使用的是MaixPy30.4.0||2022年1月19日|dalaoshu|修订具体描述|由于ADC相对SOCLinux来说是一个特殊的功能，在MaixPy3的设计里不通用。|ADC通讯协议，目前只是针对MaixII-Dock进行开发的，其他芯片或平台需要仔细阅读数据手册来确认是否支持。##使用方法###准备查看对应开发板上的管脚定义图或者是文件，如MaixII-Dock管脚定义图所示，将ADC设备接入到GPADC0的管脚上![111](./../asserts/M2Dock_pin.jpg)###代码根据数据手册可知V831数据地址0x05070080处有一个12bit（0-4095）的adc引脚，但该引脚默认被当做adc-key使用，使得一个引脚可以支持多个按键事件。定义MaixII-DockADC模块classv83x_ADC():def__init__(self,addr=b\"0x05070080\")->None:self.addr=addrself.path=\"/sys/class/sunxi_dump/dump\"self.file=open(self.path,\"wb+\")self.last=self.value()def__del__(self):try:ifself.file:self.file.close()delself.fileexceptExceptionase:passdefvalue(self):self.file.write(b\"0x05070080\")self.file.seek(0)returnint(self.file.read()[:-1],16)globalv83x_ADCv83x_ADC=v83x_ADC()使用ADC进行是设备通讯importtimefrommaiximportdisplay,imagev831_adc0=v83x_ADCwhileTrue:time.sleep(0.1)tmp=image.Image().new((240,240),(0x2c,0x3e,0x50),\"RGB\")val=v831_adc0.value()print(val)img=image.Image().open('/home/res/logo.png')tmp.draw_image(img,50,40,alpha=1).draw_string(20,200,\"adc0:\"+str(val),1,(0xbd,0xc3,0xc7))display.show(tmp)###运行效果**旋钮控制**![](./../asserts/adc-1.gif)**触控检测**![](./../asserts/adc-2.gif)**光照测量**![](./../asserts/adc-3.gif)##了解更多[什么是ADC](https://baike.baidu.com/item/%E6%A8%A1%E6%8B%9F%E6%95%B0%E5%AD%97%E8%BD%AC%E6%8D%A2%E5%99%A8/5382125?fr=aladdin)关于[LinuxADC](https://www.baidu.com/s?ie=utf-8&f=8&rsv_bp=1&tn=baidu&wd=linux%20ADC&oq=AD%2526lt%253B&rsv_pq=e7716f6c0000714c&rsv_t=628f6V5N5NUB2ky3bv1AhbIkN%2FFaocfP4Kb9JFMQmgvAQFoNlb%2Fv3y7fEwE&rqlang=cn&rsv_enter=1&rsv_dl=tb&rsv_sug3=9&rsv_sug1=5&rsv_sug7=100&rsv_sug2=0&rsv_btype=t&inputT=3109&rsv_sug4=3697)"}, "/soft/maixpy3/zh/usage/hardware/.ipynb_checkpoints/I2C-checkpoint.html": {"title": "Linux I2C 的使用", "content": "---MaixPy3把Linux系统中的I2C的使用方法进行封装和简化使用，让用户使用起来更加的简单。##使用方法目前MaixPy3所封装的I2C只有主机模式，还不能使用从机模式。###准备使用之前需要将硬件连接好，将SDL和SDA的两个数据线连接到开发板上的对应的SDA和SDL的管脚上。通过查看开发板上的**管脚定义图**，确定所接上的I2C总线的序号，一般是以I2C-x或者是SDL.x、SDA.x的形式标示，x为总线序号。如**树莓派**中的管脚定义图，这里的SDA.1和SCL.1指是的I2C-1的总线![](./../../assets/linux/I2C/I2C-1.png)###连接**扫描设备**查看总线上的设备地址(返回十进制的数据)frommaiximporti2cprint(i2c.scan())[ rpyc-kernel ]( running at Wed Jan  5 17:22:45 2022 )\n[38]**实例化设备**`/dev/i2c-x`是指所使用的I2C总线序号frommaiximporti2ci2c=i2c.I2C('/dev/i2c-2',0x26)[ rpyc-kernel ]( running at Wed Jan  5 17:22:49 2022 )**读取设备寄存器信息**frommaiximporti2ci2c=i2c.I2C('/dev/i2c-2',0x26)print(i2c.read(0x1,1))[ rpyc-kernel ]( running at Wed Jan  5 17:22:53 2022 )\nbytearray(b'\\x13')更多的使用方法，请看I2CAPI文档##了解更多MaixPy3中的i2c是基于libi2c进行封装的，想要了解更加多，可以自行查阅libi2c。"}, "/soft/maixpy3/zh/usage/hardware/.ipynb_checkpoints/GPIO-checkpoint.html": {"title": "GPIO 的使用", "content": "---##简介GPIO,全称General-PurposeInput/Output（通用输入输出），是一种软件运行期间能够动态配置和控制的通用引脚。所有的GPIO在上电后的初始状态都是输入模式，可以通过软件设为上拉或下拉，也可以设置为中断脚，驱动强度都是可编程的。Maixpy3通过将GPIO的一些复杂使用方法进行了封装，并进行简化，让用户使用起来更加方便。##使用方法Maixpy3目前适配了市面上的一些`Linux系统开发板`，对不同的板子进行了不同的封装。在使用之前，只需要加载使用的型号即可（不加载默认是使用树莓派配置）下面以**MaixII-Dock**为例，讲述如何使用，先上代码importtimefrommaiximportgpiogpio.load(gpio.m2dock)led=gpio.gpio(6)print(led.source)foriinrange(3):led.set_value(0)print(led.get_value())time.sleep(0.5)led.set_value(1)print(led.get_value())time.sleep(0.5)led.release()[ rpyc-kernel ]( running at Wed Jan  5 17:30:51 2022 )\nGPIO chip 1 bank H line 6\n0\n1\n0\n1\n0\n1通过查看MaixII-Dock开发板的[管脚定义图](/hardware/zh/maixII/M2/resources.html#硬件参数)，一共有5个引出的GPIO，这里使用MaixII-Dock开发板上的GPIO6管脚。在对管脚进行操作之前，需要使用`gpio.load()`加载配置项。将使用的GPIO管脚实例化，就能直接调用API对其进行直接的操作。目前GPIO只能使用于设置高低电平和获取当前管脚的状态|API|功能||---|---||gpio.load()|加载配置项||gpio.set_value()|设置管脚电平||gpio.get_value()|获取管脚电平|>其他适配过MaixPy3的开发板，使用方法同理。##了解更多Linux系统中，使用GPIO作为电平的输出口，我们需要关注[GPIO_line、GPIO_bank和GPIO_chip](https://www.baidu.com/s?ie=utf-8&wd=GPIO_line%20%20GPIO_bank%20GPIO_chip)，这个三个参数。以上面的例程为例子来说，使用MaixII-Dock上的GPIO6，通过查看开发板上引出口的丝印，可以知道GPIO6绑定在PH6的这个管脚上。通过查看[V831_PIN功能介绍](https://thoughts.teambition.com/share/600659e9823a3d004a4e1c7a#slate-title)得知，V831只能使用gpiochip1。这时我们知道了三个参数分别为6、H和1。这时可以使用以下的代码进行GPIO的实例化frommaiximportgpioimporttimeled=gpio.gpio(6,\"H\",1)print(led.source)foriinrange(3):led.set_value(0)print(led.get_value())time.sleep(0.5)led.set_value(1)print(led.get_value())time.sleep(0.5)led.release()[ rpyc-kernel ]( running at Wed Jan  5 17:31:00 2022 )\nGPIO chip 1 bank H line 6\n0\n1\n0\n1\n0\n1对于其他的开发板同理，我们只需要通过查看管脚定义图或者是原理图来获取到GPIO_line、GPIO_bank这两个参数，再通过查询可使用的gpio_chip，就可以通过MaixPy3来进行GPIO的控制。>如果gpio_chip值选择错误了，就会报`lineoffsetoutofrange`错误>更多的关于Linux_gpio的使用可以查看[juwan](https://www.cnblogs.com/juwan/p/14336100.html)的博客"}, "/soft/maixpy3/zh/usage/hardware/event.html": {"title": "输入事件设备", "content": "---|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|Rui|初次编写文档|---||2022年1月8日|Rui|修改文档的编写方式|使用Jupyternotebook进行编写文档||2022年1月18日|Rui|修改文档，增加效果图|外设文档通过测试的平台有MaixII-Dock，使用的是MaixPy30.4.0|输入事件是Linux系统中都存在的一种特殊设备（/dev/event/input），例如点击鼠标、移动鼠标、敲击键盘，都是通过事件检测进行的。我们也将事件检测给封装到MaixPy3当中，可以直接进行使用减少繁琐的操作。##使用方法###准备接上事件设备，例如树莓派，接上键盘鼠标等事件检测设备。对于MaixII-Dock，开发板上的按键是两个事件设备![111](./../asserts/M2Dock_pin.jpg)###代码下面是在MaixII-Dock上运行的代码，用于检测两个按键的输入。如果外接别的设备，这需要修改`event.InputDevice()`中的参数。frommaiximporteventfromselectimportselectcount=0dev=event.InputDevice('/dev/input/event0')whileTrue:select([dev],[],[])foreventindev.read():#print(event)ifevent.code==0x02:print('presskeyS1')ifevent.code==0x03:print('presskeyS2')ifevent.value==1andevent.code!=0:count+=1print('presssum:',count)[ rpyc-kernel ]( running at Mon Jan 17 18:30:27 2022 )\npress key S1\npress sum: 1\npress key S1\npress key S2\npress sum: 2\npress key S2\npress key S1\npress sum: 3\npress key S1\npress key S2\npress sum: 4\npress key S2\npress key S1\npress sum: 5\npress key S1\npress key S2\npress sum: 6\npress key S2运行代码之后，按下按键则会有内容打印出来通过`/dev/input/event0`进行事件设备的选择，可以通过`os.system(\"ls/dev/input/\")`进行查看接入了多少事件设备>详细请看[python-evdev](https://python-evdev.readthedocs.io/)或了解底层linuxevdev输入子系统。"}, "/soft/maixpy3/zh/usage/hardware/UART.html": {"title": "Linux UART 的使用", "content": "---|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|Rui|初次编写文档|---||2022年1月8日|Rui|修改文档的编写方式|使用Jupyternotebook进行编写文档||2022年1月18日|Rui|修改文档，增加效果图|外设文档通过测试的平台有MaixII-Dock,使用的是MaixPy30.4.0|##UART使用教程在Linux系统中，串口是以设备的形式存在（/dev/ttyS*），所使用的方式和原来的单片机方式有所不同。这是系统标准的UART通讯，和Linux系统中的串口操作相似。下面以MaixII-Dock为例子，来简单的简述一下如何使用UART。###准备通过查看开发板的管脚定义图，确定需要使用的UART通道。下面的代码是使用MaixII-Dock的UART-1通道>对于MaixII-Dock，不要使用UART-0通道来进行串口通讯。这个串口是直连芯片，会有一些其他数据吞吐![MaixII-Dock管脚图](./../asserts/M2Dock_pin.jpg)将MaixII-Dock上UART-1TX和UART-1RX短接即可进行串口通讯测试![](./../asserts/UART.jpg)###开始运行下列代码，即可进行串口通讯，别的开发板用法同理importserialser=serial.Serial(\"/dev/ttyS1\",115200)#连接串口print('serialteststart...')ser.write(b\"HelloWrold!!!\\n\")#输入需要通讯的内容foriinrange(3):ser.setDTR(True)ser.setRTS(True)tmp=ser.readline()print(tmp)ser.write(tmp)ser.setDTR(False)ser.setRTS(False)[ rpyc-kernel ]( running at Mon Jan 17 17:12:46 2022 )\nserial test start ...\nb'Hello Wrold !!!\\n'\nb'Hello Wrold !!!\\n'\nb'Hello Wrold !!!\\n'代码中的`/dev/ttyS1`是指串口通道1，不同的开发板，串口的表示方式不一样，请自行查看对应开发板的串口表达方式这是标准Python的串口库，更多的使用查看[Pythonserial](https://pypi.org/project/pyserial/)##UART用途这是操作系统的标准URAT，可以和单片机进行串口通讯，也可以对带有串口协议的设备、外设通讯。"}, "/soft/maixpy3/zh/usage/hardware/SPI.html": {"title": "Linux SPI 的使用", "content": "---|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|Rui|初次编写文档|---||2022年1月8日|Rui|修改文档的编写方式|使用Jupyternotebook进行编写文档||2022年1月18日|Rui|修改文档，增加效果图|外设文档通过测试的平台有MaixII-Dock，使用的是MaixPy30.4.0|##使用教程在Linux系统中，SPI是以设备的形式存在（/dev/spidevX.X），所使用的方式和原来的单片机方式有所不同。下面以MaixII-Dock为例子，来简单的简述一下如何使用SPI。###准备通过查看开发板的管脚定义图，确定自己使用的SPI通道序号，片选序号。###开始![MaixII-Dock管脚图](./../asserts/M2Dock_pin.jpg)以MaixII-Dock为例。查看MaixII-Dock管脚图，只引出了一个SPI通道，使用的是SPI-1，片选0。使用代码为frommaiximportspispi=spi.SpiDev()spi.open(1,0)spi.bits_per_word=8spi.max_speed_hz=1spi.mode=0b11importtimeforiinrange(3):time.sleep(0.1)to_send=[0x01,0x02,0x01]print(spi.xfer2(to_send,800000))[ rpyc-kernel ]( running at Mon Jan 17 17:13:45 2022 )\n[1, 2, 1]\n[1, 2, 1]\n[1, 2, 1]通过短接SPI的MOSI和MISO进行通讯测试![](./../asserts/SPI.jpg)这里所使用的是标准Python中的spidev库，更多的使用方法可以查看[Pythonspidev](https://www.baidu.com/s?ie=utf-8&wd=Python%20spidev)##了解更多SPI通信协议的[原理](https://zhuanlan.zhihu.com/p/139903418)关于MaixII-DockSPI更多详情可以查看大佬鼠的博文[为AWV831配置spidev模块，使用py-spidev进行用户层的SPI通信。](https://www.cnblogs.com/juwan/p/14341406.html)"}, "/soft/maixpy3/zh/usage/hardware/I2C.html": {"title": "Linux I2C 的使用", "content": "---|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|Rui|初次编写文档|---||2022年1月8日|Rui|修改文档的编写方式|使用Jupyternotebook进行编写文档||2022年1月18日|Rui|修改文档|测试了MaixII-DockMaixPy3IDE0.4.0|MaixPy3把Linux系统中的I2C的使用方法进行封装和简化使用，让用户使用起来更加的简单。##使用方法目前MaixPy3所封装的I2C只有主机模式，还不能使用从机模式。###准备使用之前需要将硬件连接好，将SDL和SDA的两个数据线连接到开发板上的对应的SDA和SDL的管脚上。通过查看开发板上的**管脚定义图**，确定所接上的I2C总线的序号，一般是以I2C-x或者是SDL.x、SDA.x的形式标示，x为总线序号。如**MaixII-Dock**中的管脚定义图，这里的SDA.1和SCL.1指是的I2C-1的总线![](./../asserts/M2Dock_pin.jpg)###连接**扫描设备**查看总线上的设备地址(返回十进制的数据)frommaiximporti2cprint(i2c.scan())[ rpyc-kernel ]( running at Wed Jan  5 17:22:45 2022 )\n[38]**实例化设备**`/dev/i2c-x`是指所使用的I2C总线序号frommaiximporti2ci2c=i2c.I2C('/dev/i2c-2',0x26)[ rpyc-kernel ]( running at Wed Jan  5 17:22:49 2022 )**读取设备寄存器信息**frommaiximporti2ci2c=i2c.I2C('/dev/i2c-2',0x26)print(i2c.read(0x1,1))[ rpyc-kernel ]( running at Wed Jan  5 17:24:48 2022 )\nbytearray(b'\\x13')更多的使用方法，请看I2CAPI文档##了解更多MaixPy3中的i2c是基于libi2c进行封装的，想要了解更多可以查阅[libi2c](https://github.com/sipeed/MaixPy3/tree/master/ext_modules/libi2c)的实现。"}, "/soft/maixpy3/zh/usage/hardware/watchdog.html": {"title": "Watchdog 的使用", "content": "---|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|Rui|初次编写文档|---||2022年1月8日|Rui|修改文档的编写方式|使用Jupyternotebook进行编写文档||2022年1月18日|Rui|修改文档，增加效果图|目前测试的是MaixII-DockMaixPy30.4.0，其他平台理论可用，但未测试。|看门狗主要用于保护系统正常运行，作用原理为，看门狗启动后，程序中必须定时执行一个喂狗的操作，当系统受到干扰不能正常运行时，喂狗操作也不能定时执行，此时看门狗将产生内部复位，使系统重新开始工作。##代码由于目前还在开发状态，以下代码为封装前代码，后续会有对应封装importarrayimportfcntlimportstructIO_WRITE=0x40000000IO_READ=0x80000000IO_READ_WRITE=0xC0000000IO_SIZE_INT=0x00040000IO_SIZE_40=0x00280000IO_TYPE_WATCHDOG=ord('W')<<8WDR_INT=IO_READ|IO_SIZE_INT|IO_TYPE_WATCHDOGWDR_40=IO_READ|IO_SIZE_40|IO_TYPE_WATCHDOGWDWR_INT=IO_READ_WRITE|IO_SIZE_INT|IO_TYPE_WATCHDOGWDIOC_GETSUPPORT=0|WDR_40WDIOC_GETSTATUS=1|WDR_INTWDIOC_GETBOOTSTATUS=2|WDR_INTWDIOC_GETTEMP=3|WDR_INTWDIOC_SETOPTIONS=4|WDWR_INTWDIOC_KEEPALIVE=5|WDR_INTWDIOC_SETTIMEOUT=6|WDWR_INTWDIOC_GETTIMEOUT=7|WDR_INTWDIOC_SETPRETIMEOUT=8|WDWR_INTWDIOC_GETPRETIMEOUT=9|WDR_INTWDIOC_GETTIMELEFT=10|WDR_INTWDIOF_OVERHEAT=0x0001WDIOF_FANFAULT=0x0002WDIOF_EXTERN1=0x0004WDIOF_EXTERN2=0x0008WDIOF_POWERUNDER=0x0010WDIOF_CARDRESET=0x0020WDIOF_POWEROVER=0x0040WDIOF_SETTIMEOUT=0x0080WDIOF_MAGICCLOSE=0x0100WDIOF_PRETIMEOUT=0x0200WDIOF_ALARMONLY=0x0400WDIOF_KEEPALIVEPING=0x8000WDIOS_DISABLECARD=0x0001WDIOS_ENABLECARD=0x0002WDIOS_TEMPPANIC=0x0004WATCHDOG_DEVICE='/dev/watchdog'WATCHDOG_STOP='V'WATCHDOG_START='S'classWatchdog:def__init__(self,stop=True):super(Watchdog,self).__init__()self.fd=open(WATCHDOG_DEVICE,'w')self.stop=stopifstop:self.Stop()def__del__(self)->None:#forv831try:self.fd.close()importosos.system(\"echoV>\"+WATCHDOG_DEVICE)exceptExceptionase:passdefStop(self):self.fd.write(WATCHDOG_STOP)defStart(self):self.stop=Falseself.fd.write(WATCHDOG_START)def_IoctlInt(self,cmd,write_value=0):buf=array.array('I',[write_value])start_temporary=self.stopifstart_temporary:self.Start()fcntl.ioctl(self.fd,cmd,buf,True)ifstart_temporary:self.Stop()returnbuf[0]defGetBootStatus(self):returnself._IoctlInt(WDIOC_GETBOOTSTATUS)defGetTemp(self):returnself._IoctlInt(WDIOC_GETTEMP)defSetOptions(self,options):returnself._IoctlInt(WDIOC_SETOPTIONS,options)defKeepAlive(self):ifself.stop:self.Start()returnself._IoctlInt(WDIOC_KEEPALIVE)defSetTimeout(self,timeout):timeout=int(timeout)iftimeout<=0:raiseValueError('timeout<=0')returnself._IoctlInt(WDIOC_SETTIMEOUT,timeout)defGetTimeout(self):returnself._IoctlInt(WDIOC_GETTIMEOUT)defSetPreTimeout(self,timeout):timeout=int(timeout)iftimeout<=0ortimeout>16:raiseValueError('0<timeout<=16')returnself._IoctlInt(WDIOC_SETPRETIMEOUT,timeout)defGetPreTimeout(self):returnself._IoctlInt(WDIOC_GETPRETIMEOUT)defGetTimeLeft(self):returnself._IoctlInt(WDIOC_GETTIMELEFT)#实例化看门狗设置喂狗时间1st=Watchdog()t.SetTimeout(1)importtime#进行喂狗操作0.5s喂一次t.KeepAlive()time.sleep(0.5)t.KeepAlive()time.sleep(0.5)t.__del__()delt#实例化看门狗设置喂狗时间2st=Watchdog()t.SetTimeout(2)time.sleep(2)delt当喂狗失败之后，系统会自动昂重启运行效果如下：![](./../asserts/Watchdog.gif)##了解更多查看[大佬鼠博客](https://www.cnblogs.com/juwan/p/14870346.html)中的关于看门狗的介绍"}, "/soft/maixpy3/zh/usage/train_AI/v831_sobel.html": {"title": "v831 部署 Sobel 卷积边缘检测", "content": "|时间|负责人|更新内容|备注||---|---|---|:---:||2021年8月3日|neucrack|首次编写并发布教程|发布于neucrack的[博客](https://neucrack.com/p/377)||2021年10月23日|Rui|收集文章并整理到文档中|---||2022年1月22日|Rui&dianjixz|使用Jupyter编写文档|工程文件[下载](https://github.com/dianjixz/v831_sobel)，文档还需要二次整理|>Windows系统暂不支持！边缘就是值变化剧烈的地方,如果对值的变化求导,则边缘部分就是导数局部最大。但是在图像处理时没有具体的函数让我们求导,使用卷积运算则可以很好的近似替代。卷积运算是神经网络的最常用的基本运算，所以非常适合用来展示神经网络在v831上的部署过程。##边缘检测效果![](https://neucrack.com/image/1/377/test.jpg)![](https://neucrack.com/image/1/377/sobel_edge2.jpg)![](https://neucrack.com/image/1/377/final.jpg)![](https://neucrack.com/image/1/377/sobel_edge.jpg)![](https://neucrack.com/image/1/377/sobel_v831.jpg)![](./dnn/sobel.jpg)##卷积边缘检测原理如下图,假设左上为坐标原点,横轴为x,纵轴为y,如下图左上角9个像素点,P(x,y)表示坐标(x,y)的点,要求P(1,1)处在x轴的变化率,则只需将P(2,1)-P(0,1)得到值为0,P(1,0)处为1-3=-2,这个差值即变化率,类比成导数,我们就能知道横轴在哪些地方变化率更大。![](https://neucrack.com/image/1/377/conv.jpg)上面这种方法我们可以得到横轴的变化率,这里使用卷积核~~~python[-1,0,1],[-2,0,2],[-1,0,1]~~~对图像进行卷积运算,如图中的计算方法,像素点左右权值取2,角上的也参与计算,但是权值为1,没有左右边的权值高.这样我们就得到了横轴的变化率图,即边缘检测图.注意,这里是对横轴计算了,比较的点左右的值变化,所以实际看到的图像会出现明显的纵轴边缘,如下图左边![](https://neucrack.com/image/1/377/vertical_horizontal.jpg)同理,上图右边的图使用卷积核[1,2,1],[0,0,0],[-1,-2,-1]得到的纵轴的边缘图。注意这里用右边减左边,如果右边的值比左边的小会是负数,如果我们希望只检测颜色值变大(变白)则可以直接使用,如果两个变化方向都要检测,则可以取绝对值.比如下图左边是没有取绝对值,右边取了绝对值![](https://neucrack.com/image/1/377/without_with_abs.jpg)得到两个方向的图后,对其进行合并,对每个像素平方和开方即可![](https://neucrack.com/image/1/377/final.jpg)这张图左边是使用GIMP的sobel边缘检测(垂直+水平)的效果,略微有点不同:![](https://neucrack.com/image/1/377/sobel_edge2.jpg)不同的原因是使用水平和垂直的图平方和开根后,直接用`plt.imshow`显示,和GIMP的处理方式不同```pythonout=np.sqrt(np.square(out_v)+np.square(out_h))plt.imshow(out)```简单地直接将值规范到`[0,255]`就和GIMP的图相似了(但不完全一样)```pythonout=np.sqrt(np.square(out_v)+np.square(out_h))out=out*255.0/out.max()plt.imshow(out.astype(np.uint8))```![](https://neucrack.com/image/1/377/sobel_v_h.jpg)##自定义卷积核来实现边缘检测除了上面说了使用两次卷积计算,也可以用只计算一次的卷积核,比如:```bash[-1,-1,-1],[-1,8,-1],[-1,-1,-1]```这是对于一个通道(灰度图)来说,如果要扩充到三个通道(RGB),卷积核参数就是如下形式```bashconv_rgb_core_sobel=[[[-1,-1,-1],[-1,8,-1],[-1,-1,-1],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0]],[[0,0,0],[0,0,0],[0,0,0],[-1,-1,-1],[-1,8,-1],[-1,-1,-1],[0,0,0],[0,0,0],[0,0,0]],[[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[-1,-1,-1],[-1,8,-1],[-1,-1,-1],]]```经过卷积运算后,前后图如下:![](https://neucrack.com/image/1/377/sobel_edge.jpg)注意,输入值范围如果为`[0,255]`,输出值则范围会变化,以图片形式查看时需要注意加以处理,这里使用了`plt.imshow(out)`来显示,这个函数会自动对图像做简单的处理,才会看起来是黑色背景##导出成模型使用可以将Net导出成onnx即可在其它平台使用,就是一个简单的卷积层部署到V831后的样子(使用了卷积核`[-1,-1,-1],[-1,8,-1],[-1,-1,-1],`):![](https://neucrack.com/image/1/377/sobel_v831.jpg)V831部署[源码](https://github.com/sipeed/MaixPy3/blob/master/ext_modules/_maix_nn/example/load_forward_sobel_edge_camera.py)在github，模型在[maixhub](https://www.maixhub.com/modelInfo?modelId=24)上可以下载##边缘检测源码>这是在电脑上运行的代码，不是在开发板平台上运行的代码，需要安装Pytorch使用环境，请自行百度安装。工程文件[下载](https://github.com/dianjixz/v831_sobel)'''simplesobeledgedemovisit:https://neucrack.com/p/377@authorneucrack@licenseMIT'''#引入模块importtorchimporttorch.nnasnnimportnumpyasnpfromPILimportImageimportmatplotlib.pyplotasplt###定义一个网络模型classNet(nn.Module):def__init__(self):super(Net,self).__init__()self.conv1=nn.Conv2d(3,3,3,padding=(0,0),bias=False)defforward(self,x):x=self.conv1(x)returnxnet=Net()###定义卷积权重#sobel全边缘检测算子conv_rgb_core_sobel=[[[-1,-1,-1],[-1,8,-1],[-1,-1,-1],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0]],[[0,0,0],[0,0,0],[0,0,0],[-1,-1,-1],[-1,8,-1],[-1,-1,-1],[0,0,0],[0,0,0],[0,0,0]],[[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[-1,-1,-1],[-1,8,-1],[-1,-1,-1],]]#sobel垂直边缘检测算子conv_rgb_core_sobel_vertical=[[[-1,0,1],[-2,0,2],[-1,0,1],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0]],[[0,0,0],[0,0,0],[0,0,0],[-1,0,1],[-2,0,2],[-1,0,1],[0,0,0],[0,0,0],[0,0,0]],[[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[-1,0,1],[-2,0,2],[-1,0,1],]]#sobel水平边缘检测算子conv_rgb_core_sobel_horizontal=[[[1,2,1],[0,0,0],[-1,-2,-1],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0]],[[0,0,0],[0,0,0],[0,0,0],[1,2,1],[0,0,0],[-1,-2,-1],[0,0,0],[0,0,0],[0,0,0]],[[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[0,0,0],[1,2,1],[0,0,0],[-1,-2,-1],]]###网络载入权重函数defsobel(net,kernel):sobel_kernel=np.array(kernel,dtype='float32')sobel_kernel=sobel_kernel.reshape((3,3,3,3))net.conv1.weight.data=torch.from_numpy(sobel_kernel)params=list(net.parameters())###打开一张图片pil_img=Image.open(\"./images/class1_5.jpg\")display(pil_img)input_img=np.array(pil_img)print(input_img.shape)###图片归一化处理input_tensor=(input_img.astype(np.float32)-127.5)/128#to[-1,1]print(input_tensor.shape)input_tensor=torch.Tensor(input_tensor).permute((2,0,1))input_tensor=input_tensor.unsqueeze(0)print(\"inputshape:\",input_tensor.shape)(224, 224, 3)\ninput shape: torch.Size([1, 3, 224, 224])###输入图片转换成PyTorch张量input_tensor=(input_img.astype(np.float32)-127.5)/128#to[-1,1]input_tensor=torch.Tensor(input_tensor).permute((2,0,1))print(input_tensor.shape)input_tensor=input_tensor.unsqueeze(0)print(\"inputshape:\",input_tensor.shape)torch.Size([3, 224, 224])\ninput shape: torch.Size([1, 3, 224, 224])###模型推理globalsobel_img_tglobalsobel_vertical_img_tglobalsobel_horizontal_img_tsobel_img_t=Nonesobel_vertical_img_t=Nonesobel_horizontal_img_t=None#载入网络权重sobel(net,conv_rgb_core_sobel_vertical)#在推理模式下运行网络withtorch.no_grad():out=net(input_tensor)sobel_vertical_img_t=out.numpy()[0].transpose([1,2,0])#载入网络权重sobel(net,conv_rgb_core_sobel_horizontal)#在推理模式下运行网络withtorch.no_grad():out=net(input_tensor)sobel_horizontal_img_t=out.numpy()[0].transpose([1,2,0])#载入网络权重sobel(net,conv_rgb_core_sobel)#在推理模式下运行网络withtorch.no_grad():out=net(input_tensor)sobel_img_t=out.numpy()[0].transpose([1,2,0])plt.figure()plt.figure()plt.subplot(1,5,1)plt.imshow(input_img)plt.subplot(1,5,2)plt.imshow(sobel_img_t)plt.subplot(1,5,3)plt.imshow(sobel_vertical_img_t)plt.subplot(1,5,4)plt.imshow(sobel_horizontal_img_t)plt.subplot(1,5,5)out=np.sqrt(np.square(sobel_vertical_img_t)+np.square(sobel_horizontal_img_t))plt.imshow(out)plt.show()Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).###导出onnx网络withtorch.no_grad():torch.onnx.export(net,input_tensor,\"./model.onnx\",export_params=True,input_names=[\"input0\"],output_names=[\"output0\"])print(\"导出网络完成！\")导出网络完成！###使用ncnn工具将onnx网络转换成ncnn网络以下代码中会调用用户环境中的ncnn工具，请确保已经安装好并加入环境变量。defonnx_to_ncnn(input_shape,onnx=\"out/model.onnx\",ncnn_param=\"out/conv0.param\",ncnn_bin=\"out/conv0.bin\"):importos#onnx2ncnntoolcompiledfromncnn/tools/onnx,andinthebulddircmd=f\"onnx2ncnn{onnx}{ncnn_param}{ncnn_bin}\"#可以更换工具目录os.system(cmd)withopen(ncnn_param)asf:content=f.read().split(\"\\n\")iflen(input_shape)==1:content[2]+=\"0={}\".format(input_shape[0])else:content[2]+=\"0={}1={}2={}\".format(input_shape[2],input_shape[1],input_shape[0])content=\"\\n\".join(content)withopen(ncnn_param,\"w\")asf:f.write(content)onnx_to_ncnn(input_shape=(3,224,224),onnx=\"./model.onnx\",ncnn_param=\"./conv0.param\",ncnn_bin=\"./conv0.bin\")print(\"netsuccess!\")net success!##使用MaixHub在线量化工具进行网络量化在线转换需要上传一个压缩包文件-该功能只能支持上传一个无密码的zip压缩包-压缩包内需要包含一个images目录，一个xxx.bin，一个xxx.param-需要将矫正图片放入images目录内；矫正图片集可考虑直接采用训练中的验证数据集，并务必保证矫正时图像的预处理方式与训练和部署时一致。>注意：确保images目录内没有混入其他文件，否则会导致模型量化错误。zip压缩包目录结构~~~bash└─sobel.zip.├──images│├──class1_0.jpg│├──class1_1.jpg│├──class1_2.jpg│├──class1_3.jpg│├──class1_4.jpg│└──class1_5.jpg├──sobel.bin└──sobel.param1directory,8files~~~制作好压缩包后，使用[MaixHub](https://maixhub.com/modelConvert)的在线转换工具进行模型转换，查看使用说明。![](https://neucrack.com/image/1/358/maixhub.jpg)登陆后,上传你的压缩包等待模型转换任务完成。##边缘检测模型部署等待模型转换完成,下载转换好的模型文件。得到的*.param和*.bin文件就是部署在v831上的文件。将模型文件上传到v831上。#v831运行边缘检测的代码frommaiximportnn,camera,display,imageimportnumpyasnpimporttimemodel={\"param\":\"./sobel_int8.param\",\"bin\":\"./sobel_int8.bin\"}input_size=(224,224,3)output_size=(222,222,3)options={\"model_type\":\"awnn\",\"inputs\":{\"input0\":input_size},\"outputs\":{\"output0\":output_size},\"mean\":[127.5,127.5,127.5],\"norm\":[0.0078125,0.0078125,0.0078125],}print(\"--loadmodel:\",model)m=nn.load(model,opt=options)print(\"--loadok\")whileTrue:img=camera.capture().resize(224,224)out=m.forward(img,quantize=True,layout=\"hwc\")out,=out.astype(np.float32).reshape(output_size)out=(np.ndarray.__abs__(out)*255/out.max()).astype(np.uint8)data=out.tobytes()img2=img.load(data,(222,222),mode=\"RGB\")display.show(img2)边缘检测到此结束。"}, "/soft/maixpy3/zh/question/how_to_ask.html": {"title": "", "content": ""}, "/soft/maixpy3/zh/question/driver_issue.html": {"title": "常见问题", "content": "# 常见问题\n## 问题\n> 21.06.24 目前暂时不支持使用etcher进行系统的烧录，会出现烧录之后无法进入系统，推荐使用dd命令进行烧录"}, "/soft/maixpy3/zh/question/maixpy3_issue.html": {"title": "", "content": ""}, "/soft/maixpy3/zh/install/install.html": {"title": "MaixPy3 使用的平台", "content": "---\ntitle: MaixPy3 使用的平台\nkeywords: linux, MaixII-Dock, MaixSense, 安装MaixPy3\ndesc: maixpy doc: linux_x86_64 如何安装？\n---\n\n## 可适配平台\n\n目前 MaixPy3 支持的平台主要如下，未来会进一步适配其他低端嵌入式 Linux 平台。\n\n- [MaixII-Dock](/hardware/zh/maixII/M2/resources.html)\n\n- [MaixSense](/hardware/zh/maixII/M2A/R329.html)\n\n- [Linux Desktop](https://github.com/sipeed/MaixPy3)\n\n## MaixII-Dock 上安装 MaixPy3\n\n在 MaixII-Dock 的最新[镜像](https://dl.sipeed.com/shareURL/MaixII/MaixII-Dock/SDK/release)中是已已经将 MaixPy3 安装好，烧录即可使用。不一定是最新版本的 MaixPy3，需要手动[更新 MaixPy3](/hardware/zh/maixII/M2/tools/0.MaixII-Dock.html#%E6%9B%B4%E6%96%B0-MaixPy3).\n\n也可以在[连接网络](/hardware/zh/maixII/M2/tools/0.MaixII-Dock.html#%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C)之后进行更新，通过 `pip install maixpy3` 进行安装，或者通过 `pip install -U Maixpy3` 进行更新\n\n```shell\nroot@sipeed:/# pip install maixpy3 -U\nRequirement already up-to-date: maixpy3 in /usr/lib/python3.8/site-packages (0.3.5)\nRequirement already satisfied, skipping upgrade: Pillow in /usr/lib/python3.8/site-packages (from maixpy3) (7.2.0)\nRequirement already satisfied, skipping upgrade: evdev in /usr/lib/python3.8/site-packages (from maixpy3) (1.4.0)\nRequirement already satisfied, skipping upgrade: gpiod in /usr/lib/python3.8/site-packages (from maixpy3) (1.4.0)\nRequirement already satisfied, skipping upgrade: pyserial in /usr/lib/python3.8/site-packages (from maixpy3) (3.4)\nRequirement already satisfied, skipping upgrade: rpyc in /usr/lib/python3.8/site-packages (from maixpy3) (5.0.1)\nRequirement already satisfied, skipping upgrade: spidev in /usr/lib/python3.8/site-packages (from maixpy3) (3.5)\nRequirement already satisfied, skipping upgrade: zbarlight in /usr/lib/python3.8/site-packages (from maixpy3) (3.0)\nRequirement already satisfied, skipping upgrade: plumbum in /usr/lib/python3.8/site-packages (from rpyc->maixpy3) (1.6.9)\nWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\nroot@sipeed:/#\n```\n\n输出以上信息则是代表安装好了，以下为实拍图。\n\n![](./asserts/V831.jpg)\n\n## MaixSense 安装 MaixPy3\n\nMaixSense 需要是烧录官方提供最新的 Armbian 镜像，旧的镜像在安装 MaixPy3 的时候会缺很多文件而导致的报错。\n> MaixSense 的 Tina 系统并支持使用\n\n```shell\nroot@maixsense:~# pip install maixpy3\nRequirement already satisfied: maixpy3 in /usr/local/lib/python3.9/dist-packages (0.3.4)\nRequirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from maixpy3) (8.1.2)\nRequirement already satisfied: zbarlight in /usr/local/lib/python3.9/dist-packages (from maixpy3) (3.0)\nRequirement already satisfied: evdev in /usr/local/lib/python3.9/dist-packages (from maixpy3) (1.4.0)\nRequirement already satisfied: spidev in /usr/local/lib/python3.9/dist-packages (from maixpy3) (3.5)\nRequirement already satisfied: pyserial in /usr/local/lib/python3.9/dist-packages (from maixpy3) (3.5)\nRequirement already satisfied: rpyc in /usr/local/lib/python3.9/dist-packages (from maixpy3) (5.0.1)\nRequirement already satisfied: gpiod in /usr/local/lib/python3.9/dist-packages (from maixpy3) (1.5.0)\nRequirement already satisfied: plumbum in /usr/local/lib/python3.9/dist-packages (from rpyc->maixpy3) (1.7.0)\nroot@maixsense:~# python\nPython 3.9.2 (default, Feb 28 2021, 17:03:44)\n[GCC 10.2.1 20210110] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import maix\n>>>\n```\n\n输出以上信息则是代表安装好了，以下为实拍图。\n![](./asserts/R329.jpg)\n## Linux Desktop 安装 MaixPy3\n\n> 2021年02月21日 在 RaspberryPi 、 ubuntu20 与 manjaro20 上测试通过。\n\n通过 `pip3 install maixpy3` 安装。\n\n```bash\njuwan@juwan-N85-N870HL:~$ pip3 install .Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\nProcessing /home/juwan/Desktop/v831_toolchain_linux_x86/MaixPy3\nRequirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from MaixPy3==0.2.9) (7.0.0)\nRequirement already satisfied: evdev in /home/juwan/.local/lib/python3.8/site-packages (from MaixPy3==0.2.9) (1.4.0)\nRequirement already satisfied: gpiod in /home/juwan/.local/lib/python3.8/site-packages (from MaixPy3==0.2.9) (1.4.0)\nRequirement already satisfied: numpy in /home/juwan/.local/lib/python3.8/site-packages (from MaixPy3==0.2.9) (1.19.4)\nRequirement already satisfied: opencv-python in /home/juwan/.local/lib/python3.8/site-packages (from MaixPy3==0.2.9) (4.5.1.48)\nRequirement already satisfied: pyserial in /usr/local/lib/python3.8/dist-packages (from MaixPy3==0.2.9) (3.4)\nRequirement already satisfied: rpyc in /home/juwan/.local/lib/python3.8/site-packages (from MaixPy3==0.2.9) (5.0.1)\nRequirement already satisfied: spidev in /home/juwan/.local/lib/python3.8/site-packages (from MaixPy3==0.2.9) (3.5)\nRequirement already satisfied: plumbum in /home/juwan/.local/lib/python3.8/site-packages (from rpyc->MaixPy3==0.2.9) (1.6.9)\nBuilding wheels for collected packages: MaixPy3\n  Building wheel for MaixPy3 (setup.py) ... done\n  Created wheel for MaixPy3: filename=MaixPy3-0.2.9-cp38-cp38-linux_x86_64.whl size=115611 sha256=54f70f181ccc629f1eaf470bf30eccd20389c6333814d7145e16a31db7f6cdcd\n  Stored in directory: /tmp/pip-ephem-wheel-cache-9bf1q3wt/wheels/53/7d/47/6cd374fab930089f96a0a3185f5677e52a9b71dbbee769935d\nSuccessfully built MaixPy3\nInstalling collected packages: MaixPy3\n  Attempting uninstall: MaixPy3\n    Found existing installation: MaixPy3 0.2.8\n    Uninstalling MaixPy3-0.2.8:\n      Successfully uninstalled MaixPy3-0.2.8\nSuccessfully installed MaixPy3-0.2.9\n```\n\n输出以上信息则是代表安装好了，下面为实拍图。\n\n![](./asserts/ubuntu.png)\n\n通常来说，像树莓派 2B 这类拥有桌面环境面（DE）的 linux 硬件也是可以通过 pip 进行安装 Linux Desktop 分支的，效果都是一样的。\n\n    pip install maixpy3\n\n![](./asserts/rpi2b.png)"}, "/soft/maixpy3/zh/install/index.html": {"title": "如何安装 MaixPy3 ", "content": "---\ntitle: 如何安装 MaixPy3 \nkeywords: MaixPy, MaixPy3, Python, Python3, MicroPython\ndesc: maixpy doc: 如何安装 MaixPy3 \n---\n\n通常来说，任何支持 Python3 的设备上都可以通过 `pip3 install maixpy3 --upgrade` 来安装 MaixPy3 作为模块入口使用，但由于一些嵌入式设备和不同平台限制，所以在这些平台上需要适配。\n\n适配进度请查阅 [MaixPy3#progress](https://github.com/sipeed/MaixPy3#progress) 。\n\n> 由于 Windows 的特殊性，不鼓励用户去折腾 Windows 的编译与安装。"}, "/soft/maixpy3/zh/others/develop.html": {"title": "MaixPy3 开发文档", "content": "---\ntitle: MaixPy3 开发文档\nkeywords: MaixPy, MaixPy3, Python, Python3, MicroPython\ndesc: maixpy doc: 如何参与项目（开发文档）\n---\n\nMaixPy3 并不是为了某一款芯片平台制作的，它的初衷就是为了通过 Python 编程简化用户在嵌入式 Linux 上开发程序的过程，所以是建立在所有 Linux 设备都能使用的基础上去设计的，但由于 Sipeed 官方的能力有限，难以同时照顾所有开源硬件的同步开发，所以提供一些官方的基本芯片移植参考，方便第三方的开源爱好者提交其他芯片平台、镜像、工具推送到 MaixPy3 的环境中。\n\n## 一般开发流程\n\n从 MaixPy3 仓库的 [setup.py](https://github.com/sipeed/MaixPy3/blob/main/setup.py) 进行项目的编译。\n\n对于一台 Linux X86 的个人计算机而言，我们使用如下命令进行构建。\n\n- 编译 `python3 setup.py build`\n- 清理 `python3 setup.py clean`\n- 安装 `pip3 install .`\n\n```bash\njuwan@juwan-N85-N870HL:~/Desktop/v831_toolchain_linux_x86/MaixPy3$ python3 setup.py build\nrunning build\nrunning build_py\nrunning egg_info\nwriting MaixPy3.egg-info/PKG-INFO\nwriting dependency_links to MaixPy3.egg-info/dependency_links.txt\nwriting entry points to MaixPy3.egg-info/entry_points.txt\nwriting requirements to MaixPy3.egg-info/requires.txt\nwriting top-level names to MaixPy3.egg-info/top_level.txt\nwriting manifest file 'MaixPy3.egg-info/SOURCES.txt'\nrunning build_ext\njuwan@juwan-N85-N870HL:~/Desktop/v831_toolchain_linux_x86/MaixPy3$ python3 setup.py clean\nrunning clean\njuwan@juwan-N85-N870HL:~/Desktop/v831_toolchain_linux_x86/MaixPy3$ pip3 install .Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\nProcessing /home/juwan/Desktop/v831_toolchain_linux_x86/MaixPy3\nRequirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from MaixPy3==0.2.9) (7.0.0)\nRequirement already satisfied: evdev in /home/juwan/.local/lib/python3.8/site-packages (from MaixPy3==0.2.9) (1.4.0)\nRequirement already satisfied: gpiod in /home/juwan/.local/lib/python3.8/site-packages (from MaixPy3==0.2.9) (1.4.0)\nRequirement already satisfied: numpy in /home/juwan/.local/lib/python3.8/site-packages (from MaixPy3==0.2.9) (1.19.4)\nRequirement already satisfied: opencv-python in /home/juwan/.local/lib/python3.8/site-packages (from MaixPy3==0.2.9) (4.5.1.48)\nRequirement already satisfied: pyserial in /usr/local/lib/python3.8/dist-packages (from MaixPy3==0.2.9) (3.4)\nRequirement already satisfied: rpyc in /home/juwan/.local/lib/python3.8/site-packages (from MaixPy3==0.2.9) (5.0.1)\nRequirement already satisfied: spidev in /home/juwan/.local/lib/python3.8/site-packages (from MaixPy3==0.2.9) (3.5)\nRequirement already satisfied: plumbum in /home/juwan/.local/lib/python3.8/site-packages (from rpyc->MaixPy3==0.2.9) (1.6.9)\nBuilding wheels for collected packages: MaixPy3\n  Building wheel for MaixPy3 (setup.py) ... done\n  Created wheel for MaixPy3: filename=MaixPy3-0.2.9-cp38-cp38-linux_x86_64.whl size=115611 sha256=54f70f181ccc629f1eaf470bf30eccd20389c6333814d7145e16a31db7f6cdcd\n  Stored in directory: /tmp/pip-ephem-wheel-cache-9bf1q3wt/wheels/53/7d/47/6cd374fab930089f96a0a3185f5677e52a9b71dbbee769935d\nSuccessfully built MaixPy3\nInstalling collected packages: MaixPy3\n  Attempting uninstall: MaixPy3\n    Found existing installation: MaixPy3 0.2.8\n    Uninstalling MaixPy3-0.2.8:\n      Successfully uninstalled MaixPy3-0.2.8\nSuccessfully installed MaixPy3-0.2.9\njuwan@juwan-N85-N870HL:~/Desktop/v831_toolchain_linux_x86/MaixPy3$ \n```\n\n而对于不能在目标平台上编译安装的环境，就需要使用预编译的 whl 包来辅助安装，以 Maix V831 为例。\n\n- 编译 `python3.8 setup.py maix_v831 bdist_wheel`\n\n- 安装 `pip install ./dist/*.whl`\n\n```bash\nroot@sipeed:/# pip install maixpy3 --upgrade\nCollecting maixpy3\n  Downloading MaixPy3-0.1.9-cp38-cp38-linux_armv7l.whl (1.0 MB)\n     |████████████████████████████████| 1.0 MB 43 kB/s \nCollecting pexpect\n  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n     |████████████████████████████████| 59 kB 71 kB/s \nCollecting rpyc\n  Downloading rpyc-5.0.1-py3-none-any.whl (68 kB)\n     |████████████████████████████████| 68 kB 42 kB/s \nRequirement already satisfied, skipping upgrade: Pillow in /usr/lib/python3.8/site-packages (from maixpy3) (7.2.0)\nCollecting ptyprocess>=0.5\n  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\nCollecting plumbum\n  Downloading plumbum-1.6.9-py2.py3-none-any.whl (115 kB)\n     |████████████████████████████████| 115 kB 84 kB/s \nInstalling collected packages: ptyprocess, pexpect, plumbum, rpyc, maixpy3\nSuccessfully installed maixpy3-0.1.9 pexpect-4.8.0 plumbum-1.6.9 ptyprocess-0.7.0 rpyc-5.0.1\nWARNING: You are using pip version 20.1.1; however, version 21.0 is available.\nYou should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\n\nroot@sipeed:/# \n```\n\n对于一些安装失败，缺少了依赖库的场合，需要从外部去引入该包的安装，例如这个问题 [error happened when install maixpy3](https://github.com/sipeed/MaixPy3/issues/4) ，这通常需要升级镜像来解决，或手动安装相关的依赖包。\n\n至此以后，在发布软件包的时候可以通过 `pip install maixpy3` 让目标机器直接安装 maixpy3 的包即可使用。\n\n## 一般测试流程\n\n项目引入 tox 进行软件接口交互的自动化测试，通常用它进行虚拟 Python 环境测试，确保软件代码的依赖关系和接口逻辑测试，如测试 `from xxx import *` 是否可行。\n\n```bash\njuwan@juwan-N85-N870HL:~/Desktop/v831_toolchain_linux_x86/MaixPy3$ tox\nGLOB sdist-make: /home/juwan/Desktop/v831_toolchain_linux_x86/MaixPy3/setup.py\npy38 inst-nodeps: /home/juwan/Desktop/v831_toolchain_linux_x86/MaixPy3/.tox/.tmp/package/1/MaixPy3-0.1.2.zip\npy38 installed: attrs==20.3.0,iniconfig==1.1.1,packaging==20.8,Pillow==8.1.0,pluggy==0.13.1,py==1.10.0,pyparsing==2.4.7,pytest==6.2.1,MaixPy3 @ file:///home/juwan/Desktop/v831_toolchain_linux_x86/MaixPy3/.tox/.tmp/package/1/MaixPy3-0.1.2.zip,scripttest==1.3,toml==0.10.2\npy38 run-test-pre: PYTHONHASHSEED='820562099'\npy38 run-test: commands[0] | py.test\n======================================= test session starts ========================================\nplatform linux -- Python 3.8.5, pytest-6.2.1, py-1.10.0, pluggy-0.13.1\ncachedir: .tox/py38/.pytest_cache\nrootdir: /home/juwan/Desktop/v831_toolchain_linux_x86/MaixPy3\ncollected 5 items                                                                                  \n\next_modules/_maix/example/test__maix.py .                                                    [ 20%]\ntests/test_maix.py ....                                                                      [100%]\n\n======================================== 5 passed in 0.05s =========================================\n_____________________________________________ summary ______________________________________________\n  py38: commands succeeded\n  congratulations :)\n```\n\n对于硬件模块，通常不好自动化测试，所以会做成 example 提供。\n\n关于代码覆盖性测试，暂时不做。\n\n## 一般发布流程\n\n2021年02月21日 关于自动化构建，还在考虑到导入多个平台的编译链编译的问题，暂时还没有准备好。\n\n## Python 模块编译说明\n\nMaixPy3 使用面向模块接口开发，链接跨平台的 Python 或 C 包，统一加载到 Python3 环境当中。\n\n目前支持的 Python3 环境如下：\n\n- [PC x86_64 的 Pyhon3 环境](https://www.python.org/downloads/release/python-380/)\n\n- [Sipeed v831 的 Python3 交叉编译环境](https://github.com/sipeed/MaixPy3/releases/tag/20210613) (需要使用 source toolchain_v83x_linux_x86/envsetup.sh 获得链接 V831 编译链的 python3.8 环境，注意这不是本机的 Python3 环境！！！)\n\n通常拿到一个 Python 模块，对它的 `setup.py` 执行 `python setup.py build` 即可进行构建，它的内容通常有如下示例（只是举例）。\n\n```python\n\nfrom setuptools import setup, Extension, find_packages\n\n_maix_module = Extension('_maix', include_dirs=['ext_modules/_maix/include'], sources=get_srcs('ext_modules/_maix'), libraries=['jpeg'])\n\nlibi2c_module = Extension('pylibi2c',  include_dirs=['ext_modules/libi2c/src'], sources=get_srcs('ext_modules/libi2c/src'))\n\nsetup(\n    name='MaixPy3',\n    version='0.1.2',\n    license='MIT',\n    author='Sipeed',\n    author_email=\"support@sipeed.com\",\n    url='https://github.com/sipeed/MaixPy3',\n    description=\"MaixPy Python3 library\",\n    long_description=open('README.md').read(),\n    install_requires=[\"Pillow\"],\n    ext_modules=[\n        _maix_module,\n        libi2c_module,\n    ],\n    packages = find_packages(), # find __init__.py packages\n    classifiers=[\n        'Programming Language :: Python :: 3',\n    ],\n)\n\n```\n\n只需要关心 setup 函数的参数中 packages 、 ext_modules 定义下的模块。\n\n- find_packages() 会自动寻找根目录下所有带有 `__init__.py` 的包导入到 Python3 的 site-packages 中，import 的时候就会找到它。\n- ext_modules 是需要经过编译的 C 模块。\n\n## 通用 Python 模块开发\n\n以 maix 模块为例，完全用 Python 实现的模块需要按以下结构进行构建。\n\n- maix/`__init__.py`\n- maix/video.py\n- maix/xxxxx.py\n\n首先 setuptools 打包系统会找到该模块的 maix 文件夹并将其安装到 `site-packages/maix` 下，这样用户就可以在 Python3 中 `import maix` 了，注意它与 setup.py 的相对目录（`/maix`）与安装目录（`site-packages/maix`）位置保持一致。\n\n如何控制 from maix import * 的内容可以看 `__init__.py` 了解。\n\n```python\nfrom .video import camera\nfrom .import display\n\n__all__ = ['display', 'video', 'camera']\n```\n\n其中 `__all__` 可以控制 import 加载的模块、对象或变量，这样一个最基本的 Python 模块就制作完成了。\n\n关于编写后的测试看 [test_maix.py](https://github.com/sipeed/MaixPy3/tree/main/tests/test_maix.py) 代码可知，关于 tox 测试框架会在最后简单说明。 \n\n## 关于 C 拓展模块开发\n\n以 [libi2c](https://github.com/amaork/libi2c) 举例说明原生 C 开发的模块。\n\n如果是用 C 开发就需要配合 Makefile 的规则来操作，可以直接在 MaixPy3/ext_modules/libi2c 目录下直接运行 `make all` 进行构建，此时就会得到 `libi2c.so \\ libi2c.a \\ pylibi2c.so` 等模块。\n\n这样目标系统就可以通过 C 代码链接(-l)该 libi2c 模块执行，而 `pylibi2c.so` 模块是可以直接在 Python 里面直接 import 就可以使用的。\n\n```shell\njuwan@juwan-N85-N870HL:~/Desktop/v831_toolchain_linux_x86/MaixPy3/ext_modules/libi2c$ python3\nPython 3.8.5 (default, Jul 28 2020, 12:59:40) \n[GCC 9.3.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import pylibi2c\n>>> pylibi2c\n<module 'pylibi2c' from '/home/juwan/Desktop/v831_toolchain_linux_x86/MaixPy3/ext_modules/libi2c/pylibi2c.cpython-38-x86_64-linux-gnu.so'>\n>>> \n```\n\n注意 `pylibi2c.so` 是经过 `python3 setup.py build_ext --inplace` 命令编译 [ext_modules/libi2c/src/pyi2c.c](https://github.com/sipeed/MaixPy3/tree/main/ext_modules/libi2c/src/pyi2c.c) 得到的模块。\n\n其中 `#include <Python.h>` 的是来自于系统的 `usr/include` 目录，这取决于你的编译环境。\n\n> 注意，编译通过不代表可以运行，如果发现运行时丢失函数（undefined symbol），可以通过 ldd 查询 .so 依赖函数, 通过 nm -D 查询 .a 函数，通过 readelf -e 查询程序编译版本，有些平台可能没有 ldd 的话，就用 `readelf -d /bin/ls | grep \"Shared library\"` 来查看了，缺啥就往环境里补就对了。\n\n### 导入 pyXXX.c 的 C 拓展模块\n\n对于 make / gcc 的模块包以 ext_modules/xxxx 方式加入 MaixPy3 的编译环境（setup.py）， 请确保该包可以跨平台编译通过后，同步修改 [MaixPy3/envs/general.py](https://github.com/sipeed/MaixPy3/blob/main/envs/general.py) 的 ext_modules 模块。\n\n```python\n\nfrom setuptools import Extension\nfrom .utils import get_srcs\n\nlibi2c_module = Extension('pylibi2c',  include_dirs=[\n                          'ext_modules/libi2c/src'], sources=get_srcs('ext_modules/libi2c/src'))\n\n_maix_module = Extension('_maix', include_dirs=['ext_modules/_maix/include'],\n                         sources=get_srcs('ext_modules/_maix'),\n                         libraries=[\n    \"jpeg\"\n],\n)\n\n_maix_camera_module = Extension('_maix_camera', include_dirs=['ext_modules/_maix_camera/include'],\n                                sources=get_srcs('ext_modules/_maix_camera'),\n                                )\n\n_maix_display_module = Extension('_maix_display', include_dirs=['ext_modules/_maix_display/include'],\n                                 sources=get_srcs('ext_modules/_maix_display'),\n                                 )\n\n_maix_modules = [\n    libi2c_module,\n    _maix_module,\n    _maix_camera_module,\n    _maix_display_module\n]\n\n_maix_data_files = [\n\n]\n\n_maix_py_modules = [\n    \"numpy\",\n    \"opencv-python3\",\n    \"opencv-python\",\n    \"Pillow\",\n    \"rpyc\",\n    \"gpiod\",\n    \"evdev\",\n    \"spidev\",\n    \"pyserial\"\n]\n```\n\n以 _maix_module 为例，在加入编译之前，该包结构如下（目录结构可能会过时）。\n\n- ext_modules/_maix\n- ext_modules/_maix/include/_maix.h\n- ext_modules/_maix/_maix.c\n- ext_modules/_maix/setup.py\n- /example/test__maix.py\n\n此时我们可以在 MaixPy3 根目录下使用 `python3 setup.py build` 调用 [setup.py](https://github.com/sipeed/MaixPy3/blob/main/setup.py) 進行构建，默认构建 linux_x86_64 的包。\n\n```python\n#!/usr/bin/env python\n\n\"\"\"\nsetup.py file for MaixPy3\n\"\"\"\n\nimport sys\nfrom setuptools import setup, Extension, find_packages\n\next_modules = []\ndata_files = []\npy_modules = []\n\nif 'maix_v831' in sys.argv:\n  sys.argv.remove('maix_v831')\n  from envs.maix_v831 import _maix_modules, _maix_data_files, _maix_py_modules\nelse:\n  from envs.general import _maix_modules, _maix_data_files, _maix_py_modules\n  \next_modules.extend(_maix_modules)\ndata_files.extend(_maix_data_files)\npy_modules.extend(_maix_py_modules)\n\n```\n\n如果在本机 Python 编译时出现如下错误：\n\n```shell\next_modules/_maix/pyCamera.c:4:10: fatal error: jpeglib.h: 没有那个文件或目录\n    4 | #include \"jpeglib.h\"\n      |          ^~~~~~~~~~~\ncompilation terminated.\n```\n\n运行 `sudo apt-get install libjpeg-dev` 后会在本机 usr/include 和 usr/bin 中加入 libjpeg 的模块，其他编译链同理。\n\n注意 Extension 的代码的链接时的相对地址（include_dirs & sources），以及本地打包时链接时缺少的（.h）文件，注意 [MANIFEST.in](https://github.com/sipeed/MaixPy3/tree/main/MANIFEST.in) 会链接本地的文件加入 Python 模块的打包。\n\n> 默认配置下打包中不会带入模块的（.h）文件，这会导致运行 tox 自动化打包构建模块时出错。\n\n```in\ninclude ext_modules/libi2c/src/*.h\ninclude ext_modules/_maix/include/*.h\n```\n\n> 关于 setup.py 的用法可以参考 [2021年，你应该知道的Python打包指南](https://frostming.com/2020/12-25/python-packaging)\n\n### 编写 C 拓展模块的参考\n\n接下来说明 CPython 的代码编写规范说明：\n\n- 如何编写一个 CPython 模块（PyModule）。\n- 如何 CPython 模块添加类对象（全局对象）、全局函数、全局变量。\n- 一个 PyObject 类对象的结构代码。\n- 标准 CPython 模块的命令规则。\n\n以 MaixPy3/ext_modules/_maix 模块为例，首先提供一个 C 实现的 Python 模块入口 [_maix.c](https://github.com/sipeed/MaixPy3/tree/main/ext_modules/_maix/_maix.c) 。\n\n```c\n\n#include \"_maix.h\"\n\n#define _VERSION_ \"0.1\"\n#define _NAME_ \"_maix\"\n\nPyDoc_STRVAR(_maix_doc, \"MaixPy Python3 library.\\n\");\n\nstatic PyObject *_maix_help() {\n    return PyUnicode_FromString(_maix_doc);\n}\n\nstatic PyMethodDef _maix_methods[] = {\n    {\"help\", (PyCFunction)_maix_help, METH_NOARGS, _maix_doc},\n    {NULL}\n};\n\nvoid define_constants(PyObject *module) {\n    PyModule_AddObject(module, \"_VERSION_\", Py_BuildValue(\"H\", _VERSION_));\n}\n\nstatic struct PyModuleDef _maixmodule = {\n    PyModuleDef_HEAD_INIT,\n    _NAME_,         /* Module name */\n    _maix_doc,\t/* Module _maixMethods */\n    -1,\t\t\t    /* size of per-interpreter state of the module, size of per-interpreter state of the module,*/\n    _maix_methods,\n};\n\nPyMODINIT_FUNC PyInit__maix(void)\n{\n\n    PyObject *module;\n\n    if (PyType_Ready(&CameraObjectType) < 0) {\n        return NULL;\n    }\n\n    module = PyModule_Create(&_maixmodule);\n    PyObject *version = PyUnicode_FromString(_VERSION_);\n\n    /* Constants */\n    define_constants(module);\n\n    /* Set module version */\n    PyObject *dict = PyModule_GetDict(module);\n    PyDict_SetItemString(dict, \"__version__\", version);\n    Py_DECREF(version);\n\n    /* Register CameraObjectType */\n    Py_INCREF(&CameraObjectType);\n    PyModule_AddObject(module, Camera_name, (PyObject *)&CameraObjectType);\n\n    return module;\n}\n\n\n```\n\n此时 Python 在 import 该模块的时候就会调用 PyInit_xxxx 函数进行初始化，在 Python 里 import 该模块只会执行一次，想要再次执行需要 reload 函数（`from imp import reload`）。\n\n通过 `PyModule_AddObject` 注册 PyObject 对象到该模块中，而该对象被公开到一个头文件当中进行交换，从而给 PyModule 提供多个 PyObject 的实现，添加模块的全局变量与此同理。\n\n```c\nstatic PyMethodDef _maix_methods[] = {\n    {\"help\", ()_maix_help, METH_NOARGS, _maix_doc},\n    {NULL}\n};\n```\n\n通过 `_maix_methods` 结构体为模块添加全局函数，如果你认为某个函数是公共函数，则将其放置模块顶层，表示全局公共函数。\n\n### PyObject 的结构参考\n\n一个基础的格式参考如下：\n\n定义一个对象必要的对外引用，将模块和对象实现分离，模块再通过（.h）文件链接对象实现，可见 [MaixPy3/ext_modules/_maix_camera/include/_maix_camera.h](https://github.com/sipeed/MaixPy3/blob/main/ext_modules/_maix_camera/include/_maix_camera.h) 。\n\n```c\n\n#ifndef _MAIX_CAMERA_H\n#define _MAIX_CAMERA_H\n\n#ifdef  __cplusplus\nextern \"C\" {\n#endif\n\n#include <Python.h>\n\n/* Macros needed for Python 3 */\n#ifndef PyInt_Check\n#define PyInt_Check PyLong_Check\n#define PyInt_FromLong PyLong_FromLong\n#define PyInt_AsLong PyLong_AsLong\n#define PyInt_Type PyLong_Type\n#endif\n\nPyDoc_STRVAR(VirtualCamera_name, \"VirtualCamera\");\nextern PyTypeObject VirtualCameraObjectType;\n\n// #define V831Camera\n#ifdef V831Camera\nPyDoc_STRVAR(V831Camera_name, \"V831Camera\");\nextern PyTypeObject V831CameraObjectType;\n#endif\n\n#ifdef  __cplusplus\n}\n#endif\n\n#endif\n\n```\n\n此时（PyInit__maix）就可以加载该对象（CameraObjectType）到 _maix 模块当中。\n\n```c\nif (PyType_Ready(&VirtualCameraObjectType) < 0) {\n    return NULL;\n}\n\n/* Register VirtualCameraObjectType */\nPy_INCREF(&VirtualCameraObjectType);\nPyModule_AddObject(module, VirtualCamera_name, (PyObject *)&VirtualCameraObjectType);\n\n```\n\n现在看到 PyObject 的实现参考，以 [MaixPy3/ext_modules/_maix_camera/_camera_virtual.c](https://github.com/sipeed/MaixPy3/blob/main/ext_modules/_maix_camera/_camera_virtual.c) 为范本。\n\n```c\n\nPyDoc_STRVAR(VirtualCameraObject_type_doc, \"VirtualCamera(width, height) -> VirtualCamera object.\\n\");\ntypedef struct\n{\n  PyObject_HEAD;\n  unsigned int width, height;\n} VirtualCameraObject;\n\nstatic PyGetSetDef VirtualCamera_getseters[] = {\n    {\"width\", (getter)VirtualCamera_get_width, (setter)VirtualCamera_set_width, VirtualCamera_width_doc},\n    {\"height\", (getter)VirtualCamera_get_height, (setter)VirtualCamera_set_height, VirtualCamera_height_doc},\n    {NULL},\n};\n\nPyTypeObject VirtualCameraObjectType = {\n    PyVarObject_HEAD_INIT(NULL, 0)\n    VirtualCamera_name,                           /* tp_name */\n    sizeof(VirtualCameraObject),                      /* tp_basicsize */\n    0,                                        /* tp_itemsize */\n    (destructor)VirtualCamera_free,                   /* tp_dealloc */\n    0,                                        /* tp_print */\n    0,                                        /* tp_getattr */\n    0,                                        /* tp_setattr */\n    0,                                        /* tp_compare */\n    0,                                        /* tp_repr */\n    0,                                        /* tp_as_number */\n    0,                                        /* tp_as_sequence */\n    0,                                        /* tp_as_mapping */\n    0,                                        /* tp_hash */\n    0,                                        /* tp_call */\n    VirtualCamera_str,                                /* tp_str */\n    0,                                        /* tp_getattro */\n    0,                                        /* tp_setattro */\n    0,                                        /* tp_as_buffer */\n    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE, /* tp_flags */\n    VirtualCameraObject_type_doc,                     /* tp_doc */\n    0,                                        /* tp_traverse */\n    0,                                        /* tp_clear */\n    0,                                        /* tp_richcompare */\n    0,                                        /* tp_weaklistoffset */\n    0,                                        /* tp_iter */\n    0,                                        /* tp_iternext */\n    VirtualCamera_methods,                            /* tp_methods */\n    0,                                        /* tp_members */\n    VirtualCamera_getseters,                          /* tp_getset */\n    0,                                        /* tp_base */\n    0,                                        /* tp_dict */\n    0,                                        /* tp_descr_get */\n    0,                                        /* tp_descr_set */\n    0,                                        /* tp_dictoffset */\n    (initproc)VirtualCamera_init,                     /* tp_init */\n    0,                                        /* tp_alloc */\n    VirtualCamera_new,                                /* tp_new */\n};\n```\n\n实现任何模块时需重点关注如下基本函数接口实现，忽略（Camera）前缀，且下文函数只做举例。\n\n- xxxxx_new （对象构造函数）\n- xxxxx_free （对象析构函数）\n- xxxxx_init （对象初始化函数）\n- xxxxx_getseters （对象属性定义结构）\n- xxxxx_methods （对象方法定义结构）\n\n开发上遵循基本结构即可，展示 PyArg_ParseTupleAndKeywords 传递参数用法，以 Camera_init 为例，如果不想写 keyword （kwlist） 就用 PyArg_ParseTuple 函数。\n\n```c\nstatic int Camera_init(CameraObject *self, PyObject *args, PyObject *kwds)\n{\n  // default init value\n  self->width = 640, self->height = 480;\n\n  static char *kwlist[] = {\"width\", \"height\", NULL};\n\n  if (!PyArg_ParseTupleAndKeywords(args, kwds, \"|ii:__init__\", kwlist,\n                                   &self->width, &self->height))\n  {\n    return -1;\n  }\n\n  return 0;\n}\n```\n\n为 PyObject 对象链接函数符号的时候可以看 xxxxx_getseters 和 xxxxx_methods 的结构定义。\n\n```c\nstatic PyMethodDef Camera_methods[] = {\n\n    {\"close\", (PyCFunction)Camera_close, METH_NOARGS, Camera_close_doc},\n    {\"__enter__\", (PyCFunction)Camera_enter, METH_NOARGS, NULL},\n    {\"__exit__\", (PyCFunction)Camera_exit, METH_NOARGS, NULL},\n    {NULL},\n};\n\nstatic PyGetSetDef Camera_getseters[] = {\n    {\"width\", (getter)Camera_get_width, (setter)Camera_set_width, Camera_width_doc},\n    {\"height\", (getter)Camera_get_height, (setter)Camera_set_height, Camera_height_doc},\n    {NULL},\n};\n```\n\n以 Python3 的 _maix.Camera 为例：\n\n```python\n\nimport _maix\n\ntmp = _maix.Camera()\n\nprint(\"this is method\", Camera.close)\n\nprint(\"this is var\", Camera.width)\n\n```\n\n一个简单的 PyCFunction 函数实现方法如下：\n\n```c\n/* str */\nstatic PyObject *Camera_str(PyObject *object)\n{\n  PyObject *dev_desc = PyUnicode_FromString(\"Camera_str\");\n\n  return dev_desc;\n}\n```\n\n如果是定义模块的全局函数则可以配置 METH_NOARGS 并移除函数参数，参考如下代码。\n\n```c\n\nstatic PyObject *_maix_help() {\n    return PyUnicode_FromString(_maix_doc);\n}\n\nstatic PyMethodDef _maix_methods[] = {\n    {\"help\", (PyCFunction)_maix_help, METH_NOARGS, _maix_doc},\n    {NULL}\n};\n\n```\n\n关于编写 CPython 模块的参考资料很多，这里只说明 MaixPy3 模块常用的程序设计，具体到函数的如何实现的细节就不在此赘述。\n\n### CPython 的内存标记用法\n\n可知 Python 拥有自动回收内存的 gc 机制，但在使用 Python C/C++ API 扩展 Python 模块时，对象指针标记不当可能会导致扩展的模块存在内存泄漏，可以使用 Py_INCREF（增加） & Py_DECREF（减少） 指针引用计数。\n\n```c\nPy_INCREF(ref);\n......\nPy_DECREF(ref); // Py_XDECREF(ref);\n```\n\n对应 Python 代码就是：\n\n```python\nref = 1\n....\ndel ref\n```\n\n可以理解为想要 gc 主动释放一个对象，就需要将其引用标志减少到无（0）。\n\n关于标记指针的说明上有用的文章。\n\n- 在开发时的注意事项请查阅 [使用 C 写 Python 模块时内存回收管理，Py_INCREF() 和 Py_DECREF() 的使用方式和注意点](https://neucrack.com/p/340)\n- 关于原理性的源码解析 [解密Python中的垃圾回收机制](https://www.cnblogs.com/traditional/p/13698244.html)\n\n如果你不能确定当前指针是否已经被回收，则你可以在使用前对 PyObject 结构指针进行引用计数的判断，也可以对该结构的类型做判断，从而确保可以操作该对象。\n\n```c\n\nassert(self->ob_refcnt > 0);\n\nPyAPI_DATA(PyTypeObject) PyBool_Type;\n#define PyBool_Check(x) Py_IS_TYPE(x, &PyBool_Type)\n\n```\n\n这样你就可以放心的操作内部创建的对象实例了。\n\n### CPython 模块的编写约束\n\n因为强调面向接口编程，所以 Python 模块下的 libXXXX 模块都是在各自的仓库编译通过后，再通过 setup.py 模块定义接口之间进行链接的，有些子仓库就是这么来的。\n\n也就是说不对编写代码风格做约束，但会对模块的接口做约束。\n\n要求每个模块的层次关系分离，以模块（PyModule）、对象（PyObject）、方法（PyCFunction）为接口参考，有如下结构。\n\n```shell\n+----------+         +-------------+\n|          +---------+ PyCFunction | 全局函數\n| PyModule |         +-------------+\n|          +<---+\n+----------+    |\n                |模块对象\n             +--+-------+\n             | PyObject +<---+\n             +----------+    |\n                             |\n                     +-------+-----+\n                     | PyCFunction | 成员函數\n                     +-------------+\n```\n\n因此请遵循该接口设计进行 Python 模块的开发。\n\n## 一些额外的内容\n\n### 使用 bdist_wheel 打包对应平台 wheel 包\n\n打包成对应平台的 wheel 的 bdist_wheel 的命令需要 setuptools 中支持。\n\n> 而 distutils 只可以构建 bdist 包。\n\nbdist_wheel 是将当前代码构建的最终文件都打包好，然后在安装的时候只需要释放到具体的安装目录下就结束了，这对于一些不能进行编译工作的硬件来说是极好的。\n\n确认 wheel 包是否可以被安装，只需要看名称就知道了，例如 `python3_maix-0.1.2-cp38-cp38-linux_x86_64.whl` 包，我们可以看到 `cp38-cp38-linux_x86_64` 标识。\n\npip 在安装的时候就会通过 `from pip._internal.utils.compatibility_tags import get_supported` 函数判断当前系统是否可以支持这个包，如果你改名了，它也是可以安装进去的,但能不能运行就取决于系统环境了，注意 armv7.whl 和 armv7l.whl 并不相同。\n\n> 细节阅读 [2021 年 当安装 wheel 出现 whl is not a supported wheel on this platform. 的时候](https://www.cnblogs.com/juwan/p/14250104.html)\n\n###  自动化测试框架 tox 的使用说明\n\n在本机上使用 `pip3 install tox` 完成安装，接着在 MaixPy3 根目录下运行 tox 即可。\n\n它会自动构建指定的 Python 虚拟测试环境，进行打包构建，安装解包的测试，最后会收集整个目录下的 `test_*.py` 的代码加入到自动测试当中，如果你不想让个别代码参与测试，你可以改名成 `no_test_*.py` 方便排除和保留文件。\n\n更多请自行查阅 [Python 任务自动化工具 tox 教程](https://www.cnblogs.com/daniumiqi/p/12179453.html) 和官方文档 [tox.readthedocs.io](tox.readthedocs.io) 。\n\n### *关于 V831 或其他平台芯片如何使用\n\n以上文档为通用说明，使用方法差异的地方在于调用 Python 指令有所不同。\n\n例如加载 V831 等其他平台的 SDK 环境后，要将上述命令中的 python3 改成对应 SDK 环境的 python3.8 用以调用交叉编译的 Python 解释器，从而完成目标 arm 平台的交叉编译，这是由 SDK 提供时决定的，其他平台统一按这个结构载入即可。\n\n### 调用 get-pip.py 手动为 Python pip 安装指定包。\n\n有时候一些交叉编译里面的 Python 环境可能会缺少 pip ，如果想要安装包，就可以用这样的方式从外部装进去。\n\n- `./python3.7 get-pip.py Cython --target=../usr/lib/python3.7/site-packages/`"}, "/soft/maixpy3/zh/others/product.html": {"title": "如何提交你的产品", "content": "---\ntitle: 如何提交你的产品\nkeywords: MaixPy, MaixPy3, Python, Python3, MicroPython\ndesc: maixpy doc: 如何提交你的产品\n---\n\n当完成了一款芯片平台的适配后，想要合并进 MaixPy3 仓库，本文会对此做出说明。\n\n## 提供你的编译配置\n\n如 [envs/maix_v831.py](https://github.com/sipeed/MaixPy3/blob/main/envs/maix_v831.py) Python 包编译的配置，主要是用于区分适配在 maix 系列的 v831 产品，建议以芯片型号为区分，也许产品定义会不同，这时候就需要示例代码或文档来完成产品功能的区分了。\n\n## 提供你的示例代码\n\n如 [examples](https://github.com/sipeed/MaixPy3/tree/main/examples) 目录下的 maix_v831 文件夹，你可以在这里放置与你平台有关的程序、配置脚本、代码等资源。\n\n## 提供你的相关文档\n\n> 一般情况下可以不提供编译文档说明，这层的差异可能会在交叉编译链时解决，编译命令类似于 `python3.x setup.py xxxxx build` 的结构。\n\n你可以在 [docs](https://github.com/sipeed/MaixPy3/tree/main/docs) 目录下存放公共文档，也可以在 [examples](https://github.com/sipeed/MaixPy3/tree/main/examples) 下的产品文件夹里存放专用的文档。\n\n提供的文档类型可以是 markdown 或 jupyter notebook 文档。\n\n可以提供开发方法、如何编译的文档，也可以提供各类设备特有的示例文档，建议通过 jupyter notebook 文档可以达到所见即所得的效果。\n\n## 关于其他内容\n\n2021年02月24日 现在仓库里还不会收录有关于交叉编译链、量产工具、烧录工具、训练工具等等与代码或文档无关的内容。\n\n若是上述内容有不能够适应其他平台的地方，可以在 issue 里发起讨论，一起探讨和分享如何改进项目结构。\n\n> 快快把你的代码提交进来吧！"}, "/soft/maixpy3/zh/others/platform.html": {"title": "如何适配你的平台", "content": "---\ntitle: 如何适配你的平台\nkeywords: MaixPy, MaixPy3, Python, Python3, MicroPython\ndesc: maixpy doc: 如何适配你的平台\n--- \n\n> 通过【MaixPy3开发文档】可知基础的 Python3 编译、安装、测试等开发方法。\n\n本文基于 [MaixPy3 项目主页](https://github.com/sipeed/MaixPy3) 详细地介绍了 MaixPy3 项目结构，帮助你更好的适配 MaixPy3 环境。\n\n## 2021 年的 Python 可以彻底跨平台了吗？\n\n答案是还不足够的，仍然有很多依赖底层库差异导致了 Python 模块难以跨平台兼容。\n\n虽然绝大部分软件模块（如：pil、numpy、urllib3）都支持跨平台了，但在嵌入式 linux 设备的 Python 调用硬件资源（如：video \\ audio \\ nn）的问题上，仍然不能达到理想的跨平台接口。\n\n因此 MaixPy3 是围绕一系列支持边缘 AI 的 Linux 设备来做的，短期内不会考虑所有平台（如 Android & Windows ）。\n\n## 适配 MaixPy3 流程是怎样的？\n\n除去必要 Python3 调取硬件资源的方法，在 MaixPy3 上的开发更像是自上而下的模块接口统一的工作。\n\n可以从上层软件往下要求硬件提供相关功能模块的适配。\n\n从用户角度描述常用的功能如下：\n\n- 支持显示器（display）\n- 支持摄像头（camera）\n- 支持音频录音播放（audio）\n- 支持神经网络算法（nn）\n- 支持按键、触摸、鼠标、键盘等事件（evdev）\n- 支持点灯（gpio）\n- 支持上网（network）\n- 支持访问 I2C / SPI / UART / USB 等协议外设或传感器\n\n于是适配功能的流程描述如下：\n\n1. 首先在 Linux 系统上提供上述功能模块，可以动（静）态依赖库提供，也可以系统调用提供，~~还可以直接寄存器操作~~。\n2. 接着通过更多的 Python3 拓展模块实现相应的功能，此时拥有该模块基础使用的 Python 代码。\n3. 最后在 MaixPy3 中统一存在差异的 Python 代码，屏蔽不同设备不同硬件的差异。\n\n## 以适配【显示器】为例\n\n> 由于各个产品的硬件适配程度不同，有些过程可能已经提前完成，你可以选择跳过。\n\n想要使用 Python 在屏幕上显示内容，可以先从上层 Python 代码开始描述功能，为了能够解决基本的图像处理，选择一个 Python 中经典流行通用的 PIL 图像库 [pillow](https://github.com/python-pillow/Pillow)。\n\n现在可以使用代码打开图片并显示到屏幕上了：\n\n```python\nfrom PIL import Image\nim = Image.new(\"RGB\", (640, 480), \"#FF0000\")\nim.show()\n```\n\n这时候若是从【显示器】的角度设计一个 display 模块，可以写成如下代码：\n\n```python\nfrom PIL import Image\nfrom maix import display\ndisplay.show(Image.new(\"RGB\", (640, 480), \"#FF0000\"))\n```\n\n而 `from maix import display` 的实现可以简化成如下代码：\n\n```python\nfrom PIL import Image\ndisplay = Image.new(\"RGB\", (640, 480), \"#FF0000\")\n\ndef show(img):\n  global display\n  if isinstance(img, Image.Image):\n    display.paste(img, box)\n  display.show()\n```\n\n这时候 `display` 模块的角度就是作为显示器模块，实现了同一份代码在不同类型的 Linux 设备之间产生同样的效果。\n\n![](./asserts/pil_view.jpg)\n\n在达到这样的效果验证后，就可以开始做具体的移植适配。\n\n### 准备 Linux / Python3 / pillow 等基础功能模块\n\n准备一个目标 Linux 平台上的 Python3 解释器，与之配套的还有 目标平台的 GCC 编译链与系统目录（/usr/include & /lib）相关文件。\n\n> 期间经历一系列的目标 Linux 平台的系统移植和编译操作后\n\n在确保 Linux 系统可以运行 Python 解释器后，通过 pip 下载安装 pillow 模块，验证上述 Python 实现的功能后，在 MaixPy3 的 setup.py 中给 `setup()` 函数的 `install_requires` 参数加入 `pillow` 模块。\n\n这时候用户在安装 `pip install MaixPy3` 的时候，由于 MaixPy3 依赖于 pillow 这个模块，如果安装过程中发现系统里没有，就会尝试下载编译安装 pillow 模块，但对于一些不能编译安装模块的 Linux 设备就需要系统里直接内置 pillow 模块，以减少用户的困扰。\n\n### 但运行代码后并没有效果\n\n为什么？\n\n这是因为不同平台的屏幕的显示方式（命令）有所不同，不妨从 pillow 来看看的 show 是如何工作的。\n\n```python\nfrom PIL import Image\nim = Image.new(\"RGB\", (640, 480), \"#FF0000\")\nim.show()\n```\n\n在这段代码中的 `im.show()` 最终会依赖于 [ImageShow.py](https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageShow.py) 来完成图像对象的展示。\n\n在 Linux 上是如何工作的呢？\n\n```python\n\nclass UnixViewer(Viewer):\n    format = \"PNG\"\n    options = {\"compress_level\": 1}\n\n    def get_command(self, file, **options):\n        command = self.get_command_ex(file, **options)[0]\n        return f\"({command} {quote(file)}; rm -f {quote(file)})&\"\n\n    def show_file(self, file, **options):\n        \"\"\"Display given file\"\"\"\n        fd, path = tempfile.mkstemp()\n        with os.fdopen(fd, \"w\") as f:\n            f.write(file)\n        with open(path) as f:\n            command = self.get_command_ex(file, **options)[0]\n            subprocess.Popen(\n                [\"im=$(cat);\" + command + \" $im; rm -f $im\"], shell=True, stdin=f\n            )\n        os.remove(path)\n        return 1\n\n\nclass DisplayViewer(UnixViewer):\n    \"\"\"The ImageMagick ``display`` command.\"\"\"\n\n    def get_command_ex(self, file, **options):\n        command = executable = \"display\"\n        return command, executable\n\n```\n\n可以看到 DisplayViewer 继承 UnixViewer 对象，在 show_file 的时候将图像文件缓存到临时文件（`tempfile.mkstemp()`），再通过 get_command_ex 调用 display 系统命令（程序）完成图像的显示。\n\n> 简单来说就是【在显示器上显示一张图片】的意思。\n\n![](./asserts/display_cmd.jpg)\n\n那在嵌入式 arm Linux 硬件又会是怎样的呢？\n\n在 v831 的 linux 系统中可以使用和 display 类似的 fbviewer 程序来显示一张图像。\n\n```\nroot@sipeed:/# fbviewer /home/res/logo.png \nfbv - The Framebuffer Viewer\n/home/res/logo.png\n140 x 140\n```\n\n如何注入 fbviewer 的显示接口进 pillow 模块呢？（在 `maix/__init__.py` 中有如下一段代码）\n\n```python\ntry:\n  import shutil\n  from PIL import ImageShow\n  # use fbviewer on linux\n  # os.system('ln -s /usr/sbin/fbviewer /usr/sbin/display')\n  if shutil.which(\"fbviewer\"):\n    class fbViewer(ImageShow.UnixViewer):\n      def get_command_ex(self, file, **options):\n        command = executable = \"fbviewer\"\n        return command, executable\n    ImageShow.register(fbViewer, 0)\nexcept ModuleNotFoundError as e:\n  pass\n\n```\n\n可以看到当发现系统里有 fbviewer 时就会将该类注入到 PIL 的 ImageShow 的显示接口中，又或是在系统里直接将 fbviewer 链接到 display 命令上。\n\n现在已经成功适配到具体的屏幕操作了，但这样就足够了吗？\n\n### 这样还不够，这样实现仅是完成了功能。\n\n简单分析一下，上述实现性能损耗主要发生在当图像对象进入 pillow show_file 的时候需要对其编码保存到某个临时文件（/tmp）中，然后再交给 fbviewer 去打开文件，fbviewer 对其解码后再写到 framebuffer 的设备（/dev/fb0）上。\n\n问：为什么不把图像的 rgb 数组直接写到 fb 上呢？\n\n答：没错，内部的 _maix_display 拓展模块实现是这样做的。\n\n```c++\nPyDoc_STRVAR(Display_draw_doc, \"draw()\\nDraw image(rgb888) bytes data to lcd.\\n\");\nstatic PyObject *Display_draw(V831DisplayObject *self, PyObject *args)\n{\n    PyObject *img_bytes = NULL;\n    int img_width = 0, img_height = 0;\n    if (!PyArg_ParseTuple(args, \"Oii\", &img_bytes, &img_width, &img_height))\n    {\n        return NULL;\n    }\n    if (NULL != self->disp) {\n      if (self->disp->width >= img_width && self->disp->height >= img_height) {\n          uint8_t *rgb_data = (uint8_t *)PyBytes_AS_STRING(img_bytes);\n          if (rgb_data != NULL) {\n            self->disp->draw(self->disp, rgb_data, (self->disp->width - img_width) / 2,(self->disp->height - img_height) / 2, img_width, img_height, 1);\n          }\n      }\n    }\n    Py_RETURN_NONE;\n}\n```\n\n```python\nfrom _maix_display import V831Display\n__fastview__ = V831Display(__width__, __height__)\n__fastview__.draw(img.tobytes(), __fastview__.width, __fastview__.height)\n```\n\n这就是【屏幕清屏（变黑） `dd if=/dev/zero of=/dev/fb0` 】与【显示黑色图片 `display black.bmp` 】之间存在的性能差距。\n\n至此【显示器】基本适配完成了，其他模块亦如此，但不一定每个模块都要使用这样方式进行移植，只是出于性能的考虑可以这样做。\n\n> 可以自行查阅 Linux framebuffer 相关资料了解更多。\n\n### 以 Maix 包作为通用的 Python API\n\n做完上述功能后，就要回到这里思考一个用户体验的问题（开发者也可以是用户）。\n\n如何让同一份代码在不同平台表现一致，减少用户的再次学习成本和认知成本，所以制作了一个 maix 入口模块，以减少重复实现的功能代码。\n\n> 若是不使用某个模块（maix）去约束入口代码，就会产生代码碎片化，就如同你所看到的 Linux 上各种 Python 功能模块，做同一件事，不同平台上的接口与用法都不尽相同，但你需要花费不少时间去寻找并使用，为什么不能统一常用的功能接口呢，答案肯定是可以的，但这可能需要一些时间。\n\n从摄像头获取一张图片并显示出来这样的功能，使用如下代码就可以实现这个功能，并且它在大多数平台上都是可以做到的。\n\n```python\nfrom maix import display, camera\ndisplay.show(camera.capture())\n```\n\n为了实现上述统一接口，就需要在 [maix/video.py](https://github.com/sipeed/MaixPy3/blob/main/maix/video.py) 中多次 import 直到能够匹配的平台接口，这就会产生很多肮脏的接口代码，就如下所示。\n\n```python\n\ncamera = MaixVideo()\n\ntry:\n    # use libmaix on v831\n    from _maix_camera import V831Camera\n\n    class V831MaixVideo(MaixVideo):\n\n        def __init__(self, source=\"/v831\"):\n            self.source = source\n            self.cam = None\n\n        def config(self, size=(480, 360)):\n            if self.cam == None:\n                super(V831MaixVideo, self).__init__(size)\n                self.cam = V831Camera(self.width(), self.height())\n                import time\n                time.sleep(0.2) # wait init\n                print('[camera] config input size(%d, %d)' %\n                      (self.width(), self.height()))\n\n        def read(self):\n            if self.cam == None:\n                print('[camera] run config(size=(w, h)) before capture.')\n                self.config()\n            if self.cam:\n                ret, frame = self.cam.read()\n                if ret:\n                    return frame  # bytes\n            return None\n\n        def __del__(self):\n            if self.cam:\n                self.cam.close()\n                self.cam = None\n\n    camera = V831MaixVideo()\nexcept Exception as e:\n    pass\n\ntry:\n    from cv2 import VideoCapture\n\n    class CvMaixVideo(MaixVideo):\n\n        def __init__(self, source=0):\n            super(CvMaixVideo, self).__init__((640, 480))\n            self.source = source\n            self.cam = VideoCapture(0)\n\n        def read(self):\n            ret, frame = self.cam.read()\n            if ret:\n                bgr = frame[..., ::-1]  # bgr2rgb\n                return bgr.tobytes()  # bytes\n            return None\n\n        def __del__(self):\n            self.cam.release()\n\n    camera = CvMaixVideo()\nexcept Exception as e:\n    pass\n\n```\n\n> 这样的代码并不会多次运行，只会 import 的时候载入一次。\n\n像 MaixPy3 在设计 display 和 camera 模块的时候都尽可能围绕则 pillow 和 python-opencv 模块的接口设计衍生而来的，可以看到 camera 的 MaixVideo 定义如下，是参考 opencv 结构实现的。\n\n```python\n\nclass MaixVideo():\n\n    def __init__(self, size=(640, 480)):\n        self._width, self._height = size\n        \n    def width(self):\n        return self._width\n      \n    def height(self):\n        return self._height\n      \n    def write(self):\n        pass  # for file\n\n    def read(self):\n        return b'\\xFF\\x00\\x00' * (self._width * self._height)\n\n    def config(self, size):\n        pass\n\n    def capture(self):\n        from PIL import Image\n        tmp = self.read()\n        if tmp:\n            return Image.frombytes(\"RGB\", (self._width, self._height), tmp)\n        return None\n\n    def close(self):\n        pass  # for file\n\n```\n\n后来加入的 i2c \\ spi \\ pwm \\ gpio 也尽量以通用接口实现。\n\n但也有一些例外，如 [PyAudio](http://people.csail.mit.edu/hubert/pyaudio/) 在对接具体音频驱动设备存在 alsa 和 tinyalsa 两类接口，就需要从底层上去完成 Python 拓展 C 模块的编写，从而实现上层接口的一致，而截止 2021 年的神经网络 NN 模块实现更是千奇百怪，还难以统一。\n\n所以通过 maix 模块作为用户调用的 API 入口，重新围绕功能来抽象设计对用户友好且统一的通用接口。\n\n这样在不同平台上只需要链接不同的 Python 依赖模块即可，如 v831 链接的是 _maix_camera 模块，而 pc 上直接使用 opencv-python 模块，当然也可以是任意调用其他模块，不一定是 MaixPy3 所提供的参考模块，这取决于你的想法。\n\n## 附录：如何优化 Python 模块？（以 GPIO 为例）\n\nPython 上通用软件的接口大多都是通过 shell 接口调用系统程序完成的功能，所以在执行性能上有很大的损失。\n\n所谓经过优化实际上是通过内置代码模块的方式进行操作的，这样就减少了不必要的数据交换了。\n\n那么执行性能究竟差在哪里？除了上述说的【显示器】适配时的优化，下面再以 GPIO 的实现为例说明这个问题。\n\n如果站在使用 Python 进行的 Linux 应用编程角度，可以这样实现 GPIO 的控制。\n\n### 使用 sysfs 的接口\n\n可以在 shell 接口配置 gpio 完成输入输出、拉高拉低。\n\n```bash\nsudo su\ncd /sys/class/gpio\necho 12 > export\necho out > gpio12/direction       # io used for output\necho 1 > gpio12/value             # output logic 1 level\necho 0 > gpio12/value             # output logic 0 level\necho 12 > unexport\n```\n\n而在 Python 里可以使用 os.system() 来输入 shell 命令完成。\n\n### 使用 gpiod 的接口\n\n可以参考 [python3-gpiod](https://github.com/hhk7734/python3-gpiod) 的实现，主要它是对 /dev/gpiodchipX 设备进行操作的。\n\n```python\n\ndef gpiod_chip_open(path: str) -> Optional[gpiod_chip]:\n    \"\"\"\n    @brief Open a gpiochip by path.\n    @param path: Path to the gpiochip device file.\n    @return GPIO chip handle or None if an error occurred.\n    \"\"\"\n    info = gpiochip_info()\n\n    try:\n        fd = os_open(path, O_RDWR | O_CLOEXEC)\n    except FileNotFoundError:\n        return None\n\n    # We were able to open the file but is it really a gpiochip character\n    # device?\n    if not _is_gpiochip_cdev(path):\n        os_close(fd)\n        return None\n\n    status = ioctl(fd, GPIO_GET_CHIPINFO_IOCTL, info)\n    if status < 0:\n        os_close(fd)\n        return None\n\n    if info.label[0] == \"\\0\":\n        label = \"unknown\"\n    else:\n        label = info.label.decode()\n\n    return gpiod_chip(\n        num_lines=info.lines, fd=fd, name=info.name.decode(), label=label\n    )\n\n```\n\n可以通过 shell 接口操作 /sys/class/gpio 对象，也可以通过 `from fcntl import ioctl` 操作字符设备文件进行控制，与第一种差别不大。\n\n### 使用 mmap 的接口\n\n在 Linux 下直接读写物理地址，打开设备文件 /dev/mem 后使用 mmap 进行物理地址的映射，最后查阅数据手册获取寄存器地址读写相应的寄存器。\n\n> 节选部分代码说明意图，注意不同平台的定义和实现都不尽相同。\n\n```c++\n\nunsigned int SUNXI_PIO_BASE = 0;\nstatic volatile long int *gpio_map = NULL;\n\nint sunxi_gpio_init(void) {\n    int fd;\n    unsigned int addr_start, addr_offset;\n    unsigned int PageSize, PageMask;\n\n\n    fd = open(\"/dev/mem\", O_RDWR);\n    if(fd < 0) {\n        return SETUP_DEVMEM_FAIL;\n    }\n\n    PageSize = sysconf(_SC_PAGESIZE);\n    PageMask = (~(PageSize-1));\n\n    addr_start = SW_PORTC_IO_BASE & PageMask;\n    addr_offset = SW_PORTC_IO_BASE & ~PageMask;\n\n    gpio_map = (void *)mmap(0, PageSize*2, PROT_READ|PROT_WRITE, MAP_SHARED, fd, addr_start);\n    if(gpio_map == MAP_FAILED) {\n        return SETUP_MMAP_FAIL;\n    }\n\n    SUNXI_PIO_BASE = (unsigned int)gpio_map;\n    SUNXI_PIO_BASE += addr_offset;\n\n    close(fd);\n    return SETUP_OK;\n}\n\n```\n\n然后编写相应的 Python 拓展 C 模块调用上述接口。\n\n```c++\n\n#define PD0    SUNXI_GPD(0)\n#define PD1    SUNXI_GPD(1)\n#define PD2    SUNXI_GPD(2)\n#define PD3    SUNXI_GPD(3)\n#define PD4    SUNXI_GPD(4)\n#define PD5    SUNXI_GPD(5)\n#define PD6    SUNXI_GPD(6)\n#define PD7    SUNXI_GPD(7)\n#define PD8    SUNXI_GPD(8)\n#define PD9    SUNXI_GPD(9)\n#define PD10    SUNXI_GPD(10)\n#define PD11    SUNXI_GPD(11)\n#define PD12    SUNXI_GPD(12)\n#define PD13    SUNXI_GPD(13)\n#define PD14    SUNXI_GPD(14)\n#define PD15    SUNXI_GPD(15)\n#define PD16    SUNXI_GPD(16)\n#define PD17    SUNXI_GPD(17)\n#define PD18    SUNXI_GPD(18)\n#define PD19    SUNXI_GPD(19)\n#define PD20    SUNXI_GPD(20)\n#define PD21    SUNXI_GPD(21)\n#define PD22    SUNXI_GPD(22)\n#define PD23    SUNXI_GPD(23)\n#define PD24    SUNXI_GPD(24)\n#define PD25    SUNXI_GPD(25)\n#define PD26    SUNXI_GPD(26)\n#define PD27    SUNXI_GPD(27)\n\n#define MISO    SUNXI_GPE(3)\n#define MOSI    SUNXI_GPE(2)\n#define SCK     SUNXI_GPE(1)\n#define CS      SUNXI_GPE(0)\n\nstatic int module_setup(void) {\n    int result;\n\n    result = sunxi_gpio_init();\n    if(result == SETUP_DEVMEM_FAIL) {\n        PyErr_SetString(SetupException, \"No access to /dev/mem. Try running as root!\");\n        return SETUP_DEVMEM_FAIL;\n    }\n    else if(result == SETUP_MALLOC_FAIL) {\n        PyErr_NoMemory();\n        return SETUP_MALLOC_FAIL;\n    }\n    else if(result == SETUP_MMAP_FAIL) {\n        PyErr_SetString(SetupException, \"Mmap failed on module import\");\n        return SETUP_MMAP_FAIL;\n    }\n    else {\n        return SETUP_OK;\n    }\n\n    return SETUP_OK;\n}\n\nstatic PyObject* py_init(PyObject* self, PyObject* args) {\n\n    module_setup();\n\n    Py_RETURN_NONE;\n}\n\nPyMethodDef module_methods[] = {\n    {\"init\", py_init, METH_NOARGS, \"Initialize module\"},\n    {\"cleanup\", py_cleanup, METH_NOARGS, \"munmap /dev/map.\"},\n    {\"setcfg\", py_setcfg, METH_VARARGS, \"Set direction.\"},\n    {\"getcfg\", py_getcfg, METH_VARARGS, \"Get direction.\"},\n    {\"output\", py_output, METH_VARARGS, \"Set output state\"},\n    {\"input\", py_input, METH_VARARGS, \"Get input state\"},\n    {NULL, NULL, 0, NULL}\n};\n\n```\n\n这样与上述实现 display 模块到优化处理的思路是相通的，目的都是减少不必要的接口之间的数据交换达到最终优化的目的。\n\n### 总结\n\n无论是哪种方法本意想通过抽象封装的通用接口来解决不同硬件上的差异，但有时会因为性能和内存的问题，只能放弃抽象直接访问底层寄存器硬件以提高性能。\n\n> 上述接口的操作都是处于 linux 用户空间进行的，使用 Python 和 C 访问 /sys/class/gpio 设备在程序逻辑上并无区别，但从执行代码段和传递变量消耗的角度来看，越靠近底层的实现执行效率自然越高，通过 Python 拓展模块实现的 mmap 映射操作相对于直接使用 C 代码实现而言，两者性能差异几乎可以忽略不计，所以 Python 程序也不一定会性能低下，主要还是取决于具体的实现方式。\n\n如果还想继续提高性能，就需要把寄存器操作下到内核空间了，可能这对于一些用户来说并不是必要的，例如用户点灯相对于系统而言是低频操作，而模拟 SPI 通信需要控制 GPIO 翻转则是高频操作，而从用户的角度来说，实现这个点灯功能（低频操作）对性能的要求不敏感，可以不做优化。\n\n因此要根据硬件的实际情况，在性能与功能之间选择一个折衷的实现。"}, "/soft/maixpy3/zh/update_history.html": {"title": "MaixPy3更新历史", "content": "# MaixPy3更新历史\n\n\n## 2021/8/5\n增加了MiaxII Dock在windows下的dd烧录方法。\n\n## 2021/8/2\n更新了MiaxII Dock的烧录方式，不再使用PhoenixSuit进行烧录。"}, "/soft/maixpy3/zh/develop/v83x_isp.html": {"title": "", "content": "## M2DOCK 摄像头 ISP 调试（待公开）\n\n- 摄像头 ISP 调试的经验之谈（以全志 AW hawkview 为例） https://www.cnblogs.com/juwan/p/14865188.html\n\n- 开源 SDK 地址 https://github.com/Tina-V833/tina-V833 与 文档 [Sipeed 内部培训] V831/V833 的 SDK 的 kernel & package 的开发方法 https://www.cnblogs.com/juwan/p/15226245.html\n\n- 摄像头调试工具 TigerISP-20211225.7z https://api.dl.sipeed.com/shareURL/MaixII/MaixII-Dock/tools\n\n## 相关视频\n\n<iframe src=\"//player.bilibili.com/player.html?aid=978258498&bvid=BV1p44y1L7t3&cid=487661962&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>"}, "/soft/maixpy3/zh/develop/r329_yolo.html": {"title": "", "content": "## R329 yolo 模型\n\n开发完成时间： maixpy3 0.4.0\n\n同步支持 V831 & R329\n\n## 进度\n\n- 至今模型未公开，代码已提交。\n\n## 相关视频\n\n<iframe src=\"//player.bilibili.com/player.html?aid=680815271&bvid=BV1kS4y157av&cid=487529883&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>"}, "/soft/maixpy3/zh/develop/opmv_cv.html": {"title": "", "content": "## maixpy3 图像处理加速模块\n\n开发原型时间： maixpy3 0.4.0 以上\n\n预计开发时间：已完成，等待 release 公开。\n\n开发目标：优先实现 找色 找色 找球 找块 模板匹配 特征匹配 仿射变换 之类的常用图像处理算法。\n\n## 进度\n\n- 项目地址 https://github.com/dianjixz/minicv2\n\n## 开发情况\n\n已投入使用。"}, "/soft/maixpy3/zh/develop/face_reco.html": {"title": "", "content": "## R329 人脸识别\n\n## 目前进度\n\n- 已完成，等待release。\n\n## 相关视频\n\n<iframe src=\"//player.bilibili.com/player.html?aid=295857402&bvid=BV18F411p7mD&cid=488991789&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>"}, "/soft/maixpy3/zh/develop/maixpy3_mfcc.html": {"title": "", "content": "## maix 关键词 MFCC 检测\n\n开发原型时间： maixpy3 0.4.0 以上\n\n预计开发时间： 已完成，等待 release 合并。\n\n开发目标：可以学习的语音识别，比较适合实际的固定场景。\n\n## 进度\n\nhttps://github.com/junhuanchen/speech-recognition\n\nlinux 通用的简易 VAD + MFCC 关键词识别，使用方法如下：\n1. 输入 n 等待人说话，输入序号保存录音。\n2. 输入 l 查看 waves words 目录下保存的语音段。\n3. 输入 d 后说话，给出识别的保存的语音段可能的结果。\n4. 输入 e 退出。\n\n## 相关视频\n\n<iframe src=\"//player.bilibili.com/player.html?aid=585184775&bvid=BV1oz4y1C7yE&cid=251878910&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n<iframe src=\"//player.bilibili.com/player.html?aid=500528923&bvid=BV1xK41137Rv&cid=263534446&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>"}, "/soft/maixpy3/zh/develop/maixcam.html": {"title": "", "content": "## maix 二次开发串口固件\n\n开发原型时间： maixpy3 0.4.0 以上\n\n预计开发时间： 2022年 Q1 开始 Q2 结束。\n\n开发目标：将开发的成果打包转换成用户直接可用的串口固件。\n\n项目地址：https://github.com/sipeed/MaixSmart\n\n## 相关视频\n\n<iframe src=\"//player.bilibili.com/player.html?aid=465758292&bvid=BV1UL411c77c&cid=487544102&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n## 进度\n\n- 下位机原型 https://github.com/Neutree/maix-mm\n\n- 上位机原型 https://github.com/Neutree/COMTool\n\n- 云服务支持 https://maixhub.com/\n\n## 开发情况\n\n初版已经提交，待公开。"}, "/soft/maixpy3/zh/develop/apriltag.html": {"title": "", "content": "## apriltag\n\n开发原型时间： maixpy3 0.4.0 以上\n\n预计开发时间： 2022年 Q1 结束。\n\n开发目标：官方 apriltag 而非 openmv 版本\n\n## 相关视频\n\n<iframe src=\"//player.bilibili.com/player.html?aid=850839110&bvid=BV1wL4y1t7hc&cid=487534380&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n<iframe src=\"//player.bilibili.com/player.html?aid=677488628&bvid=BV1wm4y197Jf&cid=464634360&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n## 进度\n\n- libmaix 实现分支 https://github.com/sipeed/libmaix/blob/apriltag/examples/camera/main/src/main.c\n\n## 开发情况\n\n参考 https://book.openmv.cc/image/apriltag.html\n\n官网 https://april.eecs.umich.edu/software/apriltag.html\n\n## 性能指标记录\n\nV831 libmaix AprilTag tag36h11 SP2305 QVGA 30fps ~ OV7251 QQGVA 60fps\n\n采用 opencv 绘图，直出 yuv 取 y 做灰度识别，效果理想。"}, "/soft/maixpy3/zh/develop/Edge_detection.html": {"title": "边缘检测", "content": "# 边缘检测\n\n> 2022年01月11日 以下代码由于 Maixpy3 还在施工中，此处代码仅供参考和示范，功能已在 github 和 社区供其他同学使用和参考。\n\nPytorch 使用模型(卷积/conv)实现 sobel(索贝尔) 边缘检测实现源码\n\n> 目前只能在 V831 上进行部署使用，R329 后续会更新上来\n\n## 边缘检测效果\n![](./../asserts/test.jpg)\n![](./../asserts/sobel_edge2.jpg)\n![](./../asserts/final.jpg)\n![](./../asserts/sobel_edge.jpg)\n![](./../asserts/sobel_v831.jpg)\n\n\n源码在末尾\n\n## 边缘检测原理\n边缘就是值变化剧烈的地方, 如果对值的变化求导, 则边缘部分就是导数局部最大.\n但是在图像处理时没有具体的函数让我们求导, 使用卷积运算则可以很好的近似替代\n\n如下图, 假设左上为坐标原点, 横轴为 `x`, 纵轴为`y`, 如下图左上角9个像素点, `P(x, y)`表示坐标`(x, y)`的点, 要求`P(1, 1)`处在x轴的变化率, 则只需将`P(2, 1) - P(0, 1)` 得到值为`0`, `P(1, 0)`处为`1-3 = -2,` 这个差值即变化率, 类比成导数, 我们就能知道横轴在哪些地方变化率更大.\n![](./../asserts/conv.jpg)\n上面这种方法我们可以得到横轴的变化率, 这里使用卷积核\n```\n[-1, 0, 1],\n[-2, 0, 2],\n[-1, 0, 1]\n```\n对图像进行卷积运算, 如图中的计算方法, 像素点左右权值取2, 角上的也参与计算,但是权值为1,没有左右边的权值高. 这样我们就得到了横轴的变化率图, 即边缘检测图.\n\n注意, 这里是对横轴计算了, 比较的点左右的值变化, 所以实际看到的图像会出现明显的纵轴边缘, 如下图左边\n![](./../asserts/vertical_horizontal.jpg)\n同理, 上图右边的图使用卷积核\n\n[1,2,1],\n[0,0,0],\n[-1, -2, -1]\n得到的纵轴的边缘图.\n\n注意这里用右边减左边, 如果右边的值比左边的小会是负数, 如果我们希望只检测颜色值变大(变白)则可以直接使用, 如果两个变化方向都要检测, 则可以取绝对值. 比如下图左边是没有取绝对值, 右边取了绝对值\n![](./../asserts/without_with_abs.jpg)\n得到两个方向的图后, 对其进行合并, 对每个像素平方和开方即可\n![](./../asserts/final.jpg)\n这张图左边是使用 GIMP 的 sobel 边缘检测(垂直+水平)的效果, 略微有点不同:\n![](./../asserts/sobel_edge2.jpg)\n不同的原因是使用水平和垂直的图平方和开根后, 直接用 `plt.imshow` 显示, 和 GIMP 的处理方式不同\n```python\nout = np.sqrt(np.square(out_v) + np.square(out_h))\nplt.imshow(out)\n```\n简单地直接将值规范到`[0, 255]`就和 GIMP 的图相似了(但不完全一样)\n```python\nout = np.sqrt(np.square(out_v) + np.square(out_h))\nout = out * 255.0 / out.max()\nplt.imshow(out.astype(np.uint8))\n```\n![](./../asserts/sobel_v_h.jpg)\n## 自定义卷积核来实现边缘检测\n除了上面说了使用两次卷积计算, 也可以用只计算一次的卷积核, 比如:\n```bash\n[-1, -1, -1],\n[ -1, 8, -1],\n[ -1, -1, -1]\n```\n这是对于一个通道(灰度图)来说, 如果要扩充到三个通道(RGB), 卷积核参数就是如下形式\n```bash\nconv_rgb_core_sobel = [\n                        [[-1,-1,-1],[-1,8,-1], [-1,    -1,    -1],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [-1,-1,-1],[-1,8,-1], [-1,    -1,    -1],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [-1,-1,-1],[-1,8,-1], [-1,    -1,    -1],\n                        ]]\n```\n经过卷积运算后, 前后图如下:\n\n![](./../asserts/sobel_edge.jpg)\n\n注意, 输入值范围如果为`[0, 255]`, 输出值则范围会变化, 以图片形式查看时需要注意加以处理, 这里使用了`plt.imshow(out)`来显示, 这个函数会自动对图像做简单的处理, 才会看起来是黑色背景\n\n## 导出成模型使用\n可以将 Net 导出成 onnx 即可在其它平台使用, 就是一个简单的卷积层\n\n部署到 V831 后的样子(使用了卷积核`[-1,-1,-1],[-1,8,-1], [-1,-1,-1],`):\n\n![](./../asserts/sobel_v831.jpg)\n\nV831 部署[源码](https://github.com/sipeed/MaixPy3/blob/master/ext_modules/_maix_nn/example/load_forward_sobel_edge_camera.py)在 github， 模型在 maixhub 上可以下载\n\n## 边缘检测源码\n\n> 这是在电脑上运行的代码，不是在开发板平台上运行的代码\n\n```python\n\n'''\n    simple sobel edge demo\n    visit: https://neucrack.com/p/377\n    @author neucrack\n    @license MIT\n'''\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 3, 3, padding=(0, 0), bias=False)\n    def forward(self, x):\n        x = self.conv1(x)\n        return x\nnet = Net()\nconv_rgb_core_original = [\n                        [[0,0,0],[0,1,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,1,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,1,0], [0,0,0]\n                        ]]\nconv_rgb_core_sobel = [\n                        [[-1,-1,-1],[-1,8,-1], [-1,    -1,    -1],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [-1,-1,-1],[-1,8,-1], [-1,    -1,    -1],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [-1,-1,-1],[-1,8,-1], [-1,    -1,    -1],\n                        ]]\nconv_rgb_core_sobel_vertical = [\n                        [[-1,0,1],[-2,0,2], [-1,    0,    1],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [-1,0,1],[-2,0,2], [-1,    0,    1],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [-1,0,1],[-2,0,2], [-1,    0,    1],\n                        ]]\nconv_rgb_core_sobel_horizontal = [\n                        [[1,2,1],[0,0,0], [-1, -2, -1],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [1,2,1],[0,0,0], [-1, -2, -1],\n                         [0,0,0],[0,0,0], [0,0,0]\n                        ],\n                        [[0,0,0],[0,0,0], [0,0,0],\n                         [0,0,0],[0,0,0], [0,0,0],\n                         [1,2,1],[0,0,0], [-1, -2, -1],\n                        ]]\ndef sobel(net, kernel):\n    sobel_kernel = np.array(kernel,    dtype='float32')\n    sobel_kernel = sobel_kernel.reshape((3,    3,    3,    3))\n    net.conv1.weight.data = torch.from_numpy(sobel_kernel)\nparams = list(net.parameters())\nimg = cv2.imread(\"out/test.jpg\")\ninput_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\ninput_tensor = (input_img.astype(np.float32) - 127.5) / 128 # to [-1, 1]\ninput_tensor = torch.Tensor(input_tensor).permute((2, 0, 1))\nprint(input_tensor.shape)\ninput_tensor = input_tensor.unsqueeze(0)\nprint(\"input shape:\", input_tensor.shape)\nsobel(net, conv_rgb_core_sobel)\nout = net(input_tensor).detach().numpy()[0].transpose([1,2,0])\nsobel(net, conv_rgb_core_sobel_vertical)\nout_v = net(input_tensor).detach().numpy()[0].transpose([1,2,0])\nsobel(net, conv_rgb_core_sobel_horizontal)\nout_h = net(input_tensor).detach().numpy()[0].transpose([1,2,0])\nprint(\"out shape: {}, tensor:{}\".format(out.shape, out))\nprint(out.shape, out.max(), out.min())\nplt.figure()\nplt.figure()\nplt.subplot(1, 5, 1)\ninput = input_tensor.numpy()[0].transpose((1,2,0))\nprint(input.max(), input.min())\nplt.imshow(input_img)\nplt.subplot(1, 5, 2)\nprint(out.max(), out.min())\n# out = np.sqrt(np.square(out))\n# out = out * 255.0 / out.max()\n# out = out.astype(np.uint8)\n# print(out.max(), out.min())\nplt.imshow(out)\nplt.subplot(1, 5, 3)\nout = np.abs(out_v)\n# out = out * 255.0 / out.max()\n# plt.imshow(out.astype(np.uint8))\nplt.imshow(out)\nplt.subplot(1, 5, 4)\nout = np.abs(out_h)\n# out = out * 255.0 / out.max()\n# plt.imshow(out.astype(np.uint8))\nplt.imshow(out)\nplt.subplot(1, 5, 5)\nout = np.sqrt(np.square(out_v) + np.square(out_h))\n# out = out * 255.0 / out.max()\n# plt.imshow(out.astype(np.uint8))\nplt.imshow(out)\nplt.show()\n```\n\n## 参考\n- [How to implement Sobel edge detection using Python from scratch](http://www.adeveloperdiary.com/data-science/computer-vision/how-to-implement-sobel-edge-detection-using-python-from-scratch/)\n- [梯度和Sobel导数](https://blog.csdn.net/lzhf1122/article/details/71752644)\n\n> 以上内容出至于：<https://neucrack.com/p/377>"}, "/soft/maixpy3/zh/develop/self_yolo.html": {"title": "", "content": "## 自学习检测\n\n开发原型时间： maixpy3 0.4.0 以上\n\n预计开发时间： 2022年 Q1 结束。\n\n开发目标：对标 二哈 模块\n\n## 相关视频\n\n<iframe src=\"//player.bilibili.com/player.html?aid=465843172&bvid=BV1y5411f7Yy&cid=486868043&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n## 进度\n\n- 未公开"}, "/soft/maixpy3/zh/develop/maix_speech.html": {"title": "", "content": "## maix-speech\n\n开发完成时间： maixpy3 0.3.6\n\n同步支持 V831 & R329\n\n## 相关视频\n\n<iframe src=\"//player.bilibili.com/player.html?aid=465855870&bvid=BV1B5411f7wR&cid=487613553&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n## 进度\n\n- 至今模型未公开，代码已合并 https://github.com/sipeed/MaixPy3/tree/master/ext_modules/_maix_speech 。"}, "/soft/maixpy3/zh/develop/index.html": {"title": "MaixPy3 开发进度跟踪", "content": "---\ntitle: MaixPy3 开发进度跟踪\nkeywords: maixpy3, 开发进程\ndesc: maixpy3 doc: 开发进程\n---\n## MaixPy3 开发进度跟踪\n\n通常步骤说明如下（点不开可能是没有写说明，但有在做。）\n\n1. 在计划 （收到社区反馈）\n2. 开发中 （在做了在做了） 或 待移植 （需要复制粘贴修代码）\n3. 待测试 （在测了在测了）\n4. 待整理 （在写了在写了）\n5. 待公开 （此时已经完成了基本功能原型、性能与效果测试、相关应用与开发文档，但没有公开）\n6. 待合并 （该功能已经公开，但未能合并到 MaixPy3 项目，通常是某些硬件专属功能、工具）\n\n当完成上述步骤后，就表示该功能已进到 maixpy3 项目中。\n\n> 这样大家就可以知道 maixpy3 正在做什么了！ 逃！~ 季更！~"}, "/soft/maixpy3/zh/develop/resnet.html": {"title": "V831上部署resnet18分类网络", "content": "# V831上部署resnet18分类网络\n\n> 2022年01月11日 以下代码由于 Maixpy3 还在施工中，此处代码仅供参考和示范，功能已在 github 和 社区供其他同学使用和参考。\n\n## 前期准备\n在V831上使用resnet18分类网络，我们需要在linux环境下进行。windows系统可以使用虚拟机，或者是使用WSL，具体的安装教程请自行百度，这里就不过多的进行描述\n\n### 安装pytorch环境\n\n我们需要在系统中安装pytorch，通过在pytorch官网上可以知道安装pytorch需要执行\n\n    pip3 install torch==1.9.0+cpu torchvision==0.10.0+cpu torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n\n或者是通过conda环境进行安装\n\n    conda install pytorch torchvision torchaudio cpuonly -c pytorch\n\n我们还需要安装一个`torchsummary`库来进行神经网络的可视化\n\n    pip3 install torchsummary\n\n### 编译ncnn转换工具\n\n通过 `git clone https://github.com/Tencent/ncnn.git` 将ncnn的仓库拉取到本地，进行编译\n\n安装编译环境的依赖\n\n```bash\nsudo apt update\nsudo apt install build-essential git cmake libprotobuf-dev protobuf-compiler libvulkan-dev vulkan-utils libopencv-dev\n```\n编译ncnn需要使用到 Vulkan 后端\n要使用 Vulkan 后端，请安装 Vulkan 头文件、一个 vulkan 驱动程序加载器、GLSL 到 SPIR-V 编译器和 vulkaninfo 工具。或者从<https://vulkan.lunarg.com/sdk/home>下载并安装完整的 Vulkan SDK（大约 200MB；它包含所有头文件、文档和预构建的加载程序，以及一些额外的工具和所有源代码）\n\n```bash\nwget https://sdk.lunarg.com/sdk/download/1.2.182.0/linux/vulkansdk-linux-x86_64-1.2.182.0.tar.gz\ntar xvf vulkansdk-linux-x86_64-1.2.182.0.tar.gz\nexport VULKAN_SDK=$(pwd)/1.2.182.0/x86_64\n```\n\n拉取ncnn的子仓库\n\n```bash\ncd ncnn\ngit submodule update --init\n```\n\n开始编译ncnn\n```bash\nmkdir -p build\ncd build\ncmake -DCMAKE_BUILD_TYPE=Release -DNCNN_VULKAN=ON -DNCNN_SYSTEM_GLSLANG=ON -DNCNN_BUILD_EXAMPLES=ON ..\nmake -j$(nproc)\n```\n\n编译结束之后会在build/tools/onnx/下的到onnx2ncnn可执行文件，这个是就用ncnn的转换工具\n\n> 将编译出来的 onnx2ncnn 添加到系统的环境变量中\n\n## 获取模型并进行推理\n\n> 以下代码建议在jupyter中运行\n\n通过pytorch hub来获取resnet18的预训练模型，这里并不细说训练的过程和模型定义\n\nlabel[下载](https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt)\n使用以下代码进行模型的下载和推理\n```python\nimport os\nimport torch\nfrom torchsummary import summary\ntorch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n## model\nmodel = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\nmodel.eval()\ninput_shape = (3, 224, 224)\nsummary(model, input_shape, device=\"cpu\")\n## test image\nfilename = \"out/dog.jpg\"\nif not os.path.exists(filename):\n    if not os.path.exists(\"out\"):\n        os.makedirs(\"out\")\n    import urllib\n    url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", filename)\n    try: urllib.URLopener().retrieve(url, filename)\n    except: urllib.request.urlretrieve(url, filename)\nprint(\"test image:\", filename)\n## preparing input data\nfrom PIL import Image\nimport numpy as np\nfrom torchvision import transforms\ninput_image = Image.open(filename)\n# input_image.show()\npreprocess = transforms.Compose([\n    transforms.Resize(max(input_shape[1:3])),\n    transforms.CenterCrop(input_shape[1:3]),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\ninput_tensor = preprocess(input_image)\nprint(\"input data max value: {}, min value: {}\".format(torch.max(input_tensor), torch.min(input_tensor)))\ninput_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n## forward model\n# move the input and model to GPU for speed if available\nif torch.cuda.is_available():\n    input_batch = input_batch.to('cuda')\n    model.to('cuda')\nwith torch.no_grad():\n    output = model(input_batch)\n## result    \n# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n# print(output[0])\n# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\nmax_1000 = torch.nn.functional.softmax(output[0], dim=0)\nmax_idx = int(torch.argmax(max_1000))\nwith open(\"imagenet_classes.txt\") as f:\n    labels = f.read().split(\"\\n\")\nprint(\"result: idx:{}, name:{}\".format(max_idx, labels[max_idx]))\n```\n\n运行后得到结果:\n```python\nUsing cache found in /home/neucrack/.cache/torch/hub/pytorch_vision_v0.6.0\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 112, 112]           9,408\n       BatchNorm2d-2         [-1, 64, 112, 112]             128\n              ReLU-3         [-1, 64, 112, 112]               0\n         MaxPool2d-4           [-1, 64, 56, 56]               0\n            Conv2d-5           [-1, 64, 56, 56]          36,864\n       BatchNorm2d-6           [-1, 64, 56, 56]             128\n              ReLU-7           [-1, 64, 56, 56]               0\n            Conv2d-8           [-1, 64, 56, 56]          36,864\n       BatchNorm2d-9           [-1, 64, 56, 56]             128\n             ReLU-10           [-1, 64, 56, 56]               0\n       BasicBlock-11           [-1, 64, 56, 56]               0\n           Conv2d-12           [-1, 64, 56, 56]          36,864\n      BatchNorm2d-13           [-1, 64, 56, 56]             128\n             ReLU-14           [-1, 64, 56, 56]               0\n           Conv2d-15           [-1, 64, 56, 56]          36,864\n      BatchNorm2d-16           [-1, 64, 56, 56]             128\n             ReLU-17           [-1, 64, 56, 56]               0\n       BasicBlock-18           [-1, 64, 56, 56]               0\n           Conv2d-19          [-1, 128, 28, 28]          73,728\n      BatchNorm2d-20          [-1, 128, 28, 28]             256\n             ReLU-21          [-1, 128, 28, 28]               0\n           Conv2d-22          [-1, 128, 28, 28]         147,456\n      BatchNorm2d-23          [-1, 128, 28, 28]             256\n           Conv2d-24          [-1, 128, 28, 28]           8,192\n      BatchNorm2d-25          [-1, 128, 28, 28]             256\n             ReLU-26          [-1, 128, 28, 28]               0\n       BasicBlock-27          [-1, 128, 28, 28]               0\n           Conv2d-28          [-1, 128, 28, 28]         147,456\n      BatchNorm2d-29          [-1, 128, 28, 28]             256\n             ReLU-30          [-1, 128, 28, 28]               0\n           Conv2d-31          [-1, 128, 28, 28]         147,456\n      BatchNorm2d-32          [-1, 128, 28, 28]             256\n             ReLU-33          [-1, 128, 28, 28]               0\n       BasicBlock-34          [-1, 128, 28, 28]               0\n           Conv2d-35          [-1, 256, 14, 14]         294,912\n      BatchNorm2d-36          [-1, 256, 14, 14]             512\n             ReLU-37          [-1, 256, 14, 14]               0\n           Conv2d-38          [-1, 256, 14, 14]         589,824\n      BatchNorm2d-39          [-1, 256, 14, 14]             512\n           Conv2d-40          [-1, 256, 14, 14]          32,768\n      BatchNorm2d-41          [-1, 256, 14, 14]             512\n             ReLU-42          [-1, 256, 14, 14]               0\n       BasicBlock-43          [-1, 256, 14, 14]               0\n           Conv2d-44          [-1, 256, 14, 14]         589,824\n      BatchNorm2d-45          [-1, 256, 14, 14]             512\n             ReLU-46          [-1, 256, 14, 14]               0\n           Conv2d-47          [-1, 256, 14, 14]         589,824\n      BatchNorm2d-48          [-1, 256, 14, 14]             512\n             ReLU-49          [-1, 256, 14, 14]               0\n       BasicBlock-50          [-1, 256, 14, 14]               0\n           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n             ReLU-53            [-1, 512, 7, 7]               0\n           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n           Conv2d-56            [-1, 512, 7, 7]         131,072\n      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n             ReLU-58            [-1, 512, 7, 7]               0\n       BasicBlock-59            [-1, 512, 7, 7]               0\n           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n             ReLU-62            [-1, 512, 7, 7]               0\n           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n             ReLU-65            [-1, 512, 7, 7]               0\n       BasicBlock-66            [-1, 512, 7, 7]               0\nAdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n           Linear-68                 [-1, 1000]         513,000\n================================================================\nTotal params: 11,689,512\nTrainable params: 11,689,512\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 62.79\nParams size (MB): 44.59\nEstimated Total Size (MB): 107.96\n----------------------------------------------------------------\nout/dog.jpg\ntensor(2.6400) tensor(-2.1008)\nidx:258, name:Samoyed, Samoyede\n\n```\n可以看到模型有 11,689,512的参数， 即 11MiB左右， 这个大小也就几乎是实际在 831 上运行的模型的大小了\n\n## 模型转换\n\n### pth转onnx\n通过pytorch hub获取到的resnet18 模型是pth格式的，需要转换成onnx格式的模型\n\n转换代码\n```python\ndef torch_to_onnx(net, input_shape, out_name=\"out/model.onnx\", input_names=[\"input0\"], output_names=[\"output0\"], device=\"cpu\"):\n    batch_size = 1\n    if len(input_shape) == 3:\n        x = torch.randn(batch_size, input_shape[0], input_shape[1], input_shape[2], dtype=torch.float32, requires_grad=True).to(device)\n    elif len(input_shape) == 1:\n        x = torch.randn(batch_size, input_shape[0], dtype=torch.float32, requires_grad=False).to(device)\n    else:\n        raise Exception(\"not support input shape\")\n    print(\"input shape:\", x.shape)\n    # torch.onnx._export(net, x, \"out/conv0.onnx\", export_params=True)\n    torch.onnx.export(net, x, out_name, export_params=True, input_names = input_names, output_names=output_names)\nonnx_out=\"out/resnet_1000.onnx\"\nncnn_out_param = \"out/resnet_1000.param\"\nncnn_out_bin = \"out/resnet_1000.bin\"\ninput_img = filename\ntorch_to_onnx(model, input_shape, onnx_out, device=\"cuda:0\")\n\n```\n在out文件夹中得到onnx格式模型文件\n\n### onnx转ncnn\n\n然后再利用前面编译出来的onnx2ncnn转换工具进行ncnn格式的转换\n\n```python\ndef onnx_to_ncnn(input_shape, onnx=\"out/model.onnx\", ncnn_param=\"out/conv0.param\", ncnn_bin = \"out/conv0.bin\"):\n    import os\n    # onnx2ncnn tool compiled from ncnn/tools/onnx, and in the buld dir\n    cmd = f\"onnx2ncnn {onnx} {ncnn_param} {ncnn_bin}\"\n    os.system(cmd)\n    with open(ncnn_param) as f:\n        content = f.read().split(\"\\n\")\n        if len(input_shape) == 1:\n            content[2] += \" 0={}\".format(input_shape[0])\n        else:\n            content[2] += \" 0={} 1={} 2={}\".format(input_shape[2], input_shape[1], input_shape[0])\n        content = \"\\n\".join(content)\n    with open(ncnn_param, \"w\") as f:\n        f.write(content)\nonnx_to_ncnn(input_shape, onnx=onnx_out, ncnn_param=ncnn_out_param, ncnn_bin=ncnn_out_bin)\n```\n\n> 这里需要确定 onnx2ncnn 是可以使用的命令，否则会无法使用这个函数进行模型转换\n\n\n\n### ncnn量化到int8模型\n\n通过maixhub将ncnn模型进行量化到int8模型\n\n在 maixhub 模型转换 将 ncnn 模型转换为 awnn 支持的 int8 模型 （网页在线转换很方便人为操作，另一个方面因为全志要求不开放 awnn 所以暂时只能这样做）\n\n阅读转换说明，可以获得更多详细的转换说明\n![](./../asserts/maixhub.jpg)\n\n这里有几组参数：\n\n- 均值 和 归一化因子： 在 pytorch 中一般是 (输入值 - mean ) / std, awnn对输入的处理是 (输入值 - mean ) \\* norm, 总之，让你训练的时候的输入到第一层网络的值范围和给awnn量化工具经过(输入值 - mean ) \\* norm 计算后的值范围一致既可。 比如 这里打印了实际数据的输入范围是[-2.1008, 2.6400]， 是代码中preprocess 对象处理后得到的，即x = (x - mean) / std ==> (0-0.485)/0.229 = -2.1179, 到awnn就是x = (x - mean_2\\*255) \\* (1 / std \\* 255) 即 mean2 = mean \\* 255, norm = 1/(std \\* 255), 更多可以看这里。\n\n- 所以我们这里可以设置 均值为 0.485 \\* 255 = 123.675， 设置 归一化因子为1/ (0.229 \\* 255) = 0.017125， 另外两个通道同理，但是目前 awnn 只能支持三个通道值一样。。。所以填123.675, 123.675, 123.675，0.017125, 0.017125, 0.017125 即可，因为这里用了pytorch hub的预训练的参数，就这样吧， 如果自己训练，可以好好设置一下图片输入层尺寸（问不是图片怎么办？貌似 awnn 暂时之考虑到了图片。。）\n\n- RGB 格式： 如果训练输入的图片是 RGB 就选 \n- RGB量化图片， 选择一些和输入尺寸相同的图片，可以从测试集中拿一些，不一定要图片非常多，但尽量覆盖全场景（摊手\n\n> 自己写的其它模型转换如果失败，多半是啥算子不支持，需要在 使用说明里面看支持的 算子，比如现在的版本view、 flatten、reshape 都不支持所以写模型要相当小心， 后面的版本会支持 flatten reshape 等 CPU 算子\n\n如果不出意外， 终于得到了量化好的 awnn 能使用的模型， \\*.param 和 \\*.bin\n\n## 使用模型，在v831上推理\n可以使用 python 或者 C 写代码，以下两种方式\n\npython的是需要在终端下运行的，不要使用jupyter，建议使用ssh，这样放文件什么都比较方便\n\n### MaixPy3\npython 请看MaixPy3\n\n不想看文档的话，就是在系统开机使用的基础上， 更新 MaixPy3 就可以了：\n\n    pip install --upgrade maixpy3\n\n然后在终端使用 python 运行脚本（可能需要根据你的文件名参数什么的改一下代码）：\n\nhttps://github.com/sipeed/MaixPy3_scripts/blob/main/basic/v1.0/resnet.py\n\nlabel 在这里： https://github.com/sipeed/MaixPy3/blob/main/ext_modules/_maix_nn/example/classes_label.py\n\nbaars.ttf 在这里：https://github.com/sipeed/MaixPy3_scripts/blob/main/application/base/res/baars.ttf\n```python\nfrom maix import camera, nn, display\nfrom home.res.classes_label import labels\nclass Resnset:\n    m = {\n        \"param\": \"/home/model/resnet18_1000_awnn.param\",\n        \"bin\": \"/home/model/resnet18_1000_awnn.bin\"\n    }\n    options = {\n        \"model_type\":  \"awnn\",\n        \"inputs\": {\n            \"input0\": (224, 224, 3)\n        },\n        \"outputs\": {\n            \"output0\": (1, 1, 1000)\n        },\n        \"first_layer_conv_no_pad\": False,\n        \"mean\": [127.5, 127.5, 127.5],\n        \"norm\": [0.00784313725490196, 0.00784313725490196, 0.00784313725490196],\n    }\n    def __init__(self):\n        from maix import nn\n        self.model = nn.load(self.m, opt=self.options)\n       \n    def __del__(self):\n        del self.model\n\n\n\n\nwhile True:\n    img = camera.capture().resize(224, 224)\n    tmp = img.tobytes()\n    out = resnset.model.forward(tmp, quantize=True)\n    out2 = nn.F.softmax(out)\n    msg = \"{:.2f}: {}\".format(out2.max(), labels[out.argmax()])\n    img.draw_string(0, 0, str(msg), 0.5, (255, 0, 0), 1)\n    display.show(img)\n```\n> 如果运行报错了，请更新maixpy3再运行\n\n\n\n### C语言 SDK， libmaix\n访问这里，按照 https://github.com/sipeed/libmaix 的说明克隆仓库，并编译 https://github.com/sipeed/libmaix/tree/master/examples/nn_resnet\n\n上传编译成功后dist目录下的所有内容到 v831, 然后执行./start_app.sh即可\n\n> 以上内容出至：<https://neucrack.com/p/358>"}, "/soft/maixpy3/zh/recommend_articles.html": {"title": "", "content": "# Maixpy3 精选文章"}, "/soft/maixpy3/zh/origin/video.html": {"title": "Python 教程", "content": "# Python 教程\n\n## 文档相关的\n\n廖雪峰官方网站的《python教程》 https://www.liaoxuefeng.com/\n\nPython3 教程 | 菜鸟教程 https://www.runoob.com/python3/python3-tutorial.html\n\n## 视频相关的\n\n> 如果你没有任何计算机语言基础的话，看一点视频也是极好的，但没必要看完，太多太长。\n\n<iframe src=\"//player.bilibili.com/player.html?aid=14184325&bvid=BV1ex411x7Em&cid=23153678&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n<iframe src=\"//player.bilibili.com/player.html?aid=27789609&bvid=BV1Fs411A7HZ&cid=64841219&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>"}, "/soft/maixpy3/zh/origin/xiaoxu.html": {"title": "喏呐の 【攻城狮成长记】", "content": "# 喏呐の 【攻城狮成长记】\n\n\n### 【攻城狮成长记】毕业设计之sipeed M2dock（v831）开箱\n\n<iframe src=\"//player.bilibili.com/player.html?aid=935420437&bvid=BV1QT4y1274g&cid=479478309&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n### 【攻城狮成长记】sipeed M2dock（v831）从零开始教程之烧录系统\n\n<iframe src=\"//player.bilibili.com/player.html?aid=723105111&bvid=BV1ZS4y1Z7mY&cid=482337635&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>\n\n\n### 【攻城狮成长记】sipeed M2dock（v831）从零开始教程之连接开发板&调用摄像头\n\n<iframe src=\"//player.bilibili.com/player.html?aid=678188418&bvid=BV1Wm4y1U7Kk&cid=483642122&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>"}, "/soft/maixpy3/zh/origin/python.html": {"title": "什么是 Python ？", "content": "---\ntitle: 什么是 Python ？\nkeywords: MaixPy, Python, AIOT, 边缘计算\ndesc: maixpy doc: Python\n---\n\n## 说起 Python 语言\n\n> 只提及一些重点，更详细的就请到一些 Python 教程网站学习吧。\n\n为了让从程序员从~~秃头~~事业中解脱，在开源世界里诞生了名为大蟒蛇（Python）的编程语言。\n\n它带来了什么？\n\n- 提供了完整的软件开发标准库。\n- 适应多种编程方式。\n- 用尽量少的代码完成更多工作。\n- 适应时间短、变化快的需求。\n- 让编程工作看起来更像是在“搭积木”。\n- 开源社区长期贡献了大量的第三方库。\n- 可拓展 C 、 C++ 等其他语言编写的模块。\n- 满足了想偷懒的愿望。\n\n它是一门易用的动态编程语言，可以看作现代入门编程语言的起点，程序员平时或多或少都需要使用 Python 代码帮助完成一些日常、简单、重复的脚本操作。\n\n相比其他编程语言，它看起来会很容易理解和使用，对于非专业人士也可以轻松使用起来，以 “Hello, World” 为例。\n\n- C\n\n```c\n#include <stdio.h>\n\nint main(void) {\n  printf(\"Hello, World!\\n\");\n  return 0;\n}\n```\n\n- C++\n\n```c++\n#include <iostream>\nusing namespace std;\n\nint main() {\n  cout << \"Hello, World!\" << endl;\n  return 0;\n}\n```\n\n- Java\n\n```java\nclass HelloWorld {\n  public static void main(String[] args) {\n    System.out.println(\"Hello, World!\");\n  }\n}\n```\n\n- JavaScript\n\n```javascript\nalert(\"Hello World\")\n```\n\n```javascript\ndocument.write(\"Hello World\")\n```\n\n```javascript\nconsole.log(\"Hello World\")\n```\n\n- Python\n\n```python\nprint(\"Hello, World!\")\n```\n\n不难看出，从人类自然语言的角度来看 Python 语法简单直接，减少了不必要的讯息。\n\n## 它是怎样工作的呢？\n\n在编辑框上编写的 Python 代码，实际上是依次输入到实时运行的解释器程序当中的。\n\n例如下述代码：\n\n```python\ntmp = 1 + 1\nprint(tmp)\n```\n\n运行它后就会输出 2 ，其中 tmp （变量）等于 2 ，如果这时候再运行下述代码。\n\n```python\ntmp = tmp + 1\nprint(tmp)\n```\n\n这时候就会输出 3 ，表示 tmp （变量）等于 3 了。\n\n这是因为每一次运行的 Python 程序都并非是一个全新的开始，它是一直存在于一段程序当中的，只有当解释器程序退出后，才是真的结束程序，所以上一次运行的结果并没有清除，这也是程序不需要编译的原因。\n\n这是与 C / C++ / JAVA 一类编程语言相冲突的地方，我们基于这个差异将 Python 称为动态语言，与此关联的还有 JavaScript 和 Lua 等编程语言。\n\n实时上还有各种各样支持 Python 语言的解释器，虽然写的都是 Python 代码，但并非同一个事物。\n\n我们常用的 Python 编程环境通常指 C 语言实现的 Python 解释器，涵盖 Python2.7 ~ Python3.10 的语法。\n\n而在其他领域来说，有各式各样的 Python 语言的实现，如下：\n\n- MicroPython 使用 Python3.5 语法\n\n- Jython 使用 Java 实现的 Python 语言\n\n- PyPy 通过 JIT 优化的 Python 语言\n\n- IPython 基于 Python 语言的交互接口\n\n也就是说 Python 这个名词，不一定是说 Python 编程语言，还可能是解释器，也可能是程序，这可能会有利于你理解 Python 这个事物背后可能存在的事物。\n\n> 2020 年后不再提及 Python2.7 的任何内容，今后描述的 Python 以 Python3 的语法为准。\n\n## 这一切都这么美好？\n\n并不是。\n\n在这么多编程语言中，Python 对于初学者来说是很上手且简单的，对于一些调用各种库的代码、不在意运行效率，甚至是代码的可维护性也可以忽略的场合，随手一写就可以完成任务。\n\n但代价就是想提升你瞎写程序的性能，你要付出更多的时间去做优化。\n\n> 写出文章不难，写好文章才难。\n\n因为最初不了解 Python 所写出的代码，就像小孩子的涂鸦，到处复制粘贴，以至于写出来的代码东拼西凑整合起来的。\n\n到了这时候，你会发现，一旦你想要改进它是很难做到的，从一开始就不了解它，又谈何改进。\n\n所以这里提及一下，传统的编程语言入门要经历的过程：\n\n- 学习计算机历史\n- 学习计算机语法\n- 学习编程范式\n- 学习使用开发工具\n- 学习使用调试代码\n- 学习程序设计\n\n而使用 Python 语言速成入门培养兴趣和获得成就感的代价就是以后从事这份职业会花费额外的时间补计算机的基础。\n\n> 至少 Python 能让你点火先把火箭飞起来，而不用把火箭制造原理研究透彻了再起飞。\n\n## 学哪个语言更好？\n\n至于哪个更好，这里无法做出评价，建议顺应时代潮流，先解决问题，其他的再说。\n\n- 黑猫白猫抓住佬鼠就是好猫。\n- 实践是检验真理的唯一标准。\n\n最终怎么选择，就取决于你自己了。"}, "/soft/maixpy3/zh/origin/hello_world.html": {"title": "Hello World", "content": "---\ntitle: Hello World\nkeywords: Hello World, MaixPy3, Python, Python3\ndesc: maixpy doc: Hello World\n---\n\n> 本文是给有一点 Python 基础但还想进一步深入的同学，有经验的开发者建议跳过。\n\n## 前言\n\n在写这篇案例系列的时候 [junhuanchen](https://github.com/junhuanchen) 期望能够引导用户如何成为专业的开发者，不是只会调用代码就好，所以在 MaixPy3 开源项目上期望为你带来值得学习和容易上手的开源项目，所以开篇会引导用户学习一些长期有利于编程工作上好的做法和观念，就先从最简单的认知项目开始吧。\n\n第一次接触需要编程的开源硬件项目，要做的第一件事就是先有一个好的开始，例如运行 Hello World 程序，意味着你必须能够先将这个事物跑起来才能够继续后续的内容，它可能是硬件、软件、工具等可编程的载体。\n\n> 但这里先不强调立刻开始运行程序，而是强调如何熟悉一个开源项目。\n\n要先找到它提供的开发文档（例如本文），先纵览全文，站在专业的角度来看，你需要先关注它提供了哪些资源，可以在哪里反馈你的问题，这样就有利于你后续开发过程中出现问题后，该如何迅速得到解决，避免自己之后在学习和开发过程中耽误时间。\n\n![](https://opensource.com/sites/default/files/styles/image-full-size/public/lead-images/OSDC_Resource_Main_Page.png)\n\n有哪些资源是值得关注的？\n\n- 学会搜索！！！！！\n- 找到它的开源项目（如：[github.com/sipeed](https://github.com/sipeed)），获取它所提供的一系列源码。\n- 找到它提供的用户手册、应用案例、数据手册等等一系列开发所需要的文档。\n- 找到它的开发、编译、烧录、量产等一系列配套工具链，为后续软件开发活动中做准备。\n- 找到它的公开交流的环境，如 bbs、github、twitter、facebook、qq、wechat 等社交平台。\n\n现在你可以放心的编程了，但你还需要遵守一些在开源软件上的规则，认知到开源协议的存在，不要随意地做出侵犯他人软件的行为，哪怕没有法律责任的问题。\n\n在开源软件的世界里，鼓励人们自由参与和贡献代码，而不是鼓励如何免费白嫖，自由不等于免费，免费不等于服务，将软件源码公开是为了让用户更好更具有针对性的提交和反馈项目中存在的问题，不是为了更好服务你，请不要以服务自己的产品为中心。\n\n请尊重所有在开源环境里工作的朋友们，尊重他们（或是未来的你）的劳动成果。\n\n最后在开源的世界里，学会技术，学会成长，学会参与项目，学会分享成果！\n\n## Hello World\n\n> 关于本机怎样安装运行 Python 的基础知识，建议从其他网站教程得知。\n\n说了这么多，不如先来运行一段 Python3 代码吧。\n\n```python\nprint(\"hello world\")\n```\n\n> 点击下方的 run 按钮即可运行，如果有条件就在本机运行测试。\n\n<div align=\"center\" >\n    <iframe src=\"https://tool.lu/coderunner/embed/aEj.html\" style=\"width:90%; height:320px;\" frameborder=\"0\" mozallowfullscreen webkitallowfullscreen allowfullscreen></iframe>\n</div>\n\n> 在线 Python 编程 [runoob-python](https://www.runoob.com/try/runcode.php?filename=HelloWorld&type=python3) [google-colab](https://colab.research.google.com) 备用地址。\n\n但这样的代码是不够的，稍微认真一点写。\n\n```python\n# encoding: utf-8\n\ndef unit_test():\n    '''\n    this is unit_test\n    '''\n    print(\"hello world\")\n    raise Exception('unit_test')\n\nif __name__ == \"__main__\":\n    try:\n        unit_test()\n    except Exception as e:\n        import sys, traceback\n        exc_type, exc_value, exc_obj = sys.exc_info()\n        traceback.print_tb(exc_obj)\n        print('have a error:', e)\n\n```\n\n运行结果：\n\n```bash\nPS C:\\Users\\dls\\Documents\\GitHub\\MaixPy3> & C:/Users/dls/anaconda3/python.exe c:/Users/dls/Documents/GitHub/MaixPy3/test.py\nhello world\n  File \"c:/Users/dls/Documents/GitHub/MaixPy3/test.py\", line 12, in <module>\n    unit_test()\n  File \"c:/Users/dls/Documents/GitHub/MaixPy3/test.py\", line 8, in unit_test\n    raise Exception('unit_test')\nhave a error: unit_test\n```\n\n代码瞬间就变得复杂了起来？其实不然，这么写必然有它的用意，那这么写都考虑到了哪些情况呢？\n\n### 注意字符编码和代码缩进格式\n\n初学者经常会出现缩进不对齐的语法问题，代码的语法出现问题过于基础就不详谈，检查代码的小技巧就是 `CTAL + A` 全选代码，按 TAB 键右缩进，再配合 SHIFT + TAB 左缩进来发现哪段代码存在问题。\n\n首行的 `# encoding: utf-8` 是为了避免在代码中存在中文或其他语言的字符编码导致的运行出错的问题。\n\n> 在 python3 的字符串类型中 str 与 bytes 是一对欢喜冤家，例如 print(b'123') 打印出来的是 b'123' ，而实际上就是 '123' 的 bytes 字符串，前缀 b 只是为了和 str 区分，因为用途不同，在不同的接口对数据类型的需求不对，例如传递 str 字符串时候是不允许输入 '\\xFF' (0xFF) 字符的（会在转换过程中丢失），但 bytes 可以存储和表达。\n\n### 给代码加入单元测试和异常捕获\n\n想要写出一套稳定可用的代码，需要围绕接口可重入可测试的设计来编写封装，任何人写的代码都可能存在缺陷，在不能确定是哪里产生的问题之前，要能够恢复现场也要能够定位具体位置，以求问题能够最快得到反馈。\n\n所以在代码功能还没写之前，先把测试和异常的模板写好，再开始写功能，边写边测，确保最终交付的软件代码就算出问题也可以随时被测试（定位）出来。\n\n```python\n\ndef unit_test():\n    '''\n    this is unit_test\n    '''\n    print(\"hello world\")\n\nif __name__ == \"__main__\":\n    unit_test()\n```\n\n这样的代码可以保证任何人在任何时候运行该代码的时候都可以复现当时写下的场合所做的内容，然后 `if __name__ == \"__main__\":` 意味着该代码被其他模块包含的时候，不会在 import 该 Python 模块（可取名成 `hello` ）模块时调用，而是根据自己的代码需要执行相应的单元测试进行测试。\n\n```python\nimport hello\nhello.unit_test() # print(\"hello world\")\n```\n\n接着加入异常机制（try: except Exception as e:）保护代码段，表示该段代码出错的时候，能够不停下代码继续运行，像硬件资源访问的代码常常会发生超时、找不到、无响应的错误状态，这种情况下，一个跑起来的系统程序通常不需要停下来，出错了也可以继续运行下一件事，然后把当时的错误记录下来，通过 print 或 logging 日志模块记录下来，拿着错误结果（日志）反馈给开发者，这样开发者就可以分析、定位和解决问题，这其中也包括你自己。\n\n```python\ntry:\n    raise Exception('unit_test')\nexcept Exception as e:\n    import sys, traceback\n    exc_type, exc_value, exc_obj = sys.exc_info()\n    traceback.print_tb(exc_obj)\n    print('have a error:', e)\n```\n\n单元测试是每个程序都尽可能保持的基本原则，虽然人会偷懒，但最起码的代码格式还是要有的。\n\n> 注：traceback 可以抓取最后一次运行出现的错误而不停止运行，但该模块不存在 MicroPython(MaixPy) 中，它有类似的替代方法。\n\n## 封装代码接口成通用模块的方法\n\n世上本没有路，走的人多了，也便成了路。\n\n这里说的路实际上就是一种封装和参考，它意味着你写的代码成为一种事实上的通用操作。\n\n在 Python 上有很多封装参考，主要是为了形成抽象的函数模块。\n\n所以出现了一些经典的编程思想，如面向过程、面向对象、面向切面、面向函数等编程方法，哪一种更好就不比较和讨论了。\n\n这里就简单叙述一下这些编程方法的逐渐发展与变化的过程，可以如何做出选择。\n\n### 面向过程\n\n用面向过程的思维写代码，强调的是这份代码做的这件事需要分几步完成，例如最开始写代码都是这样的。\n\n```python\none = 1\ntwo = 2\nthree = one + two\nprint(three)\n```\n\n这是用人类直觉的过程来写代码，后来意识到可以这样写成通用功能，这是最初的代码封装成某个函数。\n\n```python\ndef sum(num1, num2):\n    return num1 + num2\none, two = 1, 2\nprint(sum(one, two)) # 1 + 2 = 3\n```\n\n于是你多写了个类似的乘法操作。\n\n```python\ndef mul(num1, num2):\n    return num1 * num2\none, two = 1, 2\nprint(mul(one, two)) # 1 * 2 = 2\n```\n\n这时的代码是按照每一个代码操作流程来描述功能的。\n\n### 面向对象\n\n面向对象是相对于面向过程来讲的，把相关的数据和方法组织为一个整体来看待，从更高的层次来进行系统建模，更贴近事物的自然运行模式，一切事物皆对象，通过面向对象的方式，将现实世界的事物抽象成对象，现实世界中的关系抽象成类、[继承](https://baike.baidu.com/item/继承)，帮助人们实现对现实世界的[抽象](https://baike.baidu.com/item/抽象)与数字建模。\n\n在看了一些面向对象的描述后，你会意识到上节面向过程的函数操作可能很通用，应该不只适用于一种变量类型，所以可以通过面向对象（class）的方法来封装它，于是可以试着这样写。\n\n```python\nclass object:\n    def sum(self, a, b):\n        return a + b\n    def mul(self, a, b):\n        return a * b\nobj = object()\nprint(obj.sum(1, 2)) # 1 + 2 = 3\nprint(obj.mul(1, 2)) # 1 * 2 = 2\n```\n\n这样会意识到似乎还不只是数字能用，感觉字符串也能用。\n\n```python\nclass object:\n    def sum(self, a, b):\n        return a + b\n    def mul(self, a, b):\n        return a * b\nobj = object()\nprint(obj.sum('1', '2')) # 1 + 2 = 3\nprint(obj.mul('1', '2')) # 1 * 2 = 2\n```\n\n但这么写会出问题的，字符串相加的时候可以，但相乘的时候会报错误，因为是字符串这个类型的变量是不能相乘的。\n\n```bash\n12\nTraceback (most recent call last):\n  File \"c:/Users/dls/Documents/GitHub/MaixPy3/test.py\", line 8, in <module>\n    print(obj.mul('1', '2')) # 1 * 2 = 2\n  File \"c:/Users/dls/Documents/GitHub/MaixPy3/test.py\", line 5, in mul\n    return a * b\nTypeError: can't multiply sequence by non-int of type 'str'\n```\n\n显然这样写代码就不合理了，但这时运用的面向对象的思想是可行的，只是实现的方式不够好而已，所以重新设计类结构，例如可以写成下面的类结构。\n\n```python\nclass obj:\n    def __init__(self, value):\n        self.value = value\n    def __add__(self, obj):\n        return self.value + obj\n    def __mul__(self, obj):\n        return self.value * obj\n\nprint(obj(1) + 2) # 3\nprint(obj(1) * 2) # 2\n```\n\n其中 `__add__` 和 `__mul__` 是可重载运算符函数，意味着这个类实例化的对象在做 + 和 * 运算操作的时候，会调用类（class）重载函数，接着可以提升可以运算的对象类型，进一步继承对象拓展功能（`class number(obj):`）和访问超类的函数（`super().__add__(obj)`），其中 `if type(obj) is __class__:` 用于判断传入的参数对象是否可以进一步处理。\n\n```python\n\nclass number(obj):\n    def __add__(self, obj):\n        if type(obj) is __class__:\n            return self.value + obj.value\n        return super().__add__(obj)\n    def __mul__(self, obj):\n        if type(obj) is __class__:\n            return self.value * obj.value\n        return super().__mul__(obj)\n\nprint(number(1) + 2)\nprint(number(1) * 2)\nprint(number(1) + number(2))\nprint(number(1) * number(2))\n\n```\n\n这时候会发现可以进一步改写成字符串数值运算。\n\n```python\n\nclass str_number(obj):\n    def __init__(self, value):\n        self.value = int(value)\n    def __add__(self, obj):\n        if type(obj) is __class__:\n            return str(self.value + int(obj.value))\n        return str(super().__add__(int(obj)))\n    def __mul__(self, obj):\n        if type(obj) is __class__:\n            return str(self.value * int(obj.value))\n        return str(super().__mul__(int(obj)))\n\nprint(str_number('1') + '2')\nprint(str_number('1') * '2')\nprint(str_number('1') + str_number('2'))\nprint(str_number('1') * str_number('2'))\n```\n\n现在就可以解决了最初的同类操作适用不同的数据类型，把最初的一段操作通用到数值和字符串了，可以受此启发，它不仅仅只是加法或乘法，还有可能是其他操作，关于面向对象的内容就说到这里，感兴趣的可以查阅相关资料深入学习，本节只讲述可以怎样使用面向对象的思维写代码，而不是单纯把 Class 当 Struct 来使用。\n\n> 像最初写的代码，如果不通过对象继承分解函数，最终将会形成一个巨大的 Struct 结构。\n\n### 面向切面\n\n现在到了选择更多编程思维方式了，关于面向切面编程方法的场景是这样提出的，有一些函数，它在产品调试的时候会需要，但在产品上线的时候是不需要的，那这样的函数应该如何实现比较好？接下来不妨直接看代码，以日志输出的代码为例来说说面向切面，介绍一下如何使用装饰器进行编程的方法。\n\n```python\n\ndef log(param):\n    # simple\n    if callable(param):\n        def wrapper(*args, **kw):\n            print('%s function()' % (param.__name__,))\n            param(*args, **kw)\n        return wrapper\n    # complex\n    def decorator(func):\n        import functools\n        @functools.wraps(func)\n        def wrapper(*args, **kw):\n            print('%s %s():' % (param, func.__name__))\n            return func(*args, **kw)\n        return wrapper\n    return decorator\n\ndef now():\n    print(\"2019\")\n\n@log\ndef now1():\n    print(\"2020\")\n\n@log(\"Is this year?\")\ndef now2():\n    print(\"2021\")\n\nnow()\nnow1()\nnow2()\n\n```\n\n运行结果：\n\n```bash\nPS C:\\Users\\dls\\Documents\\GitHub\\MaixPy3> & C:/Users/dls/anaconda3/python.exe c:/Users/dls/Documents/GitHub/MaixPy3/test.py\n2019\nnow1 function()\n2020\nIs this year? now2():\n2021\nPS C:\\Users\\dls\\Documents\\GitHub\\MaixPy3>\n```\n\n对于产品上线时不需要的函数，注释掉就可以了，更进一步还可以重新设计某些函数满足于某些条件后再运行。\n\n- 在执行某段操作前，先打印当前的系统状态记录下来，确保出错时可以追溯到出错的地方。\n- 在发送网络数据前，要先检查网络通路是否存在，网卡是否还在工作。\n- 在运行操作前，先检查内存够不够，是否需要释放内存再继续操作。\n\n可以看到，当想要不改变某些现成库代码的条件下拓展系统的功能，就不免需要面向切面的设计方法。\n\n>  注意！面向切面提出的是编程思想，实现的方法不一定是装饰函数，可以是回调函数，也可以是重载函数。\n\n### 面向函数\n\n关于面向函数的场景是由于有些问题是被数学公式提出的，所以对于一些数学问题，并不一定要按过程化的思维来写，如实现阶乘函数（factorial），它的功能就是返回一个数的阶乘，即`1*2*3*...*`该数。\n\n```python\ndef fact(n):\n    if n == 3:\n        return 3*2*1\n    if n == 2:\n        return 2*1\n    if n == 1:\n        return 1\nprint(fact(3))\nprint(fact(2))\nprint(fact(1))\n```\n\n不难看出用最初的面向过程来写是写不下去的，不可能去定义所有的可能性，所以要找出规律，可以通过递归的方式实现。\n\n```python\ndef fact(n):\n    return 1 if n == 1 else n * fact(n - 1)\nprint(fact(1))\nprint(fact(5))\nprint(fact(100))\n```\n\n这样功能就完整了，简单来说函数式编程是让编程思维追求程序中存在的公式。\n\n## 试试快速迭代的敏捷开发？\n\n现代开源软件在经历了产测、内测、公测等环节后，直至更新到用户的手里，从前到后的过程通常在一周内就可以完成，所以在设计程序接口的时候，可以接受当下接口设计的不完美，等到未来有一个更好的替代功能接口的时候，就可以将其迭代替换下来，这意味着可以不用设计好整体的软件系统再开始工作，而是边做边改进，这套理论适用于初期需要频繁更新业务逻辑的开源软件。\n\n这里简单引用一段小故事来说明这个现象。\n\n快速迭代，不是说一定要产品做好了，才能上线，半成品也能上线。\n\n在没有上线之前，你怎么知道哪好那不好。所以半成品也是可以出门的，一定不要吝惜在家，丑媳妇才需要尽早见公婆。尽早的让用户去评判你的想法，你的设计是否可以赢得用户的喜爱。快速发出，紧盯用户反馈。百度完成了第一版的搜索引擎，也是让用户去做的选择。用百度 CEO 李彦宏（Robin）的话来说“你怎么知道如何把这个产品设计成最好的呢？只有让用户尽快去用它。既然大家对这版产品有信心，在基本的产品功能上我们有竞争优势，就应该抓住时机尽快将产品推向市场，真正完善它的人将是用户。他们会告诉你喜欢哪里不喜欢哪里，知道了他们的想法，我们就迅速改，改了一百次之后，肯定就是一个非常好的产品了。”\n\n## 准备一个好的开始\n\n看到这里的你，可能会困惑，可能会看不懂，会觉得很复杂，这是认知上的偏差，实际上本文所讲述的都是编程思想上的基础，如果想专业起来，不认真是不行的。\n\n不妨自己动手试试看吧。"}, "/soft/maixpy3/zh/origin/helper.html": {"title": "", "content": "## 如何正确反馈问题并得到解决的方法\n\n正如标题所述，新来开源社区的同学们不知道如何正确提问和获取问题的解，所以这里特别强调一下，使用开源硬件产品如何得到问题的解决方案。\n\n要学会站在开发者角度来解决问题，把自己当作开发者来汇报问题。\n\n开发者在面对问题的时候，需要的信息主要为如下:\n\n- 什么条件下，什么场景下，触发了什么问题\n\n- 你做了什么，遇到了什么，你想要做什么？\n\n- 要有图，有日志，有前因后果，整理成一个帖子发到社区里，然后@管理员解决。\n\n嫌字少看这个 https://bbs.sipeed.com/thread/183\n\n开源社区是大家一起构建的，而不是由少数几个人完成的任务，所以一定要怀有感恩之心，尤其是国内这种氛围下，一个好的可以技术交流和提问的社区少之又少，珍惜这些愿意浪费自己生命，而不去搞业绩赚钱的开发者吧。"}, "/soft/maixpy3/zh/origin/loop_python.html": {"title": "", "content": "> 本文是给有一点 Python 基础但还想进一步深入的同学，有经验的开发者建议跳过。\n\n## 前言\n\n上文讲述了如何认识开源项目和一些编程方法的介绍，这节主要来说说 Python 代码怎么写的一些演化过程和可以如何写的参考，在现在的 Sipeed 开源社区/社群里，有太多的新手不知道如何写好 Python 代码，尤其是嵌入式中的 Python 代码也是有不少的技巧和观念需要注意的，至少让这篇文章从循环开始说起。\n\n> 可以把本文当作一篇经验之谈，主要是探讨代码稳定性与性能，以及一些计算机知识的拓展。\n\n## 学会循环执行代码\n\n当写下第一行代码的时候，在电脑上的 Python 解释器运行效果是这样的。\n\n```python\nprint('Hello World')\n```\n\n![](./../usage/asserts/win_python.png)\n\n而嵌入式设备上的 python 是通过串口（serial）传出来。\n\n![](./../usage/asserts/maix_python.png)\n\n当写完了第一行 `Hello World` 的 `print` 函数，总不能一直复制、粘贴代码吧。\n\n```python\n\nprint('Hello World')\nprint('Hello World')\nprint('Hello World')\nprint('Hello World')\nprint('Hello World')\n\n```\n\n也不是只运行验证功能就好了吧，所以加上了循环（`while`）执行代码。\n\n```python\n\nwhile True:\n    print('Hello World')\n\n```\n\n如果想要稳定一些，最好还要为它加入异常机制，保证它不会因为 Python 代码的运行出错而停下来。\n\n```python\n\nwhile True:\n    try:\n        print('Hello World')\n    except Exception as e:\n        pass\n\n```\n\n## 循环代码中为什么需要异常机制\n\n是不是以为 print 这样的代码就不会出错？其实不然，其实程序越接近底层硬件越容易出错。\n\n从功能上说上文两者之间并没有什么区别，都是输出，但你会发现串口输出可能会出现下面几类情况。\n\n- 串口芯片损坏或线路断路、串口到芯片的通路损坏导致的串口没有数据输出。\n- 串口线路数据不稳定、串口协议（波特率、停止位）等配置错误导致的数据乱码。\n\n这就意味着你会遇到很多来自硬件上的问题，所以要注意到这些意外。\n\n那在软件代码上会发生什么有关于硬件上的意外呢？\n\n通常有无响应、无应答、未连接等不成功的错误，它们是来自 IO 的错误。\n\n- 当网络连接失败后需要超时重连，传输数据通道闲置时需要定时检查心跳数据包。\n- 当配置文件写入后通常会读出来确认真的写入了，也是为了防止出错，可能是存储介质出错，也可能是逻辑出错。\n- 当用户向输入框填了错误数据，不用写怎么判断和处理，不合法的数据抛出异常就行。\n\n因为这些现象太多不确定的可能性，才会需要对代码进行异常捕获机制，来决定是否放过这次意外，可能会在下一次的循环就恢复了，这样就能够基本保证了 Python 代码循环的稳定性了。\n\n## 来自外部/硬件上异常机制\n\n这样就足够了吗？\n\n事实上有些错误不源于 Python 代码，可能来自于底层 C 代码，或其他程序，上文说的异常机制只能捕获 Python 异常，不能捕获来自其他语言的异常。\n\n所以实际情况比想象的要更严峻一些，当你无法解决不稳定的系统带来其他异常的时候，通常在服务器程序上设计会在外部附加一个守护程序（如调试程序）来定时检查自己的程序，例如可以检查下面的一些情况。\n\n- 检查当前的系统是否能联网\n- 检查数据库的通路是否正常\n- 检查指定的程序是否在运行\n\n总得来说，你要为你的程序做一个监控程序，可以是守护程序，也可以是看门狗。\n\n> 具体怎么实现，可以了解一些守护进程的实现。\n\n## 看门狗（watchdog）是什么？\n\n如上述的守护程序是靠一个软件去监控另一个软件的状态，而看门狗的工作行为描述如下：\n\n假设有一条需要定时吃饭（更新）的狗、如果不定时喂它（feed）就会饿着肚子叫。那么问题来了，什么时候狗会叫呢？因为人（芯片）死了，没人喂它了。（这也许是一个冷笑话）\n\n看门狗是要求芯片程序负责定时喂狗，如果没有喂狗就狗就饿死了，作为报复狗会把芯片重启。让它可以继续喂狗。\n\n任何硬件产品都有可能出现意外和错误，看门狗相当于芯片上的最后一层保障机制，通常它可能会发生在函数栈的指针参数执行出错，导致后续的喂狗操作再也执行不到了，具体怎么实现，可以查阅不同芯片提供的程序接口或寄存器。\n\n## 优化！优化！！优化！！！\n\n当你的程序已经跑起来以后，你会发现程序并没有达到令人满意的效果，在性能、内存上都没有经过任何考虑，只是实现了最起码的功能而已，那么完成了功能以后，可以如何继续呢？\n\n当然，在优化程序之前得先建立计算代码执行时间的观念，建立起最简单的性能指标，如在代码加上时间计算。\n\n```python\ndef func():\n    i = 20**20000\n\nimport time\nlast = time.time()\nfunc()\ntmp = time.time() - last\nprint(tmp)\n```\n\n在 CPU I5-7300HQ 的计算机上见到每一次的循环的时间间隔约为 0.000997781753540039 不足 1ms 即可完成。\n\n```bash\nPS C:\\Users\\dls\\Documents\\GitHub\\MaixPy3> & C:/Users/dls/anaconda3/python.exe c:/Users/dls/Documents/GitHub/MaixPy3/test.py\n0.000997781753540039\n```\n\n注意不要写到 `print(time.time() - last)` ，因为重定向后的 print 是相当耗时的，尤其是当内容输出到串口终端或网页前端的时候，如下使用 M2dock 设备来演示一下串口输出。\n\n> 重定向指改变内容要输出的地方\n\n```bash\nroot@sipeed:/# python3\nPython 3.8.5 (default, Jan 17 2021, 06:07:56)\n[GCC 6.4.1] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> def func():\n...     i = 20**20000\n...\n>>> import time\n>>> last = time.time()\n>>> func()\n>>> tmp = time.time() - last\n>>> print(tmp)\n0.09001994132995605\n>>>\n>>>\n>>> def func():\n...     i = 20**20000\n...\n>>> import time\n>>> last = time.time()\n>>> func()\n>>> print(time.time() - last)\n1.480057954788208\n>>>\n```\n\n可以看到相差可能有 1 秒，而事实上只需要 90ms 就可以完成 func 函数的运算，这就产生了误差导致不准确，若是使用 jupyter 输出就会看到 0.026456356048583984 需要 26ms 可以较为准确的推算出它的真实运算结果。\n\n![](./asserts/time_python.png)\n\n为什么会造成这种差异的原因是因为串口依次输入命令输出结果需要时间，所以依次输入语句执行自然会存在误差，而 jupyter 是通过网络 socket 连接传输显示到屏幕上，所以耗时误差只会发生在运算重定向输出结果的时候，最终结果会较为贴近真实运算结果，通过保存下述代码文件来运行即可得知真实情况下约为 26 ~ 28ms 完成。\n\n```bash\nroot@sipeed:/# cat test.py\ndef func():\n    i = 20**20000\n\nimport time\nlast = time.time()\nfunc()\ntmp = time.time() - last\nprint(tmp)\n\nroot@sipeed:/# python test.py\n0.028677940368652344\nroot@sipeed:/#\n```\n\n所以从现在建立起最基础的计算耗时，并且认知到在计算机的世界里，毫秒其实已经很慢了，然后可以类比一种感受，人眼感到流畅的画面至少是 24 fps ，而平时的视频在 15 fps 的流动是不会让你感受到卡顿的，如果低于这个阈值，则会出现卡顿造成心理上的不愉快，这个 15 fps 意味着每秒 15 张存在变化的画面，如果用程序来类比就是 1000 ms / 15 = 66 ms ，也就是每个流程操作最好是在 66ms 内完成，这样用户才不会觉得卡顿，同理，当 1000ms / 24 = 41ms 就可以确保用户体验这个软件的时候会觉得流畅。\n\n有了基本的性能指标，就有了优化的对比参考，如果是一些测试框架会帮助你自动完成每个函数的耗时统计，但在没有现成框架工具的时候就要稍微辛苦一下自己了。\n\n### 讲一些经典案例\n\n在日常中存在最多操作就是循环和判断，显然好的优化就是减少不必要的指令操作，可以通过改变代码的执行结构来进行优化，下面就来具体分析吧。\n\n如某个向网络上发送数据的操作，最初可能会按人类直觉写出以下的代码，这是一种不用思考也可以很容易写出来的同步阻塞式的结构，每一条语句都是满足了某些条件再继续执行。\n\n```python\n\ndef xxxx_func():\n    import random\n    return random.randint(0, 1)\n\nwhile True:\n    is_idle = True\n    if is_idle is True:\n        print('try start')\n        is_ready = xxxx_func()\n        if is_ready is True:\n            print('try ready')\n            is_connected = xxxx_func()\n            if is_connected is True:\n                print('try connect')\n                is_send = xxxx_func()\n                if is_send is True:\n                    print('try send')\n                    is_reply = xxxx_func()\n                    if is_reply is True:\n                        print('wait reply')\n                        is_exit = xxxx_func()\n                        if is_exit is True:\n                            print('operate successfully')\n```\n\n而优化只需要加状态变量改写成状态机结构（fsm）就可以了，所有代码都可以平行化执行，并根据执行频率的重要程度（权重）调整各项判断的顺序，尤其是移除一些不必要的判断。\n\n```python\ndef xxxx_func():\n    return 1\n\n# state value\nis_idle, is_ready, is_connected, is_send, is_reply, is_exit = 0, 1, 2, 3, 4, 5\nstate = is_idle\n\nwhile state != is_exit:\n\n    if state is is_reply:\n        print('wait reply')\n        state = is_exit if xxxx_func() else is_send\n        continue\n\n    if state is is_send:\n        print('try send')\n        state = is_reply if xxxx_func() else is_connected\n        continue\n\n    if state is is_connected:\n        print('try connect')\n        state = is_send if xxxx_func() else is_ready\n        continue\n\n    if state is is_ready:\n        print('try ready')\n        state = is_connected if xxxx_func() else is_idle\n        continue\n\n    if state is is_idle:\n        print('try start')\n        state = is_ready\n        continue\n```\n\n这样改造执行结构后，每个代码之间的上下文关系并不强烈，是否执行某个语句取决于系统对于某个状态是否满足，如果状态失败也不会倒退回最初的判断，也就不需要每次都对各个状态做检查，检查只会发生在出错的时候状态跌落（state - 1）。\n\n缺点就是需要消耗一些记录状态的变量(●'◡'●)，不过代码的拓展性和维护性就上来了。\n\n> 可以根据实际情况增加状态的判断或是减少状态的转移（调整状态转移范围），如直接设置 state = is_ready，假设某些操作是已知的就可以跳过，可以添加 continue 跳过一些不可能发生的状态。\n\n### 还有吗？\n\n进一步优化还可以干掉 if 直接将状态与函数联合索引执行，简化代码如下。\n\n```python\n\nis_a, is_b, is_c = 0, 1, 2\n\nstate = is_a\n\ndef try_b():\n    global state\n    state = is_c\n\ndef try_a():\n    global state\n    state = is_b\n\nfunc = [try_a, try_b]\n\nwhile state != is_c:\n    func[state]()\n    # print(state)\n\n```\n\n基于上述结构给出一个示例代码参考。\n\n```python\n\nclass xxxx_fsm:\n\n    is_start, is_ready, is_connected, is_send, is_reply, is_exit = 0, 1, 2, 3, 4, 5\n\n    def xxxx_func(self):\n        return 1\n\n    def __init__(self):\n        self.func = [self.try_start, self.try_ready, self.try_connect, self.try_send, self.wait_reply]\n        self.state = __class__.is_start # state value\n\n    def wait_reply(self):\n        self.state = __class__.is_exit if self.xxxx_func() else __class__.is_send\n\n    def try_send(self):\n        self.state = __class__.is_reply if self.xxxx_func() else __class__.is_connected\n\n    def try_connect(self):\n        self.state = __class__.is_send if self.xxxx_func() else __class__.is_ready\n\n    def try_ready(self):\n        self.state = __class__.is_connected if self.xxxx_func() else __class__.is_start\n\n    def try_start(self):\n        self.state = __class__.is_ready\n\n    def event(self):\n        self.func[self.state]()\n\n    def check(self):\n        return self.state != __class__.is_exit\n\ntmp = xxxx_fsm()\n\nwhile tmp.check():\n\n    tmp.event()\n\n    # print(tmp.state)\n```\n\n其实上述的有限状态机并非万能的代码结构，只是刚好很适合拆分已知的复杂业务逻辑的同步阻塞代码，那么还有什么结构可以选择吗？有的，此前说的都是同步阻塞的代码，所以还有所谓的异步执行的代码。\n\n### 说说异步的执行方式\n\n在这之前的代码都是按每个循环的步骤有序执行完成功能（同步执行），但现实生活中的操作一定是按顺序发生的吗？其实不然，其实很多操作可能会在任意时刻发生。\n\n想象一个程序，它会响应来自网络的数据，也会响应来自人类的按键输入操作，这两个操作如果按上述的结构来写，可能会是下面这样。\n\n```python\nimport time, random\n\ndef check_http():\n    time.sleep(random.randint(0, 3))\n    return random.randint(0, 1)\n\ndef http_recv():\n    while True:\n        if check_http():\n            print('http_recv')\n            break\n\ndef check_key():\n    time.sleep(random.randint(0, 2))\n    return random.randint(0, 1)\n\ndef key_press():\n    while True:\n        if check_key():\n            print('key_press')\n            break\n\nwhile True:\n    http_recv()\n    key_press()\n```\n\n可以看到 http_recv 和 key_press 两个事件的检查会各自占据一段不知何时会触发或结束的检测的时间，程序只能循环等待这些事件会不会发生（或称轮询）。\n\n这是个看起来可以工作但浪费了很多时间的程序，现实里接收到许多用户的网络连接，而服务程序不可能只服务某个用户的连接。\n\n所以改写异步的第一步就是简化代码中不必要的循环，将每个需要循环等待的部分拆分成非阻塞的函数。\n\n> 非阻塞意味着某个操作会在有限的时间内结束，期望某个函数能够在较短的时间（10ms）内退出，退出不代表功能结束，只是需要把这个时间让出去给其他函数调用。\n\n```python\nimport time, random\n\nhttp_state, key_state = 0, 0\n\ndef http_recv():\n    global http_state\n    if http_state:\n        print('http_recv')\n\ndef key_press():\n    global key_state\n    if key_state:\n        print('key_press')\n\ndef check_state():\n    global key_state, http_state\n    time.sleep(random.randint(0, 1))\n    key_state, http_state = random.randint(0, 2), random.randint(0, 2)\n\nwhile True:\n    check_state()\n    http_recv()\n    key_press()\n```\n\n从逻辑上移除了等待，再通过统一的（check_state）检查每个操作的状态再决定是否唤醒该操作，变成只有满足某个状态才执行该操作，将此前的多个循环拆分出来。\n\n但你会发现这样写还是有问题，这样岂不是意味着所有代码都要按这个接口来写了吗？那么多的代码，不可能全都可以拆分吧。\n\n所以是时候加入异步 IO （asyncio）的 async 和 await 语法了！先来点简单的。\n\n```python\nimport asyncio\n\nasync def test_task(name, tm):\n    await asyncio.sleep(tm)\n    print('%s over...' % name)\n\nasync def main(name):\n    import time\n    last = time.time()\n    await asyncio.gather(\n        test_task(name + 'A', 0.1),\n        test_task(name + 'B', 0.2),\n        test_task(name + 'C', 0.3),\n    )\n    print(name, time.time() - last)\n\nloop = asyncio.get_event_loop()\ntasks = [ main('l: '), main('r: ') ]\nloop.run_until_complete(asyncio.wait(tasks))\n\n```\n\n运行结果如下：\n\n```bash\nPS python.exe test.py\nr: A over...\nl: A over...\nr: B over...\nl: B over...\nr: C over...\nl: C over...\nr:  0.3076450824737549\nl:  0.3076450824737549\n```\n\n可以看到代码总共耗时为 0.3s 完成，但运行了两次不同所属的 main 函数以及各自调用三次不同延时的 test_task 任务，而 await asyncio.sleep(tm) 延时期间实际上是被 asyncio 拿去运行其他的 async 函数了，基于此结构可以这样改写。\n\n```python\n\nimport asyncio, random\n\nasync def key_press():\n    await asyncio.sleep(0.1)\n    key_state = random.randint(0, 1)\n    if key_state:\n        return 'have key_press'\n\nasync def http_recv():\n    await asyncio.sleep(0.2)\n    http_state = random.randint(0, 1)\n    if http_state:\n        return 'have http_recv'\n\nasync def run():\n    import time\n    while True:\n        task_list = [http_recv(), key_press()]\n        done, pending = await asyncio.wait(task_list, timeout=random.randint(0, 1) / 2)\n        print(time.time(), [done_task.result() for done_task in done])\n        await asyncio.sleep(0.2) # remove to run too fast.\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(run())\n```\n\n执行效果如下。\n\n```bash\n1615141673.93252 [None, None]\n1615141674.134 [None, 'have http_recv']\n1615141674.3350334 [None, None]\n1615141674.7361133 ['have key_press', 'have http_recv']\n1615141674.9365196 [None, None]\n1615141675.1399093 ['have http_recv', None]\n```\n\n可以看到在运行 run 函数延时 `await asyncio.sleep(0.2)` 后就会循环加载异步事件函数执行，配置 asyncio.wait 函数的参数 `timeout` 会导致 `random.randint(0, 1) / 2` 秒后就会自行超时退出，退出的时候会收集当前的 `key_press` 和 `http_recv` 函数的运行结果，如果期间异步函数成功返回值（`return 'have http_recv'`），最终结果就会输出 `1615138982.9762554 ['have http_recv']` 表示有事件触发并执行了，否则为 None ，这将在下一次循环重新提交异步函数列表 `[http_recv(), key_press()]` 执行。\n\n> 注意 Python 3.7 以前的版本使用 loop = asyncio.get_event_loop() & loop.run_forever() & loop.run_until_complete() ，而后采用 asyncio.run() 了。每个编程语言都有自己的异步框架和语法特色，请根据实际情况选用。\n\n## 考虑一下封装模块给其他人使用吧？\n\n随着代码越写越多，项目越来越大，大到可能不是你一个人写的时候，你就要开始注意工程项目的管理了，这与个人写代码时的优化略微不同，主要强调的是不同代码之间的接口分离，尽量不干涉到他人的实现和提交，所以在写代码的时候，不妨为自己准备一个独立模块，以方便与其他人写的分离或是导入其他（import）模块。\n\n若是在某个目录（`mod`）下存在一个 `__init__.py` 的话，它就会变成 Python 模块，且名为 `mod` ，其中 `__init__.py` 的内容可能如下：\n\n```python\ndef code():\n    print('this is code')\n```\n\n而且在该目录下还存在一个额外的代码文件（如 `tmp.py` ）内容如下：\n\n```python\ninfo = 'nihao'\n```\n\n对于开发者或用户来说，在 `import mod` 的时候会调用 `mod` 目录下的 `__init__.py` ，而 `from mod import tmp` 会调用 `mod` 目录下的 `tmp.py` 代码。\n\n```python\n>>> import mod\n>>> mod\n<module 'mod' from 'C:\\\\mod\\\\__init__.py'>\n>>> mod.code()\nthis is code\n>>> from mod import tmp\n>>> tmp\n<module 'mod.tmp' from 'C:\\\\mod\\\\tmp.py'>\n>>> tmp.info\n'nihao'\n>>>\n```\n\n这样你写的代码就可以作为一个模块被其他人所使用了，注意 import 只会加载并执行一次，想要再次加载请使用 reload 函数。\n\n## 如何进行内存上的分析？\n\n这里就推荐 [memory_profiler](https://github.com/pythonprofilers/memory_profiler) 开源工具，快去体验吧。\n\n使用方法：`python -m memory_profiler example.py`\n\n```python\nfrom memory_profiler import profile\n\n@profile\ndef my_func():\n    a = [1] * (10 ** 6)\n    b = [2] * (2 * 10 ** 7)\n    del b\n    return a\n```\n\n运行结果：\n\n```bash\nLine #    Mem usage    Increment  Occurences   Line Contents\n============================================================\n     3   38.816 MiB   38.816 MiB           1   @profile\n     4                                         def my_func():\n     5   46.492 MiB    7.676 MiB           1       a = [1] * (10 ** 6)\n     6  199.117 MiB  152.625 MiB           1       b = [2] * (2 * 10 ** 7)\n     7   46.629 MiB -152.488 MiB           1       del b\n     8   46.629 MiB    0.000 MiB           1       return a\n```\n\n## 总结\n\n其实所谓的优化就是在程序上不断追求无延迟、零等待、鲁棒性、艺术品、最佳实践等指标。\n\n当完成了自己的某个作品，多少都会希望自己的作品是最好的，又或是越做越好的。熬夜辛苦写下的程序，用尽自己的脑力和各种逻辑思维来不断打磨它，尽可能的把它变成一件艺术品，然后为之自豪和兴奋，恨不得向它人炫耀自己的成果。\n\n但愿你不会在往后的一堆垃圾代码中失去了最初喜欢上编程的心情。\n\n## 附录：多线程？多进程？该不该使用？\n\n事实上多线程和多进程都是建立在操作系统之上的概念，由于操作系统中存在不同优先级的中断函数，其中优先级较高的函数栈会打断优先级低的函数栈执行，并且优先级高的操作结束就会轮到优先级低的操作，优先级高的操作通常都会被设计成尽快结束退出（哪怕是失败），不然用户程序就会像老爷爷一样缓慢运行了。\n\n多线程是由拥有内存空间进程（某个程序）创造出来的，多线程函数“看上去”是彼此并行的，并且共用所属进程的内存数据，而不同进程之间申请的内存空间并不互通，所以当你想要实现守护进程的程序，是需要对其他进程进行通信的（如卸载程序时会检查并发送信号停止要卸载的程序），并非是在代码中修改一个变量那么简单。\n\n事实上我并不鼓励用户在 Python 上使用多线程，因为全局解释器锁（GIL）的存在，CPython 解释器中执行的每一个 Python 线程，都会先锁住自己，以阻止别的线程执行。而 CPython 解释器会去轮询检查线程 GIL 的锁住情况，每隔一段时间，Python 解释器就会强制当前线程去释放 GIL，这样别的线程才能有执行的机会。总得来说 CPython 的实现决定了使用多线程并不会带来太大的性能提升，反而会带来更多线程安全的问题，尤其是需要线程资源同步了。\n\n> 警告：请不要在每个线程中都写上不会退出的死循环，多线程的并不是拿来偷懒的工具。"}, "/soft/maixpy3/zh/origin/difference.html": {"title": "MaixPy 与 MaixPy3 的区别", "content": "---\ntitle: MaixPy 与 MaixPy3 的区别\nkeywords: MaixPy, MaixPy3, Python, Python3, MicroPython\ndesc: maixpy doc: MaixPy3\n---\n\n## 区别是？\n\n因为使用 MaixPy 的同学可能有两类人群，一类是从 MicroPython 一路使用过来的，另一类是从 Python3 过来的，所以针对两边的差异，分别做一下说明。\n\n可以这样理解，它们都是专门为 AIoT 提供的 Python 开发环境，提供了各种各样的模块。\n\n- MaixPy 指的是基于 MicroPython 的环境制作的。\n\n- MaixPy3 指的是基于 Linux Python3 的环境制作的。\n\n> 前者是基于 MCU 无系统的，后者是基于 Linux 系统。\n\n除了基本的 Python3 语法一致，在提供的模块方面的存在着不小的差异。\n\n### Python3 与 MicroPython 的区别\n\n大多数时候，Python 的发展以 Python3 为主，以下列出一些与 Python3 的差异化信息。\n\n- MicroPython 和 Python3 在 Python 语法上保持高度的一致性，常用的标准语法命令都已经支持。\n\n- MicroPython 虽然只实现了 Python3 的标准库和容器库的一些部分，常见容器库有同类功能，但不同名的模块，但大多算法类的 Python 逻辑代码是可以拿来即用的。\n\n- MicroPython 兼容实现的 Python3 的异常机制、没有实现元类（metaclass）机制，独立的 GC 机制。\n\n- 在许当不同的硬件微芯片（最低在 nRF51）的移植上， MicroPython 代码接口缺乏一致性，呈现碎片化。\n\n- MicroPython 编译（mpy-corss）后得到的是 mpy ，而不是 Python3 的 pyc 文件。\n\n- MicroPython 在移植 Python3 代码时，经常缺少各种方法，所以要习惯寻找同类接口，而它们的使用方法除了看文档外就只能看源码。\n\n### 总结\n\n- MaixPy 相比 MaixPy3 功能要更简单（简陋）。\n- MaixPy 和 MaixPy3 的开发工具不同。\n- MaixPy 标准库（MicroPython）相比 MaixPy3 有一定的不足。\n- MaixPy 的外设驱动模块具体函数存在差异。\n- 不同的芯片执行效率有差异，MaixPy 和 MaixPy3 的有着不同的内存与性能消耗。\n\n> 如有更多欢迎补充。"}, "/soft/maixpy3/zh/tools/maixsense.html": {"title": "使用 MaixPy3 IDE 连接 MaixSense ", "content": "---\ntitle: 使用 MaixPy3 IDE 连接 MaixSense \nkeywords: Jupyter, MaixPy3, Python, Python3\ndesc: maixpy doc: 在 MaixII-Sense 平台上使用 \n---\n\n\n| 时间 | 负责人 | 更新内容 |\n| --- | --- | --- |\n| 2022年2月28日 | Rui | 编写连接文档 |\n\n> 在 MaixSense 上使用 MaixPy3 ，需要烧录内置 MaixPy3 的 armbian 系统，通过数据线连接\n\n## 串口连接\n\n使用串口连接软件，以 mobaxterm 为例\n\n![](./assets/mobaxterm-serial-4.png)\n\n在「session setting」 对话框里选择【serial】，再选好串口号及波特率，点击【OK】就完成连接了。\n\n![](./assets/mobaxterm-serial-5.png)\n\n同样【session】会保存在左侧的【session】标签页里，方便下次连接。\n\n## SSH 连接\n\n除了有线串口的方式，还可以通过无线访问 SSH 登录 Linux 系统，如一般的家用路由器。\n\n在 Linux 系统输入 ifconfig 查看自己 ip 地址（192.168.1.185），然后输入自己名称和密码，常见有 root / root 。\n\n> 如果没有设置密码，root 的连接密码是 root 。输入密码的时候是看不到的，在输入结束之后，按回车即可\n\n![](./assets/mobaxterm_ssh.jpg)\n\n就可以看到 Linux 的登录会话终端了。\n\n![](./assets/mobaxterm_ssh_view.jpg)\n\n\n## MaixPy3 IDE 连接\n\nMaixPy3 IDE 连接 MaixSense 只能使用远程连接，不能像 MaixII-Dock 可以通过 adb 进行有线连接，而且每个人的网络环境都存在差异，可能存在连接不上的情况出现。\n\n### 准备\n- 烧录好带有 MaixPy3 的 Armbian 系统\n- 连接网络进行 MaixPy3更新，确保 MaixPy3 的版本大于 0.3.4。\n- 运行 ifconfig 获取开发板的 IP 地址\n\n### 连接\n在板子上运行 python -c \"import maix.mjpg;maix.mjpg.start()\" 启动板子上的远程 RPyc 服务，启动 MaixPy3 IDE，新建代码区，运行下面的连接代码。\n\n```python\n$connect(\"192.168.43.44\")   # 此处填入开发板的 IP 地址\nimport platform\nprint(platform.uname())\n```\n\n> 启动 IDE 的时候，会打开一个 adb 终端窗口，可以直接关闭无视它"}, "/soft/maixpy3/zh/tools/maixpy3-ide-overview.html": {"title": "MaixPy3 概述", "content": "# MaixPy3 概述\n\n## What?\n\n\n## Why?\n\n\n## How?"}, "/soft/maixpy3/zh/tools/MaixPy3_IDE.html": {"title": "MaixPy3 IDE", "content": "---\ntitle: MaixPy3 IDE\nkeywords: MaixPy3 IDE\ndesc: maixpy doc: 如何连接并使用 MaixPy3 的 IDE\n---\n\n>[下载 MaixPy3 IDE ](https://dl.sipeed.com/shareURL/MaixII/MaixPy3-IDE)\n>百度网盘下载连接：<https://pan.baidu.com/s/1C7Jl3rXticeJsCgH-fIcbQ> 提取码：2333\n\n## 为什么要使用 IDE ？\n\n在没有 IDE 的时候，我们是这样编程的，这是每一只远古程序猿都必备的开发技能。\n\n![index.png](./assets/4in1.jpg)\n\n上述命令行的编程方式是上世纪 80 年代流行的开发方式，建议你在有一定 linux 系统的操作基础后再熟练使用会更好，但 2022 现代 IDE 工具的重点应该是向人类传达 Python 代码运行结果或效果。\n\n如果你是一名开发者，你要如何教会初学者使用你的代码？像你一样使用命令行敲出来看实际的效果吗？\n\n对初学者来说，这一定是一场灾难，所以我们需要 IDE 来结束这一切。\n\n## 那么 MaixPy3 IDE 是什么?\n\n它是一套基于 [jupyter](https://jupyter.org/) 实现的 Python3 集成开发环境（IDE，Integrated Development Environment ），意在帮助用户通过电脑编写 Python 语言代码后，用户运行开发者提供的 jupyter notebook 文档后，接上硬件后点击【▶ 运行】可以实时呈现如下效果图。\n\n![index.png](./assets/index.png)\n\n为了方便新入门的同学进行学习，在 Jupyter 文档中你可以单步运行代码，并保留输出的结果，还能将屏幕显示的内容保留下来。\n\n软件具备的特点如下：\n\n- 通过 TCP/IP 连接开发板，支持在本机运行 Python 代码，实时反馈开发板的运行结果或图片。\n- 通过 jupyter notebook 文档可以保存每一次的运行结果，方便知识的传播。\n- 继承 ipython 实现 Python 语法的高亮和补全功能（可以按 tab 进行补全）。\n\n## 如何安装 MaixPy3 IDE ？\n\n> **软件安装方法和注意事项要严格看本文说明（大佬鼠宣）**\n\nMaixPy3 IDE 的构成主要如下：\n\n- 一个在后台运行的托盘程序。\n- 一个 jupyter 服务程序。\n\n用户使用与排查流程主要如下：\n\n- 确认所用的系统平台，确定安装方法。\n- 确认所用的开发硬件，查看对应的系统配置方法。\n- 确认系统防火墙没有阻止 TCP 的 18811 和 18812 端口，不清楚就关闭网络防火墙或安全软件。\n- 确认硬件的 MaixPy3 的 Python 包和电脑上的 IDE 版本为 0.4.0 以上。\n- 确认 所用硬件的 连接和配置方法，确认没有被杀毒程序给阻止，确认程序权限已给到。\n- 若是仍然出现问题，将上述流程打包起来反馈给社区并@管理员解决。\n\n### 关于 Windows 平台的安装方法\n\n**只支持 Windows7 或 Windows10 32位以上的系统，需要自带安装了支持谷歌内核浏览器的系统，Windows11 测试样本极少，需要慎重选用**\n\n为了节约用户自己配置的操作，我们提供了开箱即用的绿色软件，它是借助 pyinstaller 将 ipython 、 jupyter 、 rpyc_ikernel 合并导出的 Python 程序，你可以在[下载站](https://dl.sipeed.com/shareURL/MaixII/MaixPy3-IDE)中获得 MaixPy3 IDE exe 安装包，安装程序结束之后，它会调用系统默认的浏览器以网页的形式打开，运行的浏览器需要 chrome 内核支持，不能是 IE 浏览器，旧版的 Edge 加载 8M 以上的页面会卡死，不是特别推荐。\n\n![IDE_1](./assets/IDE_1.png)\n\n> 若是下载站很慢，可以在[百度云](https://pan.baidu.com/s/1C7Jl3rXticeJsCgH-fIcbQ)下载，提取码：2333 。\n\n2022年1月15日收到用户的反馈点\n\n曾经有自己手动配置过环境的同学，需要在删除你系统的 `C:\\Users\\（改成你电脑的用户名）\\AppData\\Roaming\\jupyter\\kernels\\rpyc` 防止调用核心时调用了过去的旧核心导致错误发生。\n\n### 关于 Mac 和 linux 其他平台的安装方法\n\n如果你不喜欢提供的 pyinstaller 打包的版本，可以自行配置 python 、jupyter 、ikernel 等基础环境，自行 pip 手动安装和配置环境，需要你具备一定的 python 开发基础，请阅读 [rpyc_ikernel](https://github.com/sipeed/rpyc_ikernel) 完成安装即可，手动安装脚本的方法如下：\n\n```bash\npip install rpyc_ikernel\npython -m rpyc_ikernel.install\n```\n\n此时运行 jupyter notebook 或 lab 即可，注意 Windows 的 adb.exe 可以从 IDE 中提取或官方下载得到，然后自行配置到环境变量中，若是其他平台则自带。\n\n## MaixPy3 IDE 界面介绍\n\n下面介绍一下软件的工作区域和环境。\n\n### 程序主界面介绍\n\n![IDE_2](./assets/IDE_2.png)\n\n1. 为文件选择区，点击即可进入 Jupyter 文档中\n2. 为文件上传，是将文件上传到 MaixPy IDE 的工作区当中，并不是将文件上传到开发板中。\n3. 为新建文件或者是文件夹\n4. 退出 MaixPy3 IDE，直接关闭浏览器 MaixPy IDE 还会在后台中运行。\n\nMaixPy IDE （jupyter） 在创建代码文档的时候，可以选择多个 Python 执行核心。\n\n![IDE_2](./assets/core.png)\n\n1. 选择 Python3 此时使用的是本机的 Python 解释器，此时 Python 代码运行在本机上。\n\n2. 选择 RPyc-python ，此时会连接开发板再运行代码并输出结果，此时代码运行在开发板里。\n\n### jupyter notebook 文档界面\n\n![](./assets/IDE_3.png)\n\n1. 单元格工具栏，可以对单元格进行复制、粘贴、运行、停止等操作\n2. 当前单元格的属性，可以在代码和 markdown 文件中切换\n3. 显示当前文档运行代码属性单元格时所使用的内核\n4. 显示蓝色是为选中单元格，绿色为当前处于编辑的单元格\n\n![](./assets/IDE_4.png)\n\n借助 notebook 文档，你可以得到这份代码文档的开发者的调试过程与运行结果。\n\n![](./assets/IDE_5.png)\n\n甚至是运行的图像结果，这样初学者在确保所有环境一致的情况下，照着运行就可以同步真实的开发成果。\n\n![](./assets/IDE_6.png)\n\n这也是 jupyter 的魅力之一吧，如果你学会了也可以用同样的方式向他人分享你的开发成果喔：）。\n\n> 注意 MaixPy3 IDE 的 jupyter notebook 的服务并不在板子上启动，所以里面的文档是存在本机的，而不在板子上的，有得同学会误以为软件里的文件就是板子里的文件。\n\n## 【附录】遇到问题应该如何解决？\n\n为了节约初学者的部署和上手时间，我们做了大量的努力，但仍然无法完美解决所有人的环境差异。\n\n所以一些常见问题我们已经整理好，阅读过后本文后仍然出现无法解决的问题，就可以从左侧的导航中获取 [MaixPy3 的常见问题与解决办法](/soft/maixpy3/zh/question/maixpy3_faq.html) 。\n\n为了防止一些不了解具体实现，也不看文档，但又自作主张的同学出现的问题，大佬鼠我在这里特别说明一下 IDE 的工作框架和可能遇到的问题，谨记！没有绝对完美且不出错的软件，如果有那一定是我本机上的软件。\n\n这里我们以典型硬件 V83X 和 R329 的为例。\n\n因为 V83X 因为支持 usb adb forward 功能，可以通过转发 TCP/IP 地址进行 IP 映射的端口绑定，而 R329 只能通过 TCP/IP 地址进行连接，但从设计上来说 IDE 只支持 TCP/IP 地址的连接方法，所以要确保 TCP 的远程调用端口 18811 和 18812 图传端口没有被防火墙阻止，那么如何确认呢？\n\n最起码的就是互相 ping 对方的 IP 确保该 IP 下的通路可行。如果 IP 确定是可以连通的，则我们需要确定远程调用的服务是否存在。\n\n通常里面需要一个 rpyc + mjpg 的服务去维持远程调用，如果是 V83X 则会自动经过 adb shell 完成调用 [实现在 github 这里](https://github.com/sipeed/rpyc_ikernel/blob/master/rpyc_ikernel/adb.py#L509-L539)，如果你是 R329 则需要手动启动该服务，或配置成开机自动启动，从而避免下次手动启动。\n\n如果遇到 IDE 链接失败，首先要通过 linux ps 命令检查维持 IDE 链接的 Python 程序（`python -c from maix import mjpg;mjpg.start();`）是否存在（如 S 表示正在运行）。\n\n![](./assets/ps.png)\n\n若是通道+服务均正常，那 IDE 就一定可以连上，还需要注意的就是默认连接的 IP 地址是 localhost ，如果你本机的网卡环境比较混乱，可能你需要手动指定一下 IP 才能确保正确连接上，如：`$connect(\"192.168.0.156\")`。\n\n在我设计的 V83X 的使用体验步骤是：\n\n1. 确认使用最新镜像系统，其中的 maixpy3 大于 0.4.0 版本，要自行准备 SD 卡喔。\n2. 确认使用最新的 IDE 工具，其中版本号大于 0.4.0 版本，安装时提示安装驱动。\n3. 接上 M2DOCK OTG 口，屏幕存在画面，电脑产生 U 盘等行为都表示系统已经启动。\n4. 打开 IDE 的文档，从列表中选择一份文档运行，在选择其中的代码运行查看效果。\n\n其中 1 可以在购买 TF 卡的时候，解决普通用户到手不需要学习安装和烧录，直接跳到步骤 2 ，其他的板子也是大同小异，要注意给权限和防止杀毒软件杀死，还有防火墙的配置若是不懂就关了，懂得就自行添加过滤规则。\n\n> MaixPy3 IDE 依赖于 [jupyter](https://github.com/jupyter/jupyter)、[rpyc_ikernel](https://github.com/sipeed/rpyc_ikernel)、[MaixPy3](https://github.com/sipeed/MaixPy3) 开源仓库实现，感兴趣的自行了解，其实所谓的 IDE 就是 jupyter 的打包版本，知道了工作机制后，还不赶紧用起来！"}, "/soft/maixpy3/zh/usage/01_loop_python.html": {"title": "", "content": "> 本文是给有一点 Python 基础但还想进一步深入的同学，有经验的开发者建议跳过。\n\n## 前言\n\n上文讲述了如何认识开源项目和一些编程方法的介绍，这节主要来说说 Python 代码怎么写的一些演化过程和可以如何写的参考，在现在的 Sipeed 开源社区/社群里，有太多的新手不知道如何写好 Python 代码，尤其是嵌入式中的 Python 代码也是有不少的技巧和观念需要注意的，至少让这篇文章从循环开始说起。\n\n> 可以把本文当作一篇经验之谈，主要是探讨代码稳定性与性能，以及一些计算机知识的拓展。\n\n## 循环执行代码\n\n当写下第一行代码的时候，在电脑上的 Python 解释器运行效果是这样的。\n\n```python\nprint('Hello World')\n```\n\n![](./../usage/asserts/win_python.png)\n\n而嵌入式设备上的 python 是通过串口（serial）传出来。\n\n![](./../usage/asserts/maix_python.png)\n\n当写完了第一行 `Hello World` 的 `print` 函数，总不能一直复制、粘贴代码吧。\n\n```python\n\nprint('Hello World')\nprint('Hello World')\nprint('Hello World')\nprint('Hello World')\nprint('Hello World')\n\n```\n\n也不是只运行验证功能就好了吧，所以加上了循环（`while`）执行代码。\n\n```python\n\nwhile True:\n    print('Hello World')\n\n```\n\n如果想要稳定一些，最好还要为它加入异常机制，保证它不会因为 Python 代码的运行出错而停下来。\n\n```python\n\nwhile True:\n    try:\n        print('Hello World')\n    except Exception as e:\n        pass\n\n```\n\n### 循环代码中为什么需要异常机制\n\n是不是以为 print 这样的代码就不会出错？其实不然，其实程序越接近底层硬件越容易出错。\n\n从功能上说上文两者之间并没有什么区别，都是输出，但你会发现串口输出可能会出现下面几类情况。\n\n- 串口芯片损坏或线路断路、串口到芯片的通路损坏导致的串口没有数据输出。\n- 串口线路数据不稳定、串口协议（波特率、停止位）等配置错误导致的数据乱码。\n\n这就意味着你会遇到很多来自硬件上的问题，所以要注意到这些意外。\n\n那在软件代码上会发生什么有关于硬件上的意外呢？\n\n通常有无响应、无应答、未连接等不成功的错误，它们是来自 IO 的错误。\n\n- 当网络连接失败后需要超时重连，传输数据通道闲置时需要定时检查心跳数据包。\n- 当配置文件写入后通常会读出来确认真的写入了，也是为了防止出错，可能是存储介质出错，也可能是逻辑出错。\n- 当用户向输入框填了错误数据，不用写怎么判断和处理，不合法的数据抛出异常就行。\n\n因为这些现象太多不确定的可能性，才会需要对代码进行异常捕获机制，来决定是否放过这次意外，可能会在下一次的循环就恢复了，这样就能够基本保证了 Python 代码循环的稳定性了。\n\n### 来自外部/硬件上异常机制\n\n这样就足够了吗？\n\n事实上有些错误不源于 Python 代码，可能来自于底层 C 代码，或其他程序，上文说的异常机制只能捕获 Python 异常，不能捕获来自其他语言的异常。\n\n所以实际情况比想象的要更严峻一些，当你无法解决不稳定的系统带来其他异常的时候，通常在服务器程序上设计会在外部附加一个守护程序（如调试程序）来定时检查自己的程序，例如可以检查下面的一些情况。\n\n- 检查当前的系统是否能联网\n- 检查数据库的通路是否正常\n- 检查指定的程序是否在运行\n\n总得来说，你要为你的程序做一个监控程序，可以是守护程序，也可以是看门狗。\n\n> 具体怎么实现，可以了解一些守护进程的实现。\n\n### 看门狗（watchdog）是什么？\n\n如上述的守护程序是靠一个软件去监控另一个软件的状态，而看门狗的工作行为描述如下：\n\n假设有一条需要定时吃饭（更新）的狗、如果不定时喂它（feed）就会饿着肚子叫。那么问题来了，什么时候狗会叫呢？因为人（芯片）死了，没人喂它了。（这也许是一个冷笑话）\n\n看门狗是要求芯片程序负责定时喂狗，如果没有喂狗就狗就饿死了，作为报复狗会把芯片重启。让它可以继续喂狗。\n\n任何硬件产品都有可能出现意外和错误，看门狗相当于芯片上的最后一层保障机制，通常它可能会发生在函数栈的指针参数执行出错，导致后续的喂狗操作再也执行不到了，具体怎么实现，可以查阅不同芯片提供的程序接口或寄存器。\n\n### 优化！优化！！优化！！！\n\n当你的程序已经跑起来以后，你会发现程序并没有达到令人满意的效果，在性能、内存上都没有经过任何考虑，只是实现了最起码的功能而已，那么完成了功能以后，可以如何继续呢？\n\n当然，在优化程序之前得先建立计算代码执行时间的观念，建立起最简单的性能指标，如在代码加上时间计算。\n\n```python\ndef func():\n    i = 20**20000\n\nimport time\nlast = time.time()\nfunc()\ntmp = time.time() - last\nprint(tmp)\n```\n\n在 CPU I5-7300HQ 的计算机上见到每一次的循环的时间间隔约为 0.000997781753540039 不足 1ms 即可完成。\n\n```bash\nPS C:\\Users\\dls\\Documents\\GitHub\\MaixPy3> & C:/Users/dls/anaconda3/python.exe c:/Users/dls/Documents/GitHub/MaixPy3/test.py\n0.000997781753540039\n```\n\n注意不要写到 `print(time.time() - last)` ，因为重定向后的 print 是相当耗时的，尤其是当内容输出到串口终端或网页前端的时候，如下使用 M2dock 设备来演示一下串口输出。\n\n> 重定向指改变内容要输出的地方\n\n```bash\nroot@sipeed:/# python3\nPython 3.8.5 (default, Jan 17 2021, 06:07:56)\n[GCC 6.4.1] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> def func():\n...     i = 20**20000\n...\n>>> import time\n>>> last = time.time()\n>>> func()\n>>> tmp = time.time() - last\n>>> print(tmp)\n0.09001994132995605\n>>>\n>>>\n>>> def func():\n...     i = 20**20000\n...\n>>> import time\n>>> last = time.time()\n>>> func()\n>>> print(time.time() - last)\n1.480057954788208\n>>>\n```\n\n可以看到相差可能有 1 秒，而事实上只需要 90ms 就可以完成 func 函数的运算，这就产生了误差导致不准确，若是使用 jupyter 输出就会看到 0.026456356048583984 需要 26ms 可以较为准确的推算出它的真实运算结果。\n\n![](./asserts/time_python.png)\n\n为什么会造成这种差异的原因是因为串口依次输入命令输出结果需要时间，所以依次输入语句执行自然会存在误差，而 jupyter 是通过网络 socket 连接传输显示到屏幕上，所以耗时误差只会发生在运算重定向输出结果的时候，最终结果会较为贴近真实运算结果，通过保存下述代码文件来运行即可得知真实情况下约为 26 ~ 28ms 完成。\n\n```bash\nroot@sipeed:/# cat test.py\ndef func():\n    i = 20**20000\n\nimport time\nlast = time.time()\nfunc()\ntmp = time.time() - last\nprint(tmp)\n\nroot@sipeed:/# python test.py\n0.028677940368652344\nroot@sipeed:/#\n```\n\n所以从现在建立起最基础的计算耗时，并且认知到在计算机的世界里，毫秒其实已经很慢了，然后可以类比一种感受，人眼感到流畅的画面至少是 24 fps ，而平时的视频在 15 fps 的流动是不会让你感受到卡顿的，如果低于这个阈值，则会出现卡顿造成心理上的不愉快，这个 15 fps 意味着每秒 15 张存在变化的画面，如果用程序来类比就是 1000 ms / 15 = 66 ms ，也就是每个流程操作最好是在 66ms 内完成，这样用户才不会觉得卡顿，同理，当 1000ms / 24 = 41ms 就可以确保用户体验这个软件的时候会觉得流畅。\n\n有了基本的性能指标，就有了优化的对比参考，如果是一些测试框架会帮助你自动完成每个函数的耗时统计，但在没有现成框架工具的时候就要稍微辛苦一下自己了。\n\n#### 讲一些经典案例\n\n在日常中存在最多操作就是循环和判断，显然好的优化就是减少不必要的指令操作，可以通过改变代码的执行结构来进行优化，下面就来具体分析吧。\n\n如某个向网络上发送数据的操作，最初可能会按人类直觉写出以下的代码，这是一种不用思考也可以很容易写出来的同步阻塞式的结构，每一条语句都是满足了某些条件再继续执行。\n\n```python\n\ndef xxxx_func():\n    import random\n    return random.randint(0, 1)\n\nwhile True:\n    is_idle = True\n    if is_idle is True:\n        print('try start')\n        is_ready = xxxx_func()\n        if is_ready is True:\n            print('try ready')\n            is_connected = xxxx_func()\n            if is_connected is True:\n                print('try connect')\n                is_send = xxxx_func()\n                if is_send is True:\n                    print('try send')\n                    is_reply = xxxx_func()\n                    if is_reply is True:\n                        print('wait reply')\n                        is_exit = xxxx_func()\n                        if is_exit is True:\n                            print('operate successfully')\n```\n\n而优化只需要加状态变量改写成状态机结构（fsm）就可以了，所有代码都可以平行化执行，并根据执行频率的重要程度（权重）调整各项判断的顺序，尤其是移除一些不必要的判断。\n\n```python\ndef xxxx_func():\n    return 1\n\n# state value\nis_idle, is_ready, is_connected, is_send, is_reply, is_exit = 0, 1, 2, 3, 4, 5 \nstate = is_idle\n\nwhile state != is_exit:\n\n    if state is is_reply:\n        print('wait reply')\n        state = is_exit if xxxx_func() else is_send\n        continue\n\n    if state is is_send:\n        print('try send')\n        state = is_reply if xxxx_func() else is_connected\n        continue\n\n    if state is is_connected:\n        print('try connect')\n        state = is_send if xxxx_func() else is_ready\n        continue\n\n    if state is is_ready:\n        print('try ready')\n        state = is_connected if xxxx_func() else is_idle\n        continue\n\n    if state is is_idle:\n        print('try start')\n        state = is_ready\n        continue\n```\n\n这样改造执行结构后，每个代码之间的上下文关系并不强烈，是否执行某个语句取决于系统对于某个状态是否满足，如果状态失败也不会倒退回最初的判断，也就不需要每次都对各个状态做检查，检查只会发生在出错的时候状态跌落（state - 1）。\n\n缺点就是需要消耗一些记录状态的变量(●'◡'●)，不过代码的拓展性和维护性就上来了。\n\n> 可以根据实际情况增加状态的判断或是减少状态的转移（调整状态转移范围），如直接设置 state = is_ready，假设某些操作是已知的就可以跳过，可以添加 continue 跳过一些不可能发生的状态。\n\n#### 还有吗？\n\n进一步优化还可以干掉 if 直接将状态与函数联合索引执行，简化代码如下。\n\n```python\n\nis_a, is_b, is_c = 0, 1, 2\n\nstate = is_a\n\ndef try_b():\n    global state\n    state = is_c\n\ndef try_a():\n    global state\n    state = is_b\n\nfunc = [try_a, try_b]\n\nwhile state != is_c:\n    func[state]()\n    # print(state)\n\n```\n\n基于上述结构给出一个示例代码参考。\n\n```python\n\nclass xxxx_fsm:\n            \n    is_start, is_ready, is_connected, is_send, is_reply, is_exit = 0, 1, 2, 3, 4, 5\n\n    def xxxx_func(self):\n        return 1\n\n    def __init__(self):\n        self.func = [self.try_start, self.try_ready, self.try_connect, self.try_send, self.wait_reply]\n        self.state = __class__.is_start # state value\n\n    def wait_reply(self):\n        self.state = __class__.is_exit if self.xxxx_func() else __class__.is_send\n\n    def try_send(self):\n        self.state = __class__.is_reply if self.xxxx_func() else __class__.is_connected\n\n    def try_connect(self):\n        self.state = __class__.is_send if self.xxxx_func() else __class__.is_ready\n\n    def try_ready(self):\n        self.state = __class__.is_connected if self.xxxx_func() else __class__.is_start\n\n    def try_start(self):\n        self.state = __class__.is_ready\n\n    def event(self):\n        self.func[self.state]()\n\n    def check(self):\n        return self.state != __class__.is_exit\n\ntmp = xxxx_fsm()\n\nwhile tmp.check():\n\n    tmp.event()\n\n    # print(tmp.state)\n```\n\n其实上述的有限状态机并非万能的代码结构，只是刚好很适合拆分已知的复杂业务逻辑的同步阻塞代码，那么还有什么结构可以选择吗？有的，此前说的都是同步阻塞的代码，所以还有所谓的异步执行的代码。\n\n#### 说说异步的执行方式\n\n在这之前的代码都是按每个循环的步骤有序执行完成功能（同步执行），但现实生活中的操作一定是按顺序发生的吗？其实不然，其实很多操作可能会在任意时刻发生。\n\n想象一个程序，它会响应来自网络的数据，也会响应来自人类的按键输入操作，这两个操作如果按上述的结构来写，可能会是下面这样。\n\n```python\nimport time, random\n\ndef check_http():\n    time.sleep(random.randint(0, 3))\n    return random.randint(0, 1)\n\ndef http_recv():\n    while True:\n        if check_http():\n            print('http_recv')\n            break\n\ndef check_key():\n    time.sleep(random.randint(0, 2))\n    return random.randint(0, 1)\n\ndef key_press():\n    while True:\n        if check_key():\n            print('key_press')\n            break\n\nwhile True:\n    http_recv()\n    key_press()\n```\n\n可以看到 http_recv 和 key_press 两个事件的检查会各自占据一段不知何时会触发或结束的检测的时间，程序只能循环等待这些事件会不会发生（或称轮询）。\n\n这是个看起来可以工作但浪费了很多时间的程序，现实里接收到许多用户的网络连接，而服务程序不可能只服务某个用户的连接。\n\n所以改写异步的第一步就是简化代码中不必要的循环，将每个需要循环等待的部分拆分成非阻塞的函数。\n\n> 非阻塞意味着某个操作会在有限的时间内结束，期望某个函数能够在较短的时间（10ms）内退出，退出不代表功能结束，只是需要把这个时间让出去给其他函数调用。\n\n```python\nimport time, random\n\nhttp_state, key_state = 0, 0\n\ndef http_recv():\n    global http_state\n    if http_state:\n        print('http_recv')\n\ndef key_press():\n    global key_state\n    if key_state:\n        print('key_press')\n\ndef check_state():\n    global key_state, http_state\n    time.sleep(random.randint(0, 1))\n    key_state, http_state = random.randint(0, 2), random.randint(0, 2)\n\nwhile True:\n    check_state()\n    http_recv()\n    key_press()\n```\n\n从逻辑上移除了等待，再通过统一的（check_state）检查每个操作的状态再决定是否唤醒该操作，变成只有满足某个状态才执行该操作，将此前的多个循环拆分出来。\n\n但你会发现这样写还是有问题，这样岂不是意味着所有代码都要按这个接口来写了吗？那么多的代码，不可能全都可以拆分吧。\n\n所以是时候加入异步 IO （asyncio）的 async 和 await 语法了！先来点简单的。\n\n```python\nimport asyncio\n\nasync def test_task(name, tm):\n    await asyncio.sleep(tm)\n    print('%s over...' % name)\n\nasync def main(name):\n    import time\n    last = time.time()\n    await asyncio.gather(\n        test_task(name + 'A', 0.1),\n        test_task(name + 'B', 0.2),\n        test_task(name + 'C', 0.3),\n    )\n    print(name, time.time() - last)\n\nloop = asyncio.get_event_loop()\ntasks = [ main('l: '), main('r: ') ]\nloop.run_until_complete(asyncio.wait(tasks))\n\n```\n\n运行结果如下：\n\n```bash\nPS python.exe test.py\nr: A over...\nl: A over...\nr: B over...\nl: B over...\nr: C over...\nl: C over...\nr:  0.3076450824737549\nl:  0.3076450824737549\n```\n\n可以看到代码总共耗时为 0.3s 完成，但运行了两次不同所属的 main 函数以及各自调用三次不同延时的 test_task 任务，而 await asyncio.sleep(tm) 延时期间实际上是被 asyncio 拿去运行其他的 async 函数了，基于此结构可以这样改写。\n\n```python\n\nimport asyncio, random\n\nasync def key_press():\n    await asyncio.sleep(0.1)\n    key_state = random.randint(0, 1)\n    if key_state:\n        return 'have key_press'\n\nasync def http_recv():\n    await asyncio.sleep(0.2)\n    http_state = random.randint(0, 1)\n    if http_state:\n        return 'have http_recv'\n\nasync def run():\n    import time\n    while True:\n        task_list = [http_recv(), key_press()]\n        done, pending = await asyncio.wait(task_list, timeout=random.randint(0, 1) / 2)\n        print(time.time(), [done_task.result() for done_task in done])\n        await asyncio.sleep(0.2) # remove to run too fast.\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(run())\n```\n\n执行效果如下。\n\n```bash\n1615141673.93252 [None, None]\n1615141674.134 [None, 'have http_recv']\n1615141674.3350334 [None, None]\n1615141674.7361133 ['have key_press', 'have http_recv']\n1615141674.9365196 [None, None]\n1615141675.1399093 ['have http_recv', None]\n```\n\n可以看到在运行 run 函数延时 `await asyncio.sleep(0.2)` 后就会循环加载异步事件函数执行，配置 asyncio.wait 函数的参数 `timeout` 会导致 `random.randint(0, 1) / 2` 秒后就会自行超时退出，退出的时候会收集当前的 `key_press` 和 `http_recv` 函数的运行结果，如果期间异步函数成功返回值（`return 'have http_recv'`），最终结果就会输出 `1615138982.9762554 ['have http_recv']` 表示有事件触发并执行了，否则为 None ，这将在下一次循环重新提交异步函数列表 `[http_recv(), key_press()]` 执行。\n\n> 注意 Python 3.7 以前的版本使用 loop = asyncio.get_event_loop() & loop.run_forever() & loop.run_until_complete() ，而后采用 asyncio.run() 了。每个编程语言都有自己的异步框架和语法特色，请根据实际情况选用。\n\n### 考虑一下封装模块给其他人使用吧？\n\n随着代码越写越多，项目越来越大，大到可能不是你一个人写的时候，你就要开始注意工程项目的管理了，这与个人写代码时的优化略微不同，主要强调的是不同代码之间的接口分离，尽量不干涉到他人的实现和提交，所以在写代码的时候，不妨为自己准备一个独立模块，以方便与其他人写的分离或是导入其他（import）模块。\n\n若是在某个目录（`mod`）下存在一个 `__init__.py` 的话，它就会变成 Python 模块，且名为 `mod` ，其中 `__init__.py` 的内容可能如下：\n\n```python\ndef code():\n    print('this is code')\n```\n\n而且在该目录下还存在一个额外的代码文件（如 `tmp.py` ）内容如下：\n\n```python\ninfo = 'nihao'\n```\n\n对于开发者或用户来说，在 `import mod` 的时候会调用 `mod` 目录下的 `__init__.py` ，而 `from mod import tmp` 会调用 `mod` 目录下的 `tmp.py` 代码。\n\n```python\n>>> import mod\n>>> mod\n<module 'mod' from 'C:\\\\mod\\\\__init__.py'>\n>>> mod.code()\nthis is code\n>>> from mod import tmp\n>>> tmp\n<module 'mod.tmp' from 'C:\\\\mod\\\\tmp.py'>\n>>> tmp.info\n'nihao'\n>>>\n```\n\n这样你写的代码就可以作为一个模块被其他人所使用了，注意 import 只会加载并执行一次，想要再次加载请使用 reload 函数。\n\n### 如何进行内存上的分析？\n\n这里就推荐 [memory_profiler](https://github.com/pythonprofilers/memory_profiler) 开源工具，快去体验吧。\n\n使用方法：`python -m memory_profiler example.py`\n\n```python\nfrom memory_profiler import profile\n\n@profile\ndef my_func():\n    a = [1] * (10 ** 6)\n    b = [2] * (2 * 10 ** 7)\n    del b\n    return a\n```\n\n运行结果：\n\n```bash\nLine #    Mem usage    Increment  Occurences   Line Contents\n============================================================\n     3   38.816 MiB   38.816 MiB           1   @profile\n     4                                         def my_func():\n     5   46.492 MiB    7.676 MiB           1       a = [1] * (10 ** 6)\n     6  199.117 MiB  152.625 MiB           1       b = [2] * (2 * 10 ** 7)\n     7   46.629 MiB -152.488 MiB           1       del b\n     8   46.629 MiB    0.000 MiB           1       return a\n```\n\n## 总结\n\n其实所谓的优化就是在程序上不断追求无延迟、零等待、鲁棒性、艺术品、最佳实践等指标。\n\n当完成了自己的某个作品，多少都会希望自己的作品是最好的，又或是越做越好的。熬夜辛苦写下的程序，用尽自己的脑力和各种逻辑思维来不断打磨它，尽可能的把它变成一件艺术品，然后为之自豪和兴奋，恨不得向它人炫耀自己的成果。\n\n但愿你不会在往后的一堆垃圾代码中失去了最初喜欢上编程的心情。\n\n### 附录：多线程？多进程？该不该使用？\n\n事实上多线程和多进程都是建立在操作系统之上的概念，由于操作系统中存在不同优先级的中断函数，其中优先级较高的函数栈会打断优先级低的函数栈执行，并且优先级高的操作结束就会轮到优先级低的操作，优先级高的操作通常都会被设计成尽快结束退出（哪怕是失败），不然用户程序就会像老爷爷一样缓慢运行了。\n\n多线程是由拥有内存空间进程（某个程序）创造出来的，多线程函数“看上去”是彼此并行的，并且共用所属进程的内存数据，而不同进程之间申请的内存空间并不互通，所以当你想要实现守护进程的程序，是需要对其他进程进行通信的（如卸载程序时会检查并发送信号停止要卸载的程序），并非是在代码中修改一个变量那么简单。\n\n事实上我并不鼓励用户在 Python 上使用多线程，因为全局解释器锁（GIL）的存在，CPython 解释器中执行的每一个 Python 线程，都会先锁住自己，以阻止别的线程执行。而 CPython 解释器会去轮询检查线程 GIL 的锁住情况，每隔一段时间，Python 解释器就会强制当前线程去释放 GIL，这样别的线程才能有执行的机会。总得来说 CPython 的实现决定了使用多线程并不会带来太大的性能提升，反而会带来更多线程安全的问题，尤其是需要线程资源同步了。\n\n> 警告：请不要在每个线程中都写上不会退出的死循环，多线程的并不是拿来偷懒的工具。"}, "/soft/maixpy3/zh/usage/00_hello_world.html": {"title": "Hello World", "content": "---\ntitle: Hello World\nkeywords: Hello World, MaixPy3\ndesc: maixpy doc: Hello World\n---\n\n> 本文是给有一点 Python 基础但还想进一步深入的同学，有经验的开发者建议跳过。\n\n## 前言\n\n在写这篇案例系列的时候 [junhuanchen](https://github.com/junhuanchen) 期望能够引导用户如何成为专业的开发者，不是只会调用代码就好，所以在 MaixPy3 开源项目上期望为你带来值得学习和容易上手的开源项目，所以开篇会引导用户学习一些长期有利于编程工作上好的做法和观念，就先从最简单的认知项目开始吧。\n\n第一次接触需要编程的开源硬件项目，要做的第一件事就是先有一个好的开始，例如运行 Hello World 程序，意味着你必须能够先将这个事物跑起来才能够继续后续的内容，它可能是硬件、软件、工具等可编程的载体。\n\n> 但这里先不强调立刻开始运行程序，而是强调如何熟悉一个开源项目。\n\n要先找到它提供的开发文档（例如本文），先纵览全文，站在专业的角度来看，你需要先关注它提供了哪些资源，可以在哪里反馈你的问题，这样就有利于你后续开发过程中出现问题后，该如何迅速得到解决，避免自己之后在学习和开发过程中耽误时间。\n\n![](https://opensource.com/sites/default/files/styles/image-full-size/public/lead-images/OSDC_Resource_Main_Page.png)\n\n有哪些资源是值得关注的？\n\n- 学会搜索！！！！！\n- 找到它的开源项目（如：[github.com/sipeed](https://github.com/sipeed)），获取它所提供的一系列源码。\n- 找到它提供的用户手册、应用案例、数据手册等等一系列开发所需要的文档。\n- 找到它的开发、编译、烧录、量产等一系列配套工具链，为后续软件开发活动中做准备。\n- 找到它的公开交流的环境，如 bbs、github、twitter、facebook、qq、wechat 等社交平台。\n\n现在你可以放心的编程了，但你还需要遵守一些在开源软件上的规则，认知到开源协议的存在，不要随意地做出侵犯他人软件的行为，哪怕没有法律责任的问题。\n\n在开源软件的世界里，鼓励人们自由参与和贡献代码，而不是鼓励如何免费白嫖，自由不等于免费，免费不等于服务，将软件源码公开是为了让用户更好更具有针对性的提交和反馈项目中存在的问题，不是为了更好服务你，请不要以服务自己的产品为中心。\n\n请尊重所有在开源环境里工作的朋友们，尊重他们（或是未来的你）的劳动成果。\n\n最后在开源的世界里，学会技术，学会成长，学会参与项目，学会分享成果！\n\n## Hello World\n\n> 关于本机怎样安装运行 Python 的基础知识，建议从其他网站教程得知。\n\n说了这么多，不如先来运行一段 Python3 代码吧。\n\n```python\nprint(\"hello world\")\n```\n\n> 点击下方的 run 按钮即可运行，如果有条件就在本机运行测试。\n\n<div align=\"center\" >\n    <iframe src=\"https://tool.lu/coderunner/embed/aEj.html\" style=\"width:90%; height:320px;\" frameborder=\"0\" mozallowfullscreen webkitallowfullscreen allowfullscreen></iframe>\n</div>\n\n> 在线 Python 编程 [runoob-python](https://www.runoob.com/try/runcode.php?filename=HelloWorld&type=python3) [google-colab](https://colab.research.google.com) 备用地址。\n\n但这样的代码是不够的，稍微认真一点写。\n\n```python\n# encoding: utf-8\n\ndef unit_test():\n    '''\n    this is unit_test\n    '''\n    print(\"hello world\")\n    raise Exception('unit_test')\n\nif __name__ == \"__main__\":\n    try:\n        unit_test()\n    except Exception as e:\n        import sys, traceback\n        exc_type, exc_value, exc_obj = sys.exc_info()\n        traceback.print_tb(exc_obj)\n        print('have a error:', e)\n\n```\n\n运行结果：\n\n```bash\nPS C:\\Users\\dls\\Documents\\GitHub\\MaixPy3> & C:/Users/dls/anaconda3/python.exe c:/Users/dls/Documents/GitHub/MaixPy3/test.py\nhello world\n  File \"c:/Users/dls/Documents/GitHub/MaixPy3/test.py\", line 12, in <module>\n    unit_test()\n  File \"c:/Users/dls/Documents/GitHub/MaixPy3/test.py\", line 8, in unit_test\n    raise Exception('unit_test')\nhave a error: unit_test\n```\n\n代码瞬间就变得复杂了起来？其实不然，这么写必然有它的用意，那这么写都考虑到了哪些情况呢？\n\n### 注意字符编码和代码缩进格式\n\n初学者经常会出现缩进不对齐的语法问题，代码的语法出现问题过于基础就不详谈，检查代码的小技巧就是 `CTAL + A` 全选代码，按 TAB 键右缩进，再配合 SHIFT + TAB 左缩进来发现哪段代码存在问题。\n\n首行的 `# encoding: utf-8` 是为了避免在代码中存在中文或其他语言的字符编码导致的运行出错的问题。\n\n> 在 python3 的字符串类型中 str 与 bytes 是一对欢喜冤家，例如 print(b'123') 打印出来的是 b'123' ，而实际上就是 '123' 的 bytes 字符串，前缀 b 只是为了和 str 区分，因为用途不同，在不同的接口对数据类型的需求不对，例如传递 str 字符串时候是不允许输入 '\\xFF' (0xFF) 字符的（会在转换过程中丢失），但 bytes 可以存储和表达。\n\n### 给代码加入单元测试和异常捕获\n\n想要写出一套稳定可用的代码，需要围绕接口可重入可测试的设计来编写封装，任何人写的代码都可能存在缺陷，在不能确定是哪里产生的问题之前，要能够恢复现场也要能够定位具体位置，以求问题能够最快得到反馈。\n\n所以在代码功能还没写之前，先把测试和异常的模板写好，再开始写功能，边写边测，确保最终交付的软件代码就算出问题也可以随时被测试（定位）出来。\n\n```python\n\ndef unit_test():\n    '''\n    this is unit_test\n    '''\n    print(\"hello world\")\n\nif __name__ == \"__main__\":\n    unit_test()\n```\n\n这样的代码可以保证任何人在任何时候运行该代码的时候都可以复现当时写下的场合所做的内容，然后 `if __name__ == \"__main__\":` 意味着该代码被其他模块包含的时候，不会在 import 该 Python 模块（可取名成 `hello` ）模块时调用，而是根据自己的代码需要执行相应的单元测试进行测试。\n\n```python\nimport hello\nhello.unit_test() # print(\"hello world\")\n```\n\n接着加入异常机制（try: except Exception as e:）保护代码段，表示该段代码出错的时候，能够不停下代码继续运行，像硬件资源访问的代码常常会发生超时、找不到、无响应的错误状态，这种情况下，一个跑起来的系统程序通常不需要停下来，出错了也可以继续运行下一件事，然后把当时的错误记录下来，通过 print 或 logging 日志模块记录下来，拿着错误结果（日志）反馈给开发者，这样开发者就可以分析、定位和解决问题，这其中也包括你自己。\n\n```python\ntry:\n    raise Exception('unit_test')\nexcept Exception as e:\n    import sys, traceback\n    exc_type, exc_value, exc_obj = sys.exc_info()\n    traceback.print_tb(exc_obj)\n    print('have a error:', e)\n```\n\n单元测试是每个程序都尽可能保持的基本原则，虽然人会偷懒，但最起码的代码格式还是要有的。\n\n> 注：traceback 可以抓取最后一次运行出现的错误而不停止运行，但该模块不存在 MicroPython(MaixPy) 中，它有类似的替代方法。\n\n## 封装代码接口成通用模块的方法\n\n世上本没有路，走的人多了，也便成了路。\n\n这里说的路实际上就是一种封装和参考，它意味着你写的代码成为一种事实上的通用操作。\n\n在 Python 上有很多封装参考，主要是为了形成抽象的函数模块。\n\n所以出现了一些经典的编程思想，如面向过程、面向对象、面向切面、面向函数等编程方法，哪一种更好就不比较和讨论了。\n\n这里就简单叙述一下这些编程方法的逐渐发展与变化的过程，可以如何做出选择。\n\n### 面向过程\n\n用面向过程的思维写代码，强调的是这份代码做的这件事需要分几步完成，例如最开始写代码都是这样的。\n\n```python\none = 1\ntwo = 2\nthree = one + two\nprint(three)\n```\n\n这是用人类直觉的过程来写代码，后来意识到可以这样写成通用功能，这是最初的代码封装成某个函数。\n\n```python\ndef sum(num1, num2):\n    return num1 + num2\none, two = 1, 2\nprint(sum(one, two)) # 1 + 2 = 3\n```\n\n于是你多写了个类似的乘法操作。\n\n```python\ndef mul(num1, num2):\n    return num1 * num2\none, two = 1, 2\nprint(mul(one, two)) # 1 * 2 = 2\n```\n\n这时的代码是按照每一个代码操作流程来描述功能的。\n\n### 面向对象\n\n面向对象是相对于面向过程来讲的，把相关的数据和方法组织为一个整体来看待，从更高的层次来进行系统建模，更贴近事物的自然运行模式，一切事物皆对象，通过面向对象的方式，将现实世界的事物抽象成对象，现实世界中的关系抽象成类、[继承](https://baike.baidu.com/item/继承)，帮助人们实现对现实世界的[抽象](https://baike.baidu.com/item/抽象)与数字建模。\n\n在看了一些面向对象的描述后，你会意识到上节面向过程的函数操作可能很通用，应该不只适用于一种变量类型，所以可以通过面向对象（class）的方法来封装它，于是可以试着这样写。\n\n```python\nclass object:\n    def sum(self, a, b):\n        return a + b\n    def mul(self, a, b):\n        return a * b\nobj = object()\nprint(obj.sum(1, 2)) # 1 + 2 = 3\nprint(obj.mul(1, 2)) # 1 * 2 = 2\n```\n\n这样会意识到似乎还不只是数字能用，感觉字符串也能用。\n\n```python\nclass object:\n    def sum(self, a, b):\n        return a + b\n    def mul(self, a, b):\n        return a * b\nobj = object()\nprint(obj.sum('1', '2')) # 1 + 2 = 3\nprint(obj.mul('1', '2')) # 1 * 2 = 2\n```\n\n但这么写会出问题的，字符串相加的时候可以，但相乘的时候会报错误，因为是字符串这个类型的变量是不能相乘的。\n\n```bash\n12\nTraceback (most recent call last):\n  File \"c:/Users/dls/Documents/GitHub/MaixPy3/test.py\", line 8, in <module>\n    print(obj.mul('1', '2')) # 1 * 2 = 2\n  File \"c:/Users/dls/Documents/GitHub/MaixPy3/test.py\", line 5, in mul\n    return a * b\nTypeError: can't multiply sequence by non-int of type 'str'\n```\n\n显然这样写代码就不合理了，但这时运用的面向对象的思想是可行的，只是实现的方式不够好而已，所以重新设计类结构，例如可以写成下面的类结构。\n\n```python\nclass obj:\n    def __init__(self, value):\n        self.value = value\n    def __add__(self, obj):\n        return self.value + obj\n    def __mul__(self, obj):\n        return self.value * obj\n\nprint(obj(1) + 2) # 3\nprint(obj(1) * 2) # 2\n```\n\n其中 `__add__` 和 `__mul__` 是可重载运算符函数，意味着这个类实例化的对象在做 + 和 * 运算操作的时候，会调用类（class）重载函数，接着可以提升可以运算的对象类型，进一步继承对象拓展功能（`class number(obj):`）和访问超类的函数（`super().__add__(obj)`），其中 `if type(obj) is __class__:` 用于判断传入的参数对象是否可以进一步处理。\n\n```python\n\nclass number(obj):\n    def __add__(self, obj):\n        if type(obj) is __class__:\n            return self.value + obj.value\n        return super().__add__(obj)\n    def __mul__(self, obj):\n        if type(obj) is __class__:\n            return self.value * obj.value\n        return super().__mul__(obj)\n\nprint(number(1) + 2)\nprint(number(1) * 2)\nprint(number(1) + number(2))\nprint(number(1) * number(2))\n\n```\n\n这时候会发现可以进一步改写成字符串数值运算。\n\n```python\n\nclass str_number(obj):\n    def __init__(self, value):\n        self.value = int(value)\n    def __add__(self, obj):\n        if type(obj) is __class__:\n            return str(self.value + int(obj.value))\n        return str(super().__add__(int(obj)))\n    def __mul__(self, obj):\n        if type(obj) is __class__:\n            return str(self.value * int(obj.value))\n        return str(super().__mul__(int(obj)))\n\nprint(str_number('1') + '2')\nprint(str_number('1') * '2')\nprint(str_number('1') + str_number('2'))\nprint(str_number('1') * str_number('2'))\n```\n\n现在就可以解决了最初的同类操作适用不同的数据类型，把最初的一段操作通用到数值和字符串了，可以受此启发，它不仅仅只是加法或乘法，还有可能是其他操作，关于面向对象的内容就说到这里，感兴趣的可以查阅相关资料深入学习，本节只讲述可以怎样使用面向对象的思维写代码，而不是单纯把 Class 当 Struct 来使用。\n\n> 像最初写的代码，如果不通过对象继承分解函数，最终将会形成一个巨大的 Struct 结构。\n\n### 面向切面\n\n现在到了选择更多编程思维方式了，关于面向切面编程方法的场景是这样提出的，有一些函数，它在产品调试的时候会需要，但在产品上线的时候是不需要的，那这样的函数应该如何实现比较好？接下来不妨直接看代码，以日志输出的代码为例来说说面向切面，介绍一下如何使用装饰器进行编程的方法。\n\n```python\n\ndef log(param):\n    # simple\n    if callable(param):\n        def wrapper(*args, **kw):\n            print('%s function()' % (param.__name__,))\n            param(*args, **kw)\n        return wrapper\n    # complex\n    def decorator(func):\n        import functools\n        @functools.wraps(func)\n        def wrapper(*args, **kw):\n            print('%s %s():' % (param, func.__name__))\n            return func(*args, **kw)\n        return wrapper\n    return decorator\n\ndef now():\n    print(\"2019\")\n\n@log\ndef now1():\n    print(\"2020\")\n\n@log(\"Is this year?\")\ndef now2():\n    print(\"2021\")\n\nnow()\nnow1()\nnow2()\n\n```\n\n运行结果：\n\n```bash\nPS C:\\Users\\dls\\Documents\\GitHub\\MaixPy3> & C:/Users/dls/anaconda3/python.exe c:/Users/dls/Documents/GitHub/MaixPy3/test.py\n2019\nnow1 function()\n2020\nIs this year? now2():\n2021\nPS C:\\Users\\dls\\Documents\\GitHub\\MaixPy3>\n```\n\n对于产品上线时不需要的函数，注释掉就可以了，更进一步还可以重新设计某些函数满足于某些条件后再运行。\n\n- 在执行某段操作前，先打印当前的系统状态记录下来，确保出错时可以追溯到出错的地方。\n- 在发送网络数据前，要先检查网络通路是否存在，网卡是否还在工作。\n- 在运行操作前，先检查内存够不够，是否需要释放内存再继续操作。\n\n可以看到，当想要不改变某些现成库代码的条件下拓展系统的功能，就不免需要面向切面的设计方法。\n\n>  注意！面向切面提出的是编程思想，实现的方法不一定是装饰函数，可以是回调函数，也可以是重载函数。\n\n### 面向函数\n\n关于面向函数的场景是由于有些问题是被数学公式提出的，所以对于一些数学问题，并不一定要按过程化的思维来写，如实现阶乘函数（factorial），它的功能就是返回一个数的阶乘，即`1*2*3*...*`该数。\n\n```python\ndef fact(n):\n    if n == 3:\n        return 3*2*1\n    if n == 2:\n        return 2*1\n    if n == 1:\n        return 1\nprint(fact(3))\nprint(fact(2))\nprint(fact(1))\n```\n\n不难看出用最初的面向过程来写是写不下去的，不可能去定义所有的可能性，所以要找出规律，可以通过递归的方式实现。\n\n```python\ndef fact(n):\n    return 1 if n == 1 else n * fact(n - 1)\nprint(fact(1))\nprint(fact(5))\nprint(fact(100))\n```\n\n这样功能就完整了，简单来说函数式编程是让编程思维追求程序中存在的公式。\n\n## 试试快速迭代的敏捷开发？\n\n现代开源软件在经历了产测、内测、公测等环节后，直至更新到用户的手里，从前到后的过程通常在一周内就可以完成，所以在设计程序接口的时候，可以接受当下接口设计的不完美，等到未来有一个更好的替代功能接口的时候，就可以将其迭代替换下来，这意味着可以不用设计好整体的软件系统再开始工作，而是边做边改进，这套理论适用于初期需要频繁更新业务逻辑的开源软件。\n\n这里简单引用一段小故事来说明这个现象。\n\n快速迭代，不是说一定要产品做好了，才能上线，半成品也能上线。\n\n在没有上线之前，你怎么知道哪好那不好。所以半成品也是可以出门的，一定不要吝惜在家，丑媳妇才需要尽早见公婆。尽早的让用户去评判你的想法，你的设计是否可以赢得用户的喜爱。快速发出，紧盯用户反馈。百度完成了第一版的搜索引擎，也是让用户去做的选择。用百度 CEO 李彦宏（Robin）的话来说“你怎么知道如何把这个产品设计成最好的呢？只有让用户尽快去用它。既然大家对这版产品有信心，在基本的产品功能上我们有竞争优势，就应该抓住时机尽快将产品推向市场，真正完善它的人将是用户。他们会告诉你喜欢哪里不喜欢哪里，知道了他们的想法，我们就迅速改，改了一百次之后，肯定就是一个非常好的产品了。”\n\n## 准备一个好的开始\n\n看到这里的你，可能会困惑，可能会看不懂，会觉得很复杂，这是认知上的偏差，实际上本文所讲述的都是编程思想上的基础，如果想专业起来，不认真是不行的。\n\n不妨自己动手试试看吧。"}, "/soft/maixpy3/zh/usage/vision/image.html": {"title": "传统视觉算法", "content": "---#图像处理>2022年01月11日以下代码由于MaixPy3还在施工中，此处代码仅供参考和示范，功能已在github和社区供其他同学使用和参考。"}, "/soft/maixpy3/zh/question/maixpy3_faq.html": {"title": "MaixPy3 常见问题与解决方法", "content": "##无法新建或保存文件出现的提示信息：![](./assets/other_1.png)和![](./assets/other_2.png)这是IDE权限不足导致，在任务栏中IDE图标的右键菜单中勾选提权即可，在Windows下的IDE软件0.3.6之前默认不提权。##没有正常退出IDE通过任务栏中小图标的右键菜单重启IDE即可![](./assets/IDE.png)##开发板与电脑连接没有U盘设备添加信息弹出1、检查USB线和USB口是可以进行数据传输的。2、检查是否接上了开发板上的OTG接口。3、系统镜像是否在0.3.5以上。4、打开设备管理器，找到AndroidADBInterface设备，右键卸载改设备并删除其驱动，然后拔插一下开发板，等待系统安装新驱动即可##在运行上述代码的时候出现以下信息![842bf6204549825d5c0bb9c85b53edf.png](attachment:842bf6204549825d5c0bb9c85b53edf.png)![e5c650a86849719557dd5097d96fa6d.jpg](attachment:e5c650a86849719557dd5097d96fa6d.jpg)1、检查USB线和USB口是正常可用的。2、检查驱动正确安装成功。3、检查板子通电并已插入电脑。4、请更新镜像到至少0.3.5以上。5、搜索电脑是否存在其他adb.exe文件，请将其全部删除，并重装此IDE。>因为不同的版本的adb工具存在连接上的差异，导致部分adb工具不适配开发板。##新建文件时出现报错报错如图：![](./assets/IDE_1.png)解决办法：这是权限不足导致的，可以通过任务栏中图标右键菜单勾选提权，即可解决![](./assets/IDE_2.png)##接上开发的板的OTG接口之后，电脑上没有U设备弹出打开电脑上的设备管理器，查看是否存在AndroidADBInterface设备![adb](./assets/adb.jpg)右键卸载，该设备，并卸载勾选上删除设备驱动程序![](./assets/adb_1.jpg)![](./assets/adb_2.jpg)等待卸载结束，重新拔插一下开发板，即可出现U盘设备。##运行代码之后报Nomodulenamed'maix'![](./assets/no-module.png)这是使用的本机的Python内核运行代码导致的，只需要将内核服务切换成Rpyc-python即可##系统找不到指定的文件![](./assets/no-adb.png)这是由于之前系统安装过jupyter并修改过默认工作区文件路径导致的，需要将C:\\Users\\用户名\\\\.jupyter\\jupyter_notebook_config.py中的带有**c.NotebookApp.notebook_dir**的一行前面添加一个“#”注释掉>更多可以查看论坛的[常见问题](https://bbs.sipeed.com/thread/1303)"}, "/soft/maixpy3/zh/tools/0.MaixII-Dock.html": {"title": "使用 MaixPy3 IDE 连接 MaixII-Dock", "content": "|时间|负责人|更新内容||---|---|:---:||2021-12-3|Rui|制定文档初稿||2021-12-7|大老鼠&Ray|微调排版及审核||2021-12-8|Rui|添加IDE基本的使用介绍,MaixPy3入门目录||2022-01-14|dalaoshu|配合IDE更新优化了用户使用体验||2022-01-17|dalaoshu|根据小徐同学的视频反馈，修订了用词和补充SD卡说明||2022-03-02|Rui|添加MaixII-Dock开箱视频，修改部分表述错误|<iframesrc=\"//player.bilibili.com/player.html?aid=636382509&bvid=BV1Vb4y177kj&cid=506217787&page=1\"scrolling=\"no\"border=\"0\"frameborder=\"no\"framespacing=\"0\"allowfullscreen=\"true\"width=\"500\"height=\"300\"></iframe>**使用前请仔细阅读以下内容，可以减少很多疑问**##避坑要点（重要）1.检查USB线和USB口是正常可用的，确定板子通电并插入电脑后，驱动有提示，屏幕有背光，硬件无损坏。2.准备好可以启动系统的卡，如购买已烧录好系统的内存卡，可在购买时选择预烧录套餐（没有的同学需要[自行烧录](https://wiki.sipeed.com/hardware/zh/maixII/M2/flash.html)）。3.烧录或更新到最新MaixPy3镜像，确认`piplist`中的maixpy3包版本大于0.4.0以上。4.安装好[MaixPy3IDE](./MaixPy3_IDE.md)软件，确保大于0.4.0版本。5.安装软件时会弹出驱动安装程序，请确认好驱动安装，连上硬件后启动系统后就会弹出虚拟U盘。6.确认adbshell终端程序、相关服务存在后，就可以直接运行IDE软件自带的历程了。##初期准备工作0.安装MaixPy3IDE软件，它会在安装时提示用户安装驱动，安装好后会弹出jupyternotebook的工作区，也就是你现在看到的文档。![driver.png](attachment:driver.png)1.选择一条可以传输数据的Tpye-C数据线（如购买时附带的数据线），不可以是充电线，或者转接头，不要延长或转接数据线。![typec.jpg](attachment:typec.jpg)2.插入带有maixpy3系统的SD卡。![sd.jpg](attachment:sd.jpg)3.将板子与电脑通过OTGUSB口连接，确认设备通电亮起（power）电源**红灯**，请看下图红圈别接错。![index.jpg](attachment:index.jpg)4.确认屏幕出现logo和二维码（wiki）表示系统启动并已工作，此时电脑会弹出一个U盘，这意味着板子的系统已经准备就绪。（在Windows平台初次使用需要通过步骤5卸载一下驱动即可弹出U盘）![udisk.jpg](attachment:udisk.jpg)>不用理会或修复，出问题重试就行，虚拟U盘设备在传输大文件后可能会因为没有正常关机而丢失文件。![udisk_list.png](attachment:udisk_list.png)>该U盘目录对应的是板子上的linux系统/root/目录，这里main.py是默认的开机脚本，wpa_supplicant.conf是WIFI配置。5.如果没有出现U盘，则需要按下图手动卸载一下AndroidADBInterface手机驱动（常见于XX手机助手）。![list_dev.png](attachment:list_dev.png)找到它，勾选卸载驱动即可，此时U盘跳出，系统准备就绪，**之后遇到的问题与底层硬件没有任何关系！！！**![remove_dev.png](attachment:remove_dev.png)**如果U盘还是没有如上述步骤出现，可以重烧系统或重启设备或考虑换台电脑操作，有可能是个别系统驱动不兼容导致的，实在是解决不了，可以在bbs.sipeed.com汇报给@管理员帮忙解决。**##如何运行代码运行前的可以检查一下运行环境是否正常，下述描述只与Windows平台有关，其他平台不需要。-IDE0.4.0软件启动时会附带一个keep_adb.exe命令行终端的程序提供给熟悉linux终端操作开发板的同学。-IDE0.4.2后keep_adb服务会自动调用adb配置映射（forward）端口（22，18811，18812）。-IDE的内核是否切换成Rpyc-python-与板子连接的ide服务是否工作，判断方法可以在交互终端输入`ps|grepmjpg`查看是否存在下图红框所指示的服务。-如果发现不存在ide服务，可以手动运行`python-c'frommaiximportmjpg;mjpg.start();'`来启动服务，并把现象汇报到社区，目前发现该现象主要出现在Windows10系统之间的差异上。![grep.png](attachment:grep.png)-确认系统防火墙是否阻止了软件底层所需要TCP1881118812的端口号，主要用于运行程序和图像传输。想知道更多，可以点此查看关于[MaixPy3IDE](https://wiki.sipeed.com/soft/maixpy3/zh/tools/MaixPy3_IDE.html)的更加详细的介绍，此处不再赘述。###如何运行Python代码点击选择代码块，点击上方工具中的运行，即可运行代码并输出结果，运行后会出现*表示程序正常运行。![ac379e3ca0627839de12394216d3d87.png](attachment:ac379e3ca0627839de12394216d3d87.png)###如何停止刚才运行的Python代码选择正在运行的代码，点击上方工具栏中的停止，即可停止运行代码，快捷键是按两下ii喔。![9665737f11ad60c602ed81796954c07.png](attachment:9665737f11ad60c602ed81796954c07.png)如果有其他程序正在运行的话，需要先点停止，等程序断开了后（代码块前的*号消失），再点运行。![MaixPy3-IDE.gif](attachment:adc-5.gif)###注意事项IDE的每个代码单元块是独立的，只有定义为全局变量才能在不同的代码单元块中传递。运行也是按开始的顺序进行排队运行，当前一个代码没有运行结束的时候，后一个代码是不会运行。当出现代码运行之后没有出现结果，或者是卡住了，重启IDE和重启开发板就可以解决了。##不妨来试试?点击下列代码块，再点击上方菜单栏中的运行，测试板子连接是否正常。importplatformprint(platform.platform())importtimeprint(time.asctime())[ rpyc-kernel ]( running at Fri Jan 14 16:07:28 2022 )\nLinux-4.9.118-armv7l-with-libc\nThu Jan  1 01:23:27 1970上述结果可知：一、运行这段代码的时间是\\[rpyc-kernel\\](runningatMonDec617:29:312021)二、运行这段代码的平台是Linux-4.9.118-armv7l-with-libc三、运行这段代码的时候，板子系统时间是TueDec701:56:332021。当代码运行的时间为当前时间，并打印出以上代码，说明开发板已经连接上并可以正常的使用##如何连接网络开发板上的OTG接口与电脑连接之后，就会在资源管理器中得到一个U盘设备。通过记事本打开里面名为`wpa_supplicant.conf`文件![9917ccc6b0563cb0f72084dea137e38.png](attachment:9917ccc6b0563cb0f72084dea137e38.png)![net.gif](attachment:adc-1.gif)-wpa_supplicant.conf```bashctrl_interface=/var/run/wpa_supplicantupdate_config=1network={ssid=\"yourWIFIname\"psk=\"yourWIFIpassword\"}```将根据提示修改成需要连接的网络名字和密码。(只支持连接2.4G频段的WIFI，每个人的网络环境不同，也有可能连接不上)##如何更新MaixPy3包可以手动下载最新的MaixPy3[安装包](https://pypi.org/project/maixpy3/#history)![image.png](attachment:image.png)下载带有cp8的安装包，cp9是给别的平台使用的。将这个安装的名字修改成`maixpy3-9.9.9-cp38-cp38-linux_armv7l.whl`,直接存放到开发板中，重启开发板就会自动更新和安装MaixPy3。![2387eda63480f059a12350154f64628.png](attachment:2387eda63480f059a12350154f64628.png)更新前请关闭IDE或不接OTG口，防止有其他操作影响系统的软件更新，在放入U盘后，断电开机会看到如下画面，如果超过3分钟画面没有变化，那可能就是失败了，就请重烧系统吧。（2022年1月14日至今还没出现过失败样本）![pypi.jpg](attachment:pypi.jpg)##配置开机启动脚本将需要开机自动运行的脚本文件名修改成`main.py`放到开发板中的U盘中即可。存放之前要注意，确保脚本是可运行的代码，脚本运行出错只会中断运行，不会有错误信息提示，U盘位置对应着开发板中的linux系统/root/目录。>不用直接在开机启动脚本中进行代码调试，这样会出现一些奇怪的错误！系统默认的启动脚本如下：#!/usr/bin/envpythonfrommaiximportdisplay,imageqrcode=image.Image().open('/home/res/qrcode.png')tmp=image.Image().new((240,240),(0x2c,0x3e,0x50),\"RGB\")tmp.draw_image(qrcode,20,10).draw_string(20,214,\"wiki.sipeed.com/maixpy3\",1,(0xbd,0xc3,0xc7))display.show(tmp)[ rpyc-kernel ]( running at Fri Jan 14 16:08:46 2022 )##更多连接方式使用mobaxterm可以进行串口连接和ssh连接，具体教程查看【<ahref='/hardware/zh/maixII/M2/tools/mobaxterm.html'target=_blank>如何使用mobaxterm</a>】##常见问题指南###如何退出MaixPy3IDE因为它是jupyter网络服务，所以需要从底下托盘右键退出，否则关闭浏览器后，它的网络服务还挂在后台运行的。![exit.png](attachment:exit.png)###我的MaixPy3IDE没有跳出浏览器，没有可以操作的页面。![pan.png](attachment:pan.png)点击托盘查看MaixPy3jupyter服务是否存在，存在则手动复制以下红框的地址到支持谷歌内核的浏览器中进入（有少数同学遇到）。![path.png](attachment:path.png)###如何设置成中文界面请搜索jupyternotebook如何设置成中文，修改对应的语言环境变量即可，如设置中文时需要变量名为：LANG变量值：zh_CN.UTF8。###虚拟U盘文件复制失败，看不到文件。多试几次就好了，大文件容易失败，如果不确定可以在终端交互那里输入sync同步文件或输入poweroff让M2DOCK正常关机，此时再上电就行。注意U盘与系统的linux`root`目录联通，拷贝到U盘的文件会同步出现，但从板子里创建到/root/的文件不会同步出现在U盘，需要重启才能出现，或手动重新挂载U盘才会出现。###更多请查阅[MaixPy3常见问题与解决方法](https://wiki.sipeed.com/soft/maixpy3/zh/question/maixpy3_faq.html)"}, "/soft/maixpy3/zh/usage/vision/preamble.html": {"title": "传统视觉算法 序言", "content": "##版权所有|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|dianjixz|初次编写文档|---||2022年1月18日|dianjixz|修订文档文档|使用Jupyternotebook进行编写文档|该文档为深圳矽速科技有限公司所有，在该公司允许以及遵循开源协议的情况下，允许对其转载复制传播。##软件提要-该软件是maixpy的继承者与发展者，maixpy3软件的诞生标志这maixpy从单一的传统机器视觉迈向了具有AI加持的现代机器视觉。-该软件体系的使用适合对现代嵌入式机器视觉具有热爱的人。-该软件体系的使用适合对现代嵌入式机器视觉设备具有落地期望的公司和个人。-该软件体系的使用适合对现代嵌入式机器视觉的核心算法具有热爱的人。##软件的长期规划目标做成AI领域中的openmv。##本文档的目的本文档不是以教大家如何学习传统机器视觉的文档，而是在大家有机器视觉基础之上能够快速掌握maixpy3软件的使用为目的而编写的。如果大家对文档中的一些说法有什么疑问或者不解，可以参考星瞳科技所作的openmv机器视觉入门文档。如果API有报错或者运行异常，可以进入论坛、qq群等开发者反馈平台进行反馈。[openmv新手入门文档](https://book.openmv.cc/)[https://book.openmv.cc/](https://book.openmv.cc/)>**以下文章基于MaixII-Dock设备编写，适合在所有适配过maixpy3的设备上使用。**"}, "/soft/maixpy3/zh/usage/vision/back-information.html": {"title": "传统视觉背景知识", "content": "|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|dianjixz|初次编写文档|---||2022年1月18日|dianjixz|修订文档文档|使用Jupyternotebook进行编写文档|##图像传感器-摄像头![image-2.png](attachment:image-2.png)[摄像头](https://baike.baidu.com/item/%E6%91%84%E5%83%8F%E5%A4%B4/321263?fr=aladdin)（CAMERA或WEBCAM）又称为电脑相机、电脑眼、电子眼等，是一种视频输入设备，被广泛的运用于视频会议、远程医疗及实时监控等方面。普通的人也可以彼此通过摄像头在网络进行有影像、有声音的交谈和沟通。另外，人们还可以将其用于当前各种流行的数码影像、影音处理等。摄像头的具体内容太多，在此就不做过多解释了。在本文档中，图像传感器就是摄像头，主要用来获取图像数据。##图像描述摄像头的成像背景请参考[摄像头成像的基本原理及结构](https://www.sohu.com/a/141710704_712214)。像素和分辨率是图像描述的基本参数。像素是图像的基本组成单位，分辨率是用来描述像素数量。![引用openmv的图像](attachment:image-3.png)>引用星瞳科技openmv的图像##颜色空间这里只对使用到的颜色空间做简单的介绍。更多请参考：[计算机视觉及色彩空间RGB,HSV,HLS,Lab,LMS,XYZ,CMYK](https://blog.51cto.com/u_15353042/3751269)###RGB三原色在光的世界里，白色光并不是纯净的光。牛顿用三菱镜把光分解成了七种颜色的光。而现代研究表明，光的各种颜色可以由RGB三原色组成。![image-4.png](attachment:image-4.png)###LAB颜色模型[Lab](https://baike.baidu.com/item/Lab%E9%A2%9C%E8%89%B2%E6%A8%A1%E5%9E%8B/3944053?fr=aladdin)模式是根据CommissionInternationalEclairage（CIE）在1931年所制定的一种测定颜色的国际标准建立的。于1976年被改进，并且命名的一种色彩模式。Lab颜色模型是一种设备无关的颜色模型，也是一种基于生理特征的颜色模型。Lab颜色模型由三个要素组成，一个要素是亮度（L），a和b是两个颜色通道。a包括的颜色是从深绿色（低亮度值）到灰色（中亮度值）再到亮粉红色（高亮度值）；b是从亮蓝色（低亮度值）到灰色（中亮度值）再到黄色（高亮度值）。因此，这种颜色混合后将产生具有明亮效果的色彩。对于lab颜色模型的两个优点。基于生理特征的颜色，与设备无关。这两个优点能够很方便的应用在计算机视觉模型的颜色提取上，机器视觉算法的颜色分割主要是基于该模型进行的。![image-6.png](attachment:image-6.png)详细的LAB阈值获取等待有工具后就写。##图像的坐标系统图像的坐标和现实的坐标有些不一样，相对图像来说，左上角为图像坐标的原点，横纵轴依然是X轴Y轴，不同的是，Y轴是反方向的。相应的宽就是图像X轴的长度，高是图像的Y轴的长度。在视觉工具使用中要注意图像坐标系统。![image-5.png](attachment:image-5.png)>引用星瞳科技openmv的图像"}, "/soft/maixpy3/zh/usage/vision/image_base.html": {"title": "图像基础用法", "content": "--->2022年01月11日在V83X与R329硬件上使用maixpy30.3.6版本以上通过测试##创建并显示一张图片这需要display和image的接口功能。-img=image.Image()支持创建一张空白的RGB图像，内置RGB的排列方式是NHWC例如下图。![image.png](attachment:image.png)-img.new(size=(240,240),mode=\"RGB\")，意味着生成一张大小为240x240的RGB图像。-display.show(img)支持showPIL或image生成的图像显示出来，但物理屏幕会进行自适应的拉伸。-str(img)序列化图像的类型，方便查看内部参数如果不做特殊说明，以下所有图像操作均以NHWCRGB24（RGB888）为标准，下图为BGR24示意图。![image-3.png](attachment:image-3.png)所谓RGB和BGR只是交换了以下R和B数据位置，除此之外还有RGB565\\RGB666\\RGBA等常见格式，细节此处不展开介绍，下面我们来创建一张空白的图片吧。frommaiximportimage,displayimg=image.Image()img.new(size=(240,240),mode=\"RGB\")print(str(img))display.show(img)[ rpyc-kernel ]( running at Tue Jan 11 12:00:25 2022 )\n<_maix_image.Image 0x973d90 \" width\":240, \"height\":240, \"type\"=RGB, \"size\":172800>##图像的基础绘图操作有了图片就可以做一些基础的绘图操作，比如说：-draw_line画线-draw_rectangle画框-draw_circle画圆-draw_string写字-draw_image贴图-draw_ellipse椭圆基础用法如下：frommaiximportimage,displayimg=image.Image()img.new(size=(240,240),mode=\"RGB\")img.draw_line(0,0,240,240)img.draw_rectangle(40,80,160,200)img.draw_rectangle(80,160,160,200,color=(255,0,0),thickness=-1)img.draw_circle(120,120,20,color=(0,255,))img.draw_string(40,20,\"hello,world\")img.draw_string(40,40,\"dalaoshu\",2,color=(0,0,255))#椭圆用法解释过于复杂，只介绍常用的基本功能。#img.draw_ellipse(120,40,20,50,90,0,360,color=(0,255,0),thickness=1)#img.draw_image(img)#贴图操作display.show(img)[ rpyc-kernel ]( running at Tue Jan 11 13:09:25 2022 )##保存并打开一张图片>下图仅为示意![image-1-2.jpg](attachment:image-1-2.jpg)承接上文我们得到了一张自己绘制的图片，那么不妨来保存它，并且打开它或从内存中恢复出来。-img.save(\"/root/test.png\")保存到root根目录下，后缀可以是jpgbmppng等等编码格式。-img.open(\"/root/test.png\")打开一张目录下的图片，与save对称。frommaiximportimage,displayimg=image.Image()img.new(size=(240,240),mode=\"RGB\")img.draw_line(0,0,240,240)img.draw_rectangle(40,120,160,200,color=(255,0,0),thickness=16)img.draw_circle(120,120,20,color=(0,255,0))img.draw_string(40,40,\"dalaoshu\",2,color=(0,0,255))img.save(\"/root/test.png\")tmp=image.Image()tmp.open(\"/root/test.png\")display.show(tmp)[ rpyc-kernel ]( running at Tue Jan 11 13:16:46 2022 )##从内存中恢复一张图片>下图仅为示意![image-2-2.jpg](attachment:image-2-2.jpg)除了上述的方法，我们还可以借助img.tobytes()可以将img图像导出一个bytes字符串，再通过img.load恢复原图，这通常发生在图传数据的场合。-img.tobytes()转换图像数据为数组字符串。-img.load()加载数组字符串作为图像数据使用，这需要已知图像的排列方式和数据大小进行数据的还原。需要注意的就是数据的长度和排列的方式要已知，尤其是RGB和BGR会不小心弄混。frommaiximportimage,displayimg=image.Image()img.new(size=(240,240),mode=\"RGB\")img.draw_line(0,0,240,240)img.draw_line(0,240,240,0)data=img.tobytes()tmp=image.Image()tmp.load(data,size=(240,240),mode=\"RGB\")display.show(tmp)[ rpyc-kernel ]( running at Tue Jan 11 13:31:34 2022 )##从摄像头获取一张图像>小提示：在循环代码中使用print会导致系统明显卡顿和延迟。上述的图像都是来自于自己创建，如果想要外部输入一张图像，就可以使用。-camera.capture()获取一张image图像，与上述用法一致。![](./../asserts/camera_1.gif)一般情况下camera生成的图像大小与display的大小一致。如果想要改变可以使用camera.config(size=(224,224))但要慎重使用这个接口，下文会做出解释。frommaiximportimage,display,cameraimg=camera.capture()display.show(img)print(str(img))[ rpyc-kernel ]( running at Tue Jan 11 14:16:01 2022 )\n<_maix_image.Image 0x19fce40 \" width\":240, \"height\":240, \"type\"=RGB, \"size\":172800>##附录一：一种典型的图像缩放场景>这是我们在开发视觉AI应用开发时总结下来的场景经验。推荐使用resize而不是改变摄像头输入，摄像头的输入大小应当与屏幕一致，这是因为落地场景下整体的应用框架决定的。```┌───────────────────────────────────────┐│320x240││┌─────────┐││││224x224│││camera├────────────────────┐││││▼││└────┬────┘┌────────┐││││││││draw┌───────┐│││││◄─────┤text├─────┤nn││││└───────┘││││┌────▼────┐││││││└────────┘│││display│││││││└─────────┘││320x240│└───────────────────────────────────────┘```看上图示意，在落地的使用场景里camera通常要直出到display画面，而nn由于模型的输入尺寸导致需要从320x240缩放到224x224大小。如果我们将camera的输入图像设置成224x224会发生什么？它会在原图的基础上进行最大比例矩形裁剪与缩放（320x240>240x240>224x224），那就会导致camera对原图进行裁剪后送入nn会导致丢失图像的边缘，如果是主流的摄像头输入大小，则呈现（1920x1080>1080x1080>224x224）的效果，此时丢失的数据会更多，还会发现摄像头的视角变小了。**所以为了尽量保留有效数据，会使用copy和resize进行图像的缩放（而非裁剪），这会导致一定的变形，但边缘数据的信息量会被保留，同时不会改变原图。**而改变摄像头输入的大小丢失了数据后，同时在display图像的时候又需要从224x224恢复成320x240，显然resize回去会导致模糊和变形，这样效果会更加糟糕，因此综上所述，此时的代码结构应该如下：frommaiximportimage,displayimg=image.Image()#准备一张原图img.new(size=(240,240),color=(255,255,255),mode=\"RGB\")img.draw_circle(120,120,120,color=(0,255,0))#拷贝一张新图出来并resize后送入nn模块tmp=img.copy().resize(192,160)img.draw_image(tmp)#贴张图示意print(tmp)#原图依旧显示出来display.show(img)##这表示在对当前图像resize尺寸，会导致display显示的时候重新resize回240x240。#img.resize(224,224)#print(img)[ rpyc-kernel ]( running at Tue Jan 11 15:30:22 2022 )\n<_maix_image.Image \"width\":192, \"height\":160, \"type\"=RGB, \"size\":92160>##附录二：关于图像格式的补充说明最后说点什么吧？我们在上面所操作的对象的都是rgb图像，但实际上图像背后是存在了很多变换操作的。这一条路径可以描述成：-从摄像头sensor获取到RAW12/YUV422/JPG这类原始数据，想要得到RGB图像则需要对其各种转换。-如RAW经过ISP转YUV、USB摄像头直出YUV转RGB图像，又或是解码JPG变回RGB等图像转换操作。而在maixpy3中，图像的获取和显示已经被内置的方法自动转换成了RGB888，但背后可能会存在类似YUV图像格式，下图为YUV示意。![image-2.png](attachment:image-2.png)为了能满足落地所需要的性能，maixpy3图像操作是基于opencvC/C++写的，不同于CV2或者PIL这类桌面常见图像处理库，所以在低端硬件上也能有不错的效果表现，如果想深入可以自己琢磨琢磨maixpy3/libmaix的开源仓库，此处所有操作都与libmaixsdk保持一致。"}, "/soft/maixpy3/zh/usage/vision/maixpy3-example.html": {"title": "MaixPy3 基本使用示例", "content": "---|更新时间|负责人|内容|备注||---|---|---|---||2022年1月4日|dianjixz|初次编写文档|---||2022年1月18日|dianjixz|修订文档文档|使用Jupyternotebook进行编写文档|假设你会python，并具有基础的视觉知识，下面是maixpy3的最简程序示例。##\"helloworld!\"确保目标机器已经安装maixpy3软件包。使用maixpy3包在图像上显示\"helloworld!\"。frommaiximportdisplay,imagehello_img=image.Image().new(size=(240,240),color=(255,0,0),mode=\"RGB\")#创建一张红色背景图hello_img.draw_string(30,115,\"helloworld!\",scale=1.0,color=(255,255,255),thickness=1)#在红色背景图上写下helloworlddisplay.show(hello_img)#把这张图显示出来[ rpyc-kernel ]( running at Fri Jan 14 16:48:03 2022 )##从摄像头获取图像并显示使用maixpy3包从摄像头获取图像并显示。frommaiximportcamera,display,image#引入python模块包whileTrue:img=camera.capture()#从摄像头中获取一张图像display.show(img)#将图像显示出来##图像的基础操作###图像的画线frommaiximportimage,displayimg=image.Image().new(size=(240,240),color=(0,0,0),mode=\"RGB\")#创建一张黑色背景图img.draw_line(0,0,100,100,color=(127,127,127),thickness=1)#画一条从（0,0）到（100,100）的白色线段display.show(img)[ rpyc-kernel ]( running at Fri Jan 14 16:47:26 2022 )###图像的画框frommaiximportimage,displayimg=image.Image().new(size=(240,240),color=(0,0,0),mode=\"RGB\")#创建一张黑色背景图img.draw_rectangle(80,160,160,200,color=(0,0,255),thickness=1)#画一个从（80,160）到（160,200）的蓝色矩形外框img.draw_rectangle(10,10,60,60,color=(255,0,0),thickness=-1)#画一个从（10,10）到（60,60）的红色实心矩形display.show(img)[ rpyc-kernel ]( running at Fri Jan 14 16:41:39 2022 )###图像的画圆frommaiximportimage,displayimg=image.Image().new(size=(240,240),color=(0,0,0),mode=\"RGB\")#创建一张黑色背景图img.draw_circle(50,50,20,color=(0,0,255),thickness=1)#画一个中心点在（50,50），半径为20的空心蓝圆img.draw_circle(150,150,20,color=(255,0,0),thickness=-1)#画一个中心点在（150,150），半径为20的实心红圆display.show(img)[ rpyc-kernel ]( running at Fri Jan 14 16:45:05 2022 )###图像的画字符注意：显示中文时需要加载字库！frommaiximportdisplay,image#引入python模块包hello_img=image.Image().new(size=(240,240),color=(0,0,0),mode=\"RGB\")#创建一张黑色背景图hello_img.draw_string(30,115,\"helloworld!\",scale=1.0,color=(255,255,255),thickness=1)#在黑色背景图上写下helloworlddisplay.show(hello_img)#把这张图显示出来[ rpyc-kernel ]( running at Fri Jan 14 16:49:17 2022 )###图像的画椭圆frommaiximportimage,displayimg=image.Image().new(size=(240,240),color=(0,0,0),mode=\"RGB\")#创建一张黑色背景图img.draw_ellipse(120,40,20,50,90,0,360,color=(0,255,0),thickness=1)display.show(img)[ rpyc-kernel ]( running at Fri Jan 14 16:49:49 2022 )画椭圆的参数比较复杂，详情请查看miaxpy3API。###图像的打开与保存frommaiximportimage,displayimg=image.Image()#画一图img.new(size=(240,240),mode=\"RGB\")img.draw_line(0,0,240,240)img.draw_rectangle(40,120,160,200,color=(255,0,0),thickness=16)#img.draw_circle(120,120,20,color=(0,255,0))img.draw_string(40,40,\"dalaoshu\",2,color=(0,0,255))#保存图片到/root/中img.save(\"/root/test.png\")tmp=image.Image()#读取/root/中的图片tmp.open(\"/root/test.png\")display.show(tmp)##vision图像视觉算法maixpy3中集成了一些常用的vision算法，下面是vision算法的简单使用例子。###寻找色块使用maixpy3的查找色块算法，查找图像中符合颜色阈值的色块。frommaiximportimage,display,camerabull=[(13,11,-91,54,48,-28)]#蓝色的lab阈值whileTrue:img=camera.capture()blobs=img.find_blobs(bull)#在图片中查找lab阈值内的颜色色块ifblobs:foriinblobs:img.draw_rectangle(i[\"x\"],i[\"y\"],i[\"x\"]+i[\"w\"],i[\"y\"]+i[\"h\"],color=(0,0,255),thickness=1)#将找到的颜色区域画出来display.show(img)###视觉找线找线算法是面对小车寻线而开发的一个算法。主要的流程是，灰度化->自适应阈值处理->形态学运算->图像最小二乘法。完成算法流程后返回一条线的信息，让小车能够根据识别出来线的信息进行运动。这个接口比较适合做图像寻线。frommaiximportimage,display,cameraimporttimewhileTrue:img=camera.capture()line=img.find_line()img.draw_line(line[\"rect\"][0],line[\"rect\"][1],line[\"rect\"][2],line[\"rect\"][3],color=(255,255,255),thickness=1)img.draw_line(line[\"rect\"][2],line[\"rect\"][3],line[\"rect\"][4],line[\"rect\"][5],color=(255,255,255),thickness=1)img.draw_line(line[\"rect\"][4],line[\"rect\"][5],line[\"rect\"][6],line[\"rect\"][7],color=(255,255,255),thickness=1)img.draw_line(line[\"rect\"][6],line[\"rect\"][7],line[\"rect\"][0],line[\"rect\"][1],color=(255,255,255),thickness=1)img.draw_circle(line[\"cx\"],line[\"cy\"],4,color=(255,255,255),thickness=1)display.show(img)###获取区域的颜色颜色统计算法，统计感兴趣区域最多的颜色并返回。frommaiximportimage,display,cameraimporttimewhileTrue:img=camera.capture()colors=img.get_blob_color((100,100,10,10),0,0)img.draw_rectangle(100,100,110,110,color=(255,0,0),thickness=1)#将找到的颜色区域画出来img.draw_rectangle(9,9,21,21,color=(255,255,255),thickness=1)#将找到的颜色区域画出来img.draw_rectangle(10,10,20,20,color=(int(colors[0]),int(colors[1]),int(colors[2])),thickness=-1)#将找到的颜色区域画出来display.show(img)###识别二维码采用zbar实现，查找画面中出现的二维码。frommaiximportcamera,display,zbarwhileTrue:img=camera.capture()result=zbar.scan_codes([\"qrcode\",\"code39\"],img)display.show(img.draw_string(10,10,str(result),2.0,(255,0,0)))>**更多传统视觉方法小编正在努力开发中，敬请期待！！！**"}}